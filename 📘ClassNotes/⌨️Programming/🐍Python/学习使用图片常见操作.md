参考 https://blog.csdn.net/weixin_52067875/article/details/125921057 
## 一、基本读取和转换方法
### (1) 读取图片为RGB数组和灰度图
使用 Image.open 方法, 并直接通过 np.array 转换成数组。
转换图片 则用 .convert() 函数 
```python
import numpy as np
from PIL import Image 

#读取图像 转化为灰度图片 转化为numpy数组
myim = Image.open(r"C:\Users\18298\Desktop\JupyterProjects\image\mixue.jpg")   # r : raw 
myimgray = np.array(myim.convert("L"),dtype=np.float32)
myim.show()
```

## 二、边缘检测,轮廓提取和压缩图像
### (1) 常用的卷积操作
```python
# 层对应的类	功能
torch.nn.Cov1d()	# 对输入信号应用1D卷积
torch.nn.Cov2d()	# 对输入信号应用2D卷积
torch.nn.Cov3d()	# 对输入信号应用3D卷积
torch.nn.CovTranspose1d()	# 对输入信号应用1D转置卷积
torch.nn.CovTranspose2d()	# 对输入信号应用2D转置卷积
torch.nn.CovTranspose3d()	# 对输入信号应用3D转置卷积 
```
其中常用的参数如下:
```python
#在输入信号上应用1D卷积 torch.nn.Conv1d()
#在输入信号上应用2D卷积 torch.nn.Conv2d()
#在输入信号上应用3D卷积 torch.nn.Conv3d()
#调用2D卷积
torch.nn.Conv2d(in_channels,
                out_channels,
                kernel_size,
                stride=1,
                padding=0,
                dilation=1,
                groups=1,
                bias=True
)
```

### (2) 边缘提取方案
对于边缘提取方案, 往往使用如下的做卷积核  
![[attachments/Pasted image 20240609174123.png]]
完整代码如下(注意: 卷积一定要投影到3维或者4维进行卷积, 同时卷积之前必须更改为浮点数类型), 执行代码是` conv_ker(img_data)  `:

```python 
import torch  
import numpy as np  
import torch.nn as nn  
from matplotlib import pyplot as plt  
from PIL import Image  
  
img = Image.open(r"../datasheets/friedparrot.png").convert("L")  
# img.show()  
img_arr = np.array(img)  
  
# firstly, we change it to a 4-dimension tensor  
img_data = torch.tensor(img_arr.reshape((1,1,img_arr.shape[0],img_arr.shape[1])),  
                        dtype=torch.float32)  
# must convert the img data to float for convolution  
  
print(img_data.shape)   #  must transfer the image into 4 dims  for the convolution [batch,channel,h,w]  
# use the image edge detection kernel to obtain the edge of the image.  
  
s1 = 5; s2 = 5  
kernel = torch.ones(s1,s2, dtype=torch.float32)*-1  
kernel[2,2] = 24  # modify the data of center  
kernel = kernel. reshape((1,1,s1, s2))  # [batch,channel,h,w]  
  
conv_ker = nn.Conv2d(  
    1,1,(s1,s2), bias= False)  
# input is 1 and output is 1 (the first output use the edge detection kernel)  
  
conv_ker.weight.data[0] = kernel   # set the kernel by conv_res.weight.data[0]  
out = conv_ker(img_data)  
img_res = out.data.squeeze()       # sequeeze is leave out all the dimension is 1 (zip figure)  
  
plt.figure()  
plt.imshow(img_res)  
plt.show()
```
效果如图所示:
![[attachments/Pasted image 20240609175312.png]]
### (3) 池化和图像压缩
