### (1) 线程和进程的概念
线程 (Thread) 和进程 (Processing) 其中, thread 线程是操作系统中能够进行运算的最小单位, 
一个进程可以有多个线程, 即并发不同线程;  
同时处理大量任务一般有多线程和多进程两种方式。而<mark style="background: transparent; color: red">多线程往往适用于 IO 密集型任务, 多进程主要适用于包含多 CPU 的计算密集型任务</mark>。

在 Python 多线程中, 最常用的包是 <b><mark style="background: transparent; color: orange">threading 包和 concurrent 包, asyncio 包</mark></b>, 例如 [concurrent.futures](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor) 部分, 常用还有 queue 包, 可以 提供线程之间数据安全的接口。<mark style="background: transparent; color: red">同一个进程的线程之间共享相同的变量</mark>

而多进程主要是通过 multiprocessing 包进行实现的。每个 multiprocessing 间的变量和数据结构等等都是独立的。 


### (2)  Threading 的多线程 
最简单的方法是 threading.Thread 创建线程, 其中采用 `start()` 开始线程,  而 `join` 用于<b><mark style="background: transparent; color: orange">等待线程结束， 即阻塞线程</mark></b>。 即 join 语句会阻塞直到某个线程完成才释放。

time.sleep 为阻塞主程序的部分, 而 threading.Thread <mark style="background: transparent; color: red">可以指定 daemon (守护线程) 参数, 默认为 False (前台线程)</mark>,  即默认创建非守护线程。 而 join 的等待完成实际上即使调用了 `join()`，如果主线程退出了，守护线程的执行也会中断。因此如果将线程设为守护线程，需要确保主线程的生命周期足够长，或者避免在守护线程的生命周期内调用 `join()`
] 
**守护线程（Daemon Thread）的主要特点是：**
1. **主线程退出时，所有的守护线程会被自动终止，而不会等待它们完成。**
2. **非守护线程（默认）会阻止主线程退出，直到它们完成为止。**

可以用 `threading.local()` 创建本地线程, 在本地线程中,  不同的线程的修改仅在线程之内发挥作用, 而线程之间是不影响的 , 例如默认主程序是一个主线程,  而其他创建的线程不会影响开始设置的值。即不能修改;

```python
import time  
from concurrent.futures import ThreadPoolExecutor  
import asyncio  
import threading  
  
mydata = threading.local()  
mydata.number = 10  
print(mydata.number)  
  
def f():  
    for i in range(10):  
        if hasattr(mydata, "number"):  
            mydata.number += 1  
        else:  
            print("no number")  
            mydata.number = 11  
        print(mydata.number)  
        time.sleep(1)  
  
if __name__ == "__main__":  
    thread = threading.Thread(target=f)  
    thread.start()  
    thread.join()  
    print(mydata.number)
```

上述结果不会修改初始的值 10, 这是由于是 threading.local() 类型, 而如果改用下面的部分, 则会被修改 :
```python
class struct:  
    def __init__(self):  
        self.number = 0
mydata = struct()  
mydata.number = 10
```



### `async def` 简介

在 Python 中，`async def` 用于定义 **异步函数**（协程函数）。异步函数允许程序通过 `await` 暂停执行，等待某个耗时操作完成（如 I/O 操作），然后再继续执行后续代码。
`async def` 和 `await` 是 Python 中实现异步编程的核心部分，常与 `asyncio` 库一起使用。

### 定义异步函数
使用 `async def` 定义一个异步函数。调用异步函数时，它不会立即执行，而是返回一个协程对象，需使用 `await` 或通过事件循环运行它。

**示例**:
```python
import asyncio

async def say_hello():
    print("Hello, world!")

# 调用异步函数不会直接运行
result = say_hello()  # 返回一个协程对象
print(result)         # 输出: <coroutine object say_hello at ...>

# 使用事件循环运行协程
asyncio.run(say_hello())  # 输出: Hello, world!
```

### 异步函数中的 `await`
`await` 用于暂停异步函数的执行，等待一个 **awaitable 对象** 完成。`awaitable` 对象包括:
- **协程对象**（由 `async def` 定义的函数调用返回）。
- **`asyncio` 中的一些特定对象**（如 `asyncio.sleep`、`asyncio.gather`）。
- **实现了 `__await__()` 方法的自定义对象**。

**示例**:
```python
import asyncio

async def delayed_hello():
    print("Start waiting...")
    await asyncio.sleep(2)  # 模拟耗时操作
    print("Hello after 2 seconds!")

asyncio.run(delayed_hello())
```

**输出**：

```
Start waiting...
（2秒后）
Hello after 2 seconds!
```

---

### 同步函数和异步函数的对比

|特性|同步函数|异步函数|
|---|---|---|
|定义方式|使用 `def`|使用 `async def`|
|执行方式|立即执行|返回协程对象，需显式运行|
|暂停/非阻塞支持|不支持|支持通过 `await` 暂停执行|
|用途|通常用于 CPU 密集型任务|通常用于 I/O 密集型任务|

---

### 异步编程场景示例

#### 并发任务执行

通过 `asyncio.gather` 或 `asyncio.create_task` 并发运行多个协程，以更高效地完成任务。

**示例**：

```python
import asyncio

async def fetch_data(delay, name):
    await asyncio.sleep(delay)
    print(f"{name} finished after {delay} seconds")
    return f"{name} result"

async def main():
    # 并发运行两个任务
    results = await asyncio.gather(
        fetch_data(2, "Task A"),
        fetch_data(3, "Task B")
    )
    print(results)

asyncio.run(main())
```

**输出**：

```
Task A finished after 2 seconds
Task B finished after 3 seconds
['Task A result', 'Task B result']
```

---

#### 超时控制

`asyncio` 提供 `wait_for` 方法，允许为协程设置超时时间。

**示例**：

```python
import asyncio

async def slow_task():
    await asyncio.sleep(5)
    return "Completed"

async def main():
    try:
        # 设置超时时间为 2 秒
        result = await asyncio.wait_for(slow_task(), timeout=2)
        print(result)
    except asyncio.TimeoutError:
        print("Task timed out!")

asyncio.run(main())
```

**输出**：

```
Task timed out!
```

---

#### 异步迭代器和生成器

异步函数也支持迭代器和生成器，通过 `async for` 和 `async with` 使用。

**异步迭代器**：

```python
class AsyncIterator:
    def __init__(self, n):
        self.n = n
        self.i = 0

    def __aiter__(self):
        return self

    async def __anext__(self):
        if self.i < self.n:
            self.i += 1
            await asyncio.sleep(1)  # 模拟异步操作
            return self.i
        else:
            raise StopAsyncIteration

async def main():
    async for num in AsyncIterator(3):
        print(num)

asyncio.run(main())
```

**输出**：

```
1
2
3
```

---

### `async def` 的限制

1. **只能在事件循环中运行**： 异步函数不能直接运行，必须通过 `await` 或事件循环（如 `asyncio.run`）来启动。
    
2. **不适合 CPU 密集型任务**： 异步函数适用于 I/O 密集型操作（如网络请求、文件操作），而不适合 CPU 密集型任务（如大规模计算）。对于 CPU 密集型任务，可以结合多线程或多进程。
    
3. **老版本兼容性**： Python 3.5 引入了 `async def` 和 `await`，如果使用低于 3.5 的版本，不支持这些特性。
    

---

### 常见的 `asyncio` 工具

1. **`asyncio.run(coroutine)`**： 启动事件循环并运行协程。
    
2. **`asyncio.sleep(seconds)`**： 异步地等待指定时间。
    
3. **`asyncio.gather(*coroutines)`**： 并发运行多个协程，并收集结果。
    
4. **`asyncio.create_task(coroutine)`**： 创建一个新的异步任务，允许调度其他任务的同时继续运行。
    

---

### 总结

`async def` 是 Python 异步编程的核心，用于定义非阻塞协程函数，适合处理 I/O 密集型任务。结合 `await` 和 `asyncio` 的工具，`async def` 能够实现高效的并发操作，是现代异步开发的重要工具。




在 Python 中，`asyncio.Event` 是线程安全的，因此可以在一个线程中调用 `set()`，而在另一个线程中检测它。然而，`asyncio` 的事件循环默认只在主线程中运行，因此如果你在另一个线程中设置了 `asyncio.Event`，主线程中的事件循环可能不会立即检测到变化。

为了让主线程能够检测到另一个线程中设置的 `asyncio.Event`，你可以通过以下方法解决：

---

### 方法 1：使用 `call_soon_threadsafe`
`call_soon_threadsafe` 是 `asyncio` 提供的一种线程安全的方式，用于在事件循环中调度回调函数。你可以在另一个线程中通过 `call_soon_threadsafe` 来设置 `asyncio.Event`，从而确保主线程的事件循环能够立即检测到变化。

#### 修改代码示例：
```python
import asyncio
import threading

class Base2PCTransaction(ABC):
    def __init__(self, conn: BlockingConnection = None, service_name: str = ''):
        # 其他初始化代码...
        self.loop = asyncio.get_event_loop()  # 获取当前事件循环

    def consumers_callback(self, ch, method, properties, body):
        headers = properties.headers
        if headers.get('__type__') == Base2PCStatus.PREPARE.value:
            if self.prepare_cb(ch, method, properties, body):
                # 使用 call_soon_threadsafe 在主线程中设置事件
                self.loop.call_soon_threadsafe(self.__prepare_event.set)
            else:
                self.loop.call_soon_threadsafe(self.__prepare_failed.set)
        elif headers.get('__type__') == Base2PCStatus.COMMIT.value:
            if self.commit_cb(ch, method, properties, body):
                self.loop.call_soon_threadsafe(self.__commit_event.set)
            else:
                self.loop.call_soon_threadsafe(self.__commit_failed.set)
        elif headers.get('__type__') == Base2PCStatus.ROLLBACK.value:
            if self.rollback_cb(ch, method, properties, body):
                self.loop.call_soon_threadsafe(self.__rollback_event.set)
            else:
                self.loop.call_soon_threadsafe(self.__rollback_failed.set)
        else:
            system_logger.warning(f"Invalid message type: {headers.get('__type__')}")
```

---

### 方法 2：使用 `threading.Event` 和 `asyncio` 的结合
如果你不想依赖 `asyncio.Event`，可以使用 `threading.Event` 来跨线程通信，然后在主线程中通过 `asyncio` 的 `run_in_executor` 或 `create_task` 来检测 `threading.Event` 的变化。

#### 修改代码示例：
```python
import asyncio
import threading

class Base2PCTransaction(ABC):
    def __init__(self, conn: BlockingConnection = None, service_name: str = ''):
        # 其他初始化代码...
        self.__prepare_event = threading.Event()  # 使用 threading.Event
        self.__commit_event = threading.Event()
        self.__rollback_event = threading.Event()

    async def __wait_for_prepare(self) -> bool:
        while not self.__prepare_event.is_set():
            if self.__prepare_failed:
                return False
            await asyncio.sleep(0.1)
        return True

    def consumers_callback(self, ch, method, properties, body):
        headers = properties.headers
        if headers.get('__type__') == Base2PCStatus.PREPARE.value:
            if self.prepare_cb(ch, method, properties, body):
                self.__prepare_event.set()  # 直接设置 threading.Event
            else:
                self.__prepare_failed = True
        elif headers.get('__type__') == Base2PCStatus.COMMIT.value:
            if self.commit_cb(ch, method, properties, body):
                self.__commit_event.set()
            else:
                self.__commit_failed = True
        elif headers.get('__type__') == Base2PCStatus.ROLLBACK.value:
            if self.rollback_cb(ch, method, properties, body):
                self.__rollback_event.set()
            else:
                self.__rollback_failed = True
        else:
            system_logger.warning(f"Invalid message type: {headers.get('__type__')}")
```

---

### 方法 3：使用 `asyncio.Queue` 进行跨线程通信
`asyncio.Queue` 是线程安全的，可以用于在多个线程之间传递消息。你可以在消费者线程中将事件放入队列，然后在主线程中从队列中读取事件。

#### 修改代码示例：
```python
import asyncio
import threading

class Base2PCTransaction(ABC):
    def __init__(self, conn: BlockingConnection = None, service_name: str = ''):
        # 其他初始化代码...
        self.event_queue = asyncio.Queue()  # 创建一个 asyncio.Queue

    async def __wait_for_prepare(self) -> bool:
        while True:
            event = await self.event_queue.get()
            if event == 'prepare_success':
                return True
            elif event == 'prepare_failed':
                return False

    def consumers_callback(self, ch, method, properties, body):
        headers = properties.headers
        if headers.get('__type__') == Base2PCStatus.PREPARE.value:
            if self.prepare_cb(ch, method, properties, body):
                # 将事件放入队列
                asyncio.run_coroutine_threadsafe(self.event_queue.put('prepare_success'), self.loop)
            else:
                asyncio.run_coroutine_threadsafe(self.event_queue.put('prepare_failed'), self.loop)
        elif headers.get('__type__') == Base2PCStatus.COMMIT.value:
            if self.commit_cb(ch, method, properties, body):
                asyncio.run_coroutine_threadsafe(self.event_queue.put('commit_success'), self.loop)
            else:
                asyncio.run_coroutine_threadsafe(self.event_queue.put('commit_failed'), self.loop)
        elif headers.get('__type__') == Base2PCStatus.ROLLBACK.value:
            if self.rollback_cb(ch, method, properties, body):
                asyncio.run_coroutine_threadsafe(self.event_queue.put('rollback_success'), self.loop)
            else:
                asyncio.run_coroutine_threadsafe(self.event_queue.put('rollback_failed'), self.loop)
        else:
            system_logger.warning(f"Invalid message type: {headers.get('__type__')}")
```

---

### 总结
- **推荐方法**：使用 `call_soon_threadsafe`，因为它是最直接的方式，能够确保 `asyncio.Event` 在主线程中被正确检测到。
- **替代方案**：如果不想依赖 `asyncio.Event`，可以使用 `threading.Event` 或 `asyncio.Queue` 进行跨线程通信。
- **注意事项**：确保在设置事件时使用线程安全的方式，避免竞争条件。

通过以上方法，你可以确保主线程能够检测到另一个线程中设置的事件。



Yes, there are more stable alternatives to Pika for managing RabbitMQ connections in a Flask application. Here are some options you might consider:

### 1. Celery with RabbitMQ
Celery is a distributed task queue that works well with Flask and can use RabbitMQ as its message broker. It's more robust for production environments and handles connection issues gracefully.

```python
from celery import Celery

# Setup Celery with RabbitMQ
celery = Celery('tasks', broker='amqp://guest:guest@localhost:5672//')

# Define a task
@celery.task
def process_transaction(data):
    # Your transaction logic here
    return result
```

### 2. Flask-AMQP

A Flask extension specifically designed for AMQP protocols like RabbitMQ:

```python
from flask import Flask
from flask_amqp import Amqp

app = Flask(__name__)
amqp = Amqp(app)

@amqp.consumer
def process_message(message):
    # Process your message
    pass
```

### 3. Kombu

Kombu is a messaging library that serves as the transport layer for Celery but can be used independently:

```python
from kombu import Connection, Exchange, Queue, Producer

# Establish connection
conn = Connection('amqp://guest:guest@localhost:5672//')

# Define exchange and queue
exchange = Exchange('my_exchange', type='direct')
queue = Queue('my_queue', exchange, routing_key='my_key')

# Produce message
with conn as connection:
    producer = Producer(connection)
    producer.publish({'data': 'value'}, exchange=exchange, routing_key='my_key')

# Consume message
with conn.Consumer(queue, callbacks=[process_message]) as consumer:
    while True:
        connection.drain_events()
```

### 4. aio-pika (Async variant)

If you're using async Flask with ASGI, aio-pika provides an async interface to RabbitMQ that's more stable than the synchronous Pika:

```python
import asyncio
import aio_pika

async def main():
    connection = await aio_pika.connect_robust("amqp://guest:guest@localhost/")
    
    async with connection:
        channel = await connection.channel()
        
        # Declare queue
        queue = await channel.declare_queue("test_queue", durable=True)
        
        # Send message
        await channel.default_exchange.publish(
            aio_pika.Message(body="Hello".encode()),
            routing_key=queue.name
        )
```

### 5. RabbitMQ client for Python with Flask-RabbitMQ

```python
from flask import Flask
from flask_rabbitmq import RabbitMQ

app = Flask(__name__)
rabbitmq = RabbitMQ(app)

@rabbitmq.queue(exchange='my_exchange', routing_key='my_key')
def process_message(message):
    # Process your message
    pass
```

Each of these alternatives offers better connection management and more stable error handling than raw Pika. Celery is especially popular in Flask applications for managing background tasks with RabbitMQ.

For your 2PC implementation specifically, I would recommend Kombu or Celery, as they provide more robust connection handling and better support for distributed transactions.