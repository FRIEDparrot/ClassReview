## 一、Scipy 常用操作
#### 概率统计常用
scipy.stats 是常用的概率统计的分布函数库:
```python
from scipy.stats import norm       # 正态分布
from scipy.stats import uniform   # 均匀分布

norm.cdf(x) # 返回正态密度 
norm.pdf(x) # 返回正态分布概率密度
uniform.cdf(1)
uniform.pdf(1)
```

生成均匀分布或者正态分布数据:
```python
x1_sample =  uniform.rvs(loc=-pi, scale=2* pi, size=(1,10))
x2_sample = uniform(-5, 10).rvs(size=100)
```

#### 稀疏矩阵分解
稀疏矩阵 svd 分解和求秩:
```python
import numpy as np
from scipy.sparse import csc_matrix
from scipy.sparse.linalg import svds

# 创建一个稀疏矩阵
row = np.array([0, 2, 2, 0, 1, 2, 0])
col = np.array([0, 0, 1, 2, 2, 2, 0])
data = np.array([1, 2, 3, 4, 5, 6, 5])
sp_A = csc_matrix((data, (row, col)), shape=(3, 3), dtype=float)

# 使用奇异值分解求解稀疏矩阵的秩
u, s, vt = svds(sp_A, k=min(sp_A.shape)-1)
rank = np.sum(s > 1e-10)  # 设定一个阈值来判断奇异值是否为零

print("稀疏矩阵的秩:", rank)
```

## 二、numpy 常用操作
### 1. 矩阵操作
创建方法参考 [array-creation文档](https://numpy.org/devdocs/reference/routines.array-creation.html)  
操作方法具体参考[array-manipulation文档](https://numpy.org/devdocs/reference/routines.array-manipulation.html) 
numpy 矩阵索引方法: 如果是取行,则直接采用`[[1,2,3,4,5]]`, 如果是取第二维或者第三维, 则采用 `[:,[1,2,3,4,5]]` , 示例如下:
```python 
data =   self.train_data.data[tar_range][:, dec_range] 
```
零矩阵 np.zeros
单位对角矩阵 eye 
随机矩阵 np.random.rand((3,3))
转换列表为矩阵 np.mat 
矩阵求和 np.sum  (可以选择axis, keep_dims = True) 保证前后维数相同
某个向量或者矩阵中的最大值: m.max() , np.max(m) 
按元素乘积(一般的 * 是按矩阵做矩阵乘法) np.multiply 
按元素施加函数 np.ufunc  
向量点乘(按元素相乘) np.dot 
对角矩阵 np.diag 
返回排序后的下标 np.argsort()
返回**所有的独立元素** np.unique()
**按照下标序列取元素** ndarray.take 
重复元素 np.repeat, np.tile()
抽取某些符合条件的元素 np.extract() 
删除某些下标上的元素 np.delete(a, idx) (也可以指定删除某些轴 axis = m) 
```python 
a = np.array([1,2,3,4,5])             
a.take([0,3])             
array([1, 4])
```

判定是否为 NaN    np.isnan()
另外也可以通过取补运算符 ~ 进行操作
np.choose 按choices中每一个下标进行选取,构造新的向量
```python
choices = np.array([[10, 20, 30, 40], [50, 60, 70, 80], [90, 100, 110, 120], [130, 140, 150, 160]])     
b = np.array([0,1,2,3])     
np.choose(b,choices) 
array([ 10,  60, 110, 160])
```

| 翻转和旋转数组                                                                                                           | 解释                                                              |
| ----------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------- |
| [`flip`](https://numpy.org/devdocs/reference/generated/numpy.flip.html#numpy.flip "numpy.flip")(m[, axis])        | Reverse the order of elements in an array along the given axis. |
| [`fliplr`](https://numpy.org/devdocs/reference/generated/numpy.fliplr.html#numpy.fliplr "numpy.fliplr")(m)        | Reverse the order of elements along axis 1 (left/right).        |
| [`flipud`](https://numpy.org/devdocs/reference/generated/numpy.flipud.html#numpy.flipud "numpy.flipud")(m)        | Reverse the order of elements along axis 0 (up/down).           |
| [`roll`](https://numpy.org/devdocs/reference/generated/numpy.roll.html#numpy.roll "numpy.roll")(a, shift[, axis]) | Roll array elements along a given axis.                         |
| [`rot90`](https://numpy.org/devdocs/reference/generated/numpy.rot90.html#numpy.rot90 "numpy.rot90")(m[, k, axes]) | Rotate an array by 90 degrees in the plane specified by axes.   |
numpy.swapaxes 交换轴
numpy.rollaxes 滚动轴
numpy.broadcast 
np.broadcast_to 

np.expand_dims 插入轴 (类似于unsqueeze)
np.squeeze     删除轴  

替换某些符合要求的元素 cls_prop = np.where(cls_prop == 0,1e-10, cls_prop)
删除array中某个下标的元素 `a = np.delete(a, [1,2])`  
填充对角线元素(常常用于对角线置一或者置零): `np.fill_diagnoal` 
矩阵按找元素除 : 一般 `/` 和 np.divide 等效, 但 `np.divide` 提供了更多的参数选项，例如 `out` 参数可以指定输出数组，`where` 参数可以指定条件掩码等。

np.where : 获取某些符合条件的下标 ()
np.isin : 一个数组中的元素是否在另一个数组中, 示例代码如下:
```python 
target = np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])
left_tar_idx = [0, 1]
# 获取包含在 left_tar_idx 中的下标
indices = np.where(np.isin(target, left_tar_idx))[0]
```
np.cumsum()  # 累计求和  
np.cumpod()  # 累计乘积

```python
# 矩阵转置 
m = np.mat([1,2,3,4], dtype=np.float32)  
m.transpose()
m.T # 得到结果相同
```
统计非零元素的个数: 采用nonzero返回数组或者矩阵**非零元素的下标**(注意返回的是元组, 和维数是相同的)
```python
idx_zero = np.nonzero(A)  # 返回的部分为所有的非零下标, len(idx_zero)为非零元素个数:
idx_zero = (array([0, 0, 0, 1, 1, 1, 2, 2], dtype=int64), array([0, 1, 2, 0, 1, 2, 0, 1], dtype=int64))
#  其中 A[2][2] = 0 , 因此  idx_zero[0] 为
```

`idx_les = (dist_mat < r).nonzero()[0]` 获取满足某个条件的元素的下标(注意:nonzero返回一个和行, 列相同的元组)

此外, numpy.save 和 numpy.load, savetxt() 等等提供了保存和读取的函数, 一般保存在.npy 文件中.

### 2. 概率论相关
舍入 np.around 
均值: np.mean 
方差: $\sigma$ = np.std 
均方差: np.var () (实际上是每个元素与平均值差的平方和的均值)

<b><mark style="background: transparent; color: orange">计算两个向量的相关系数 (Pearson 相关系数)</mark></b>: rowvar 是重要参数
```python 
x = [1,2,3]
y = [4,5,6]
np.corrcoef(x,y)

# 注意:  通过  rowvar 指定是行作为变量还是列作为变量
data = np.random.rand(10, 2)
correlation_matrix = np.corrcoef(data, rowvar=True)  
# 得到的是 10 \times  10 矩阵 (如果是  False, 得到  2x2 矩阵为列向量相关性)
```

```python
np.sort()       
np.argsort()
np.lexsort() #  用于对多个序列进行排序, 返回对应的下标
```

其中, lexsort 中的每一列是一个序列, 并且在排序时, 靠后的优先进行排序，最终返回排序之后的下标。

### 3. np.linalg 线性代数矩阵库相关
#### 1. 常用矩阵操作
参考[linalg.html文档](https://numpy.org/devdocs/reference/routines.linalg.html)线性代数库集成了包括求解行列式和矩阵求逆等等内容。
```python
import numpy as np
import numpy.linalg as la

np.dot(a,b) # 点积 
np.inner   # 内积(对于高维度返回最后一个轴上的和的乘积)
np.outer   # 外积
la.det(a)  # 求行列式 
la.inv(a)   # 矩阵求逆
la.pinv(a) # 伪拟 
lmbda, v = la.eig(A) # 求解**特征值和特征向量**
la.norm(b);  la.norm(A) # 取向量的模或者长度, 进行规范化; 等同于np.sqrt(np.sum(np.multiply(A,A))) 
la.matrix_rank(A) # 矩阵求秩 
```
特征值和特征向量概念和一般公式参考[[📘ClassNotes/📐Mathmatics/📏linear algebra/第五章 矩阵的相似变换|矩阵的相似变换]] 
条件数: [`linalg.cond`](https://numpy.org/devdocs/reference/generated/numpy.linalg.cond.html#numpy.linalg.cond "numpy.linalg.cond")(x[, p]) 定义为
$$\kappa  = ||A|| \space ||A^{-1}||$$

解方程:
$$A x = b$$
```python
求解矩阵方程: la.solve()
A = np.mat([[1,2,3], [4,10,6],[7,3,2]])
b = np.mat([10, 20, 30]).T
la.inv(A) * b , la.solve(A,b)  # 两种是等同的
```

#### 2. 矩阵的分解 (SVD, QR 分解等等)
U,S, VT = la.svd(A) # 奇异值SVD分解(参考[[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓深度学习算法原理(sklearn)/3. 推荐系统和需求搜寻算法(CF,PCA,SVD)#(3) 一般矩阵的 SVD 分解及其证明|一般矩阵的 SVD 分解及其证明]])  
```python
from numpy.linalg import 
from numpy.linalg import svd
fromm numpy.linalg import qr 

la.cholesky(A) # cholesky 分解
U, s, V = svd(matrix)
Q, R = qr(matrix)
```

## 三、pandas 数据分析常用操作
pandas 中最常用的两个数据结构是 Series 和 DataFrame 
<mark style="background: transparent; color: red">Series 是必须包含标签进行创建的类型, 也可以从字典进行创建</mark>。其方法是 
```python
dic = {'a': 1, 'b':2}
s= pd.Series(dic);      bl_s = pd.Series(5, index=range(3));  # 也可以从标量创建   
dic2 = dict(s)   #  反序列化为字典
>>> a = pd.Series(['A', 'B', 'C'])
>>> a.str.cat(sep=',')
```
DataFrame(数据帧) 也可以从值为 list 或者 ndarray 的字典进行创建 
另外, 可以创建面板 (pandas.Panel(data, items, major_axis, minor_axis)), 但是基本不用

### (1) loc, iloc 切片索引
首先, 给出 pandas 采取的存储结构如下(A,B 为columns, 后面的为 index), 实际以字典存储:
```python
df = pd.DataFrame({'A': [10, 20, 30], 'B': [40, 50, 60]})
   A   B
0  10  40
1  20  50
2  30  60
```

```python 
DataFrame.shape()
DataFrame.ndim()
DataFrame.head(n)  # 返回小样本
DataFrame.tail(n)  # 返回小样本
```
取某几行(.loc 函数) 或者某几列 `df[col]`, 此外 <mark style="background: transparent; color: red">iloc 函数也用于访问多个列的元素</mark>:
```python
features = data.iloc[0:2]                    # 取0-1行
print(df.iloc[:, 0]) # 访问第1列 
features = data[data.columns[0:2]]  # 取某几列
features.shape[1]         # 获取某些方向上的尺寸
data_tensor = torch.tensor(data.values)  # 转换pd.dataframe 到 torch.tensor
```

对于新的列添加和删除, 可以直接采用字符串索引, 而 loc 和 iloc 中,可以采用 axis 参数选择行, 因此当 axis = 0 时, 可以直接传递行标签; 
```python
df["new column"] = data   # 新的列添加 
df.pop(["column1", "col2"])   # 删除某一列
df.iloc(axis=0)[1]    # 默认的 axis 是 0, 因此是取第一行的 
df.iloc(axis=1)[0] 
```
loc 用于按照标签索引, 并且可以通过  `[:,]` 指定不同维数, 例如: 
```python
print(df.loc['x'])       # 访问索引为 'x' 的行
print(df.loc[:, 'A'])    # 访问列 'A'
print(df.loc['x', 'A'])  # 访问 'x' 行的 'A' 列
print(df.loc['x':'y', :])# 切片访问从 'x' 到 'y' 的行
```

### (2) 其他索引操作
#### 1. 混合索引 .at 和 .iat
- `.at`: 基于标签访问单个元素，效率高。
- `.iat`: 基于位置访问单个元素，效率高。
```python
print(df.at['x', 'A']) # 访问 'x' 行的 'A' 列 
print(df.iat[0, 0]) # 访问第1行第1列
```

#### 2. 设置新索引
set_index
```python
 df = df.set_index('A');  # 得到的 A 实际上下降了一级
```
此外支持多层索引:
```python
multi_index = pd.MultiIndex.from_tuples([('A', 1), ('A', 2), ('B', 1), ('B', 2)])
df = pd.DataFrame({'Value': [10, 20, 30, 40]}, index=multi_index)
print(df)
# 可通过 loc ,  xs 访问多层索引
print(df.loc['A'])         # 访问第一层索引 'A'
print(df.xs(1, level=1))   # 访问第二层索引为 1 的行
```

rename:
```python
df1.rename(columns={'col1':'c1', 'col2':'c2'});
```

#### 3. 删除行列
```python
df1 = df.append()  # 
df2 = df.drop(0)   # 删除第一行 
del df['A'] # 删除某一列 
df.pop['A']
```

### (3) Pandas 统计基础
pd.sum()
pd.mean()
pd.std()
pd.describe()  # 显示统计信息 (相对比较全)
pd.repeat()
pd.count()
pd.pct_change() # 计算变化百分比
pd.rolling() 
.expanding() 
排序: `df.sort_values('timestamp')` 将 df 按照 timestamp 进行排序

```python
pd.find() 
pd.findall()
```

#### 1. 缺失值处理
pd.fillna()  # 替换缺失值， 具体用法如下:
dropna() # 删除缺失值所在的行列
replace(), interpolate(), mask() 等等
`isna` / `isnull` 和 `notna` / `notnull` (前后两者等效): 检查是否为确实值 
```python
# 用 0 填充
df.fillna(0)
# 用列均值填充
df.fillna(df.mean())
# 前向填充（将 NaN 替换为上一个值）
df.fillna(method='ffill')
# 后向填充（将 NaN 替换为下一个值）
df.fillna(method='bfill')
# 指定每列不同值填充
df.fillna({'A': 0, 'B': 99, 'C': df['C'].mean()})

# 删除含有任何 NaN 的行
df.dropna()
# 删除含有任何 NaN 的列
df.dropna(axis=1)
# 删除所有值为 NaN 的行（全缺失）
df.dropna(how='all')
# 只删除特定列含 NaN 的行
df.dropna(subset=['A', 'B'])

# 替换 NaN 为指定值
df.mask(df.isna(), other=0)
# 替换大于某值的元素为 NaN
df.mask(df > 3, np.nan)
```

#### 2. 表格操作
最常用的函数包括 **apply, applymap 和 pipe** 几种 
<mark style="background: transparent; color: red">1. apply: 行列合理函数</mark> : 针对单列或单行（`Series`）。针对某一轴上的数据（`DataFrame`）。
<b><mark style="background: transparent; color: orange">2. applymap: 元素合理函数</mark></b> : **作用**：针对 `DataFrame` 中的**每一个元素**应用函数。**适用范围**：仅适用于 `DataFrame` (不考虑轴，直接操作每个元素)
<mark style="background: transparent; color: red">3. pipe() 表格函数</mark>  : 往往用于链式处理的函数, 并让 apply 和 applymap 更加简洁;
具体取决于在行, 列或者元素上进行操作. 
```python
df.apply(sum, axis=0) # 对每列求和
df.apply(lambda row: row['A'] + row['B'], axis=1) # 行加总
# 将每个元素平方 
df.applymap(lambda x: x**2)
```

```python title:pipe用法示例
# 示例 DataFrame
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6]
})
# 定义处理函数
def add_constant(df, constant):
    return df + constant
def multiply_constant(df, constant):
    return df * constant
# 使用 pipe 链式操作
df.pipe(add_constant, constant=2).pipe(multiply_constant, constant=3)
```

pandas 中有两种排序方式: 按照标签和按照实际值排序
1. sort_index 用于默认按照升序方法排序, 
2. sort_values 用于按照实际值排序
```python
df = pd.DataFrame(np.random.randn(10,2), index=[1,4,2,3,5])
df.sort_index(axis=0,ascending=false)
df.sort_values(by='col1', kind='quicksort')
```

**get_dummies 转换为独热编码的数据帧**
`pd.get_dummies(a)`

### (4) 转换 pandas 数据到其他格式
#### 1. csv 文件转换
read_csv 和 write_csv 部分:
```python
data = pd.DataFrame(pd.read_csv("Book_data.csv"))  
x,y, z = np.array(data.values).squeeze(0)  
print(x, y, z)
```
squeeze 用于减小一维, 而在 pytorch 中, unsqueeze 用于增加张量的维数, 例如将一个一维张量转换为二维, 则使用:
```python
targets  = data_tensor[:,3].unsqueeze(1)   # add a dimension to it 
```
DataFrame.values() 返回一个 ndarray 形式的数组;
torch张量: 在 torch 中最为常用的是 torch.utils.data 包, 
```python
from torch.utils.data import dataloader
```

最为简单的小批量依次输出的方法如下, 需要注意 `data_tensor = torch.tensor(data.values, dtype=torch.float32) ` 将 DataFrame 转换为 float32 数据类型, 如果默认, 则是double 数据类型，会产生问题

```python 
import deeplearning_util_functions  
import pandas as pd  
import torch  
from torch.utils.data import DataLoader, TensorDataset  
  
# Boston housing problem  
data = pd.read_csv("../datasheets/housing.csv")  
data_tensor = torch.tensor(data.values, dtype=torch.float32)  # note from 
  
features = data_tensor[:, 0:3]  #  
targets  = data_tensor[:,3].unsqueeze(1)   # add a dimension to it  to keep 2 dims
n = features.shape[0] 

# create the linear regression minibatch stochastic gradient descent  
w = torch.ones(n)  
b = torch.zeros(n)  
  
X = features  
Y = targets  
  
DataLoader1 = DataLoader(torch.cat((X,Y), 1),batch_size=20,shuffle=True)
for minibatch in DataLoader1:  
    print(minibatch)
```

#### 2. 文件的分块加载方式和内存释放方法
```python
self.item_properties_data = pd.concat([
    pd.read_csv(path.join(self.dataset_path, 'item_properties_part1.csv')),
    pd.read_csv(path.join(self.dataset_path, 'item_properties_part2.csv'))
])
# 例如, 调用 
item1 = pd.read_csv(path.join(self.dataset_path, 'item_properties_part1.csv'))
item2 = pd.read_csv(path.join(self.dataset_path, 'item_properties_part2.csv'))
# 可以通过如下方法, 删除变量以释放内存
del item1
del item2
# 需要说明的是, 一般调用 del 之后, 不会立即释放内存, 需要调用 gc. collect 进行内存回收:
import gc 
gc.collect()

#  此外,   可以采用 chunksize 分块读取和合并, 这样既能节省内存，也能避免在内存中长期保留大数据集的多个副本, 进一步降低内存占用
chunks1 = pd.read_csv(path.join(self.dataset_path, 'item_properties_part1.csv'), chunksize=10000)
chunks2 = pd.read_csv(path.join(self.dataset_path, 'item_properties_part2.csv'), chunksize=10000)
self.item_properties_data = pd.concat([chunk for chunk in chunks1] + [chunk for chunk in chunks2])
# 需要说明, 上述方法实际上是采用时间换取空间, 实际加载会比较慢
```


### (5) 迭代器对象和 next() 用法
一般 range() 对象是一个 range 对象, 而 iter(range)迭代器可以将 range 转换为迭代器对象。

`next()` 用于迭代器中获取下一个元素, 如果达到末尾则抛出 StopIteration 异常 
```python 
# 获取下一个元素
numbers = [1, 2, 3, 4, 5]
numbers_iter = iter(numbers)
print(next(numbers_iter))  # 输出：1
print(next(numbers_iter))  # 输出：2
```

如果是迭代器对象, 则必须实现 `__iter__()` 和 `__next__()` 两个方法
- `__iter__()`方法：返回迭代器对象本身。
- `__next__()`方法：返回迭代器对象的下一个数据元素，如果没有元素可迭代，则抛出`StopIteration`异常。例如定义 MyIterator 迭代器对象 
```python
class MyIterator:
    def __init__(self, data):
        self.data = data
        self.index = 0

    def __iter__(self):
        return self

    def __next__(self):
        if self.index >= len(self.data):
            raise StopIteration
        result = self.data[self.index]
        self.index += 1
        return result
numbers = [1, 2, 3, 4, 5] 
my_iter = MyIterator(numbers) 

for num in my_iter:  
	print(num)   # 实际上是从next 迭代器方法中获取到的num对象
```

## 四、Python 官方库用法整理
列出某个目录下的文件 `dir(tensorflow)` 
获取encoding 函数:
isinstance(value, dict)

Python 中传值是按照引用传递的, 而为了值传递, 一般采用 copy.deepcopy() 方法 (.copy() 返回的也只是浅拷贝)
```python
a = [1,2]
b = a
b.append(3)
>>> a
[1, 2, 3]
```

### (1) 最常见使用
#### 1) print格式控制和进制转换
```python
x = 1
y = 2
print(f'x = {x:.3f}, z = {x+y:.3f}')  # 直接嵌入式格式控制 
print('score:{:.3f}\n'.format(score))  # 采用字符串的 .format 控制 
```

其中第二个显示 z = 3.00, 即通过string 中的 f 实现了格式控制;
进制转换常用函数
```python
bin()
oct()
int()
hex()
```
当其他数字转换成另外的进制时, 加上0b,0o, 无前缀, oh即可
int('10110001',2) -> 177,  int(0b10110001)
bin(0xbe) # 对于使用其他进制

','.split 和 .splitlines() 方法,可以返回列表式的迭代对象。

利用Python的广播机制, 可以将 下面的整个部分缩写为一句:
```python
# cnt_mat = np.mat(np.zeros((targets.size, decisions.size))) # number of samples of each class for each decision attribute 
# for c in range(targets.size):  
#     for d in range(decisions.size):  
#         tar = targets[c]  
#         dec = decisions[d]  
#         cnt_mat[c,d] = np.sum(counts_arr[(decision_arr == dec) & (target_arr == tar)])

# 正确的简介写法如下 : 
cnt_mat = np.array([  
    [np.sum(counts_arr[(decision_arr == dec) & (target_arr == tar)]) for dec in decisions]  
    for tar in targets  
])
```

下面的例子给出了<b><mark style="background: transparent; color: orange">利用 any 结合生成器表达式, 实现判断两个集合是否有重叠元素, 同时适用于稀疏矩阵</mark></b>:
```python
a = [1, 2, 3]  
b = [4, 5, 6]  

# 使用 any 函数判断重叠  
if any(item in b for item in a):  
    print("有重叠元素")  
else:  
    print("没有重叠元素")
```

#### 2) 数据类型和基本运算
id(a) 可以返回对应的存储地址; 对于 ndarray.copy() 可以返回其他副本;

```python title:检查器
hasattr(X, "ndim")   # 检查某个类对象是否具有某种属性: hasattr
isinstance(X, list)    #  检查某个对象是否是某个类:isinstance 
```
列表拼接直接使用 + 进行  `b =  a + item` 

python 自带了复数类型和 bytes 数据类型, 采用 j 表示复数 
```python
b =  1 + 2j
type(b)   # complex 
b.conjugate()   # 共轭 
b.imag()
b.real()              # 实部
d, m = divmod(3, 2)    # 返回 x/y , x%y

c = bytes(12)   # bytes 数据类
bytes("你好",encoding="utf-8")
```

在 python 中, C 语言的整除(%)采用 `//` 进行,  同时接受 `nan` 和 `inf`, 定义 0\*\*0 = 1 例如: 
``` python 
5.2 // 2  #  2
d = float("inf") ;  - d
d = float("nan")
```

```python
math.trunc(x);   # 取整数部分
round(x, n);    # 取 n 位小数部分 
math.floor  | math.ceil()
```

#### 3) 列表操作和下标遍历指定 

`np.unique(cluster_labels).sort()` 
说明 `sort()` 方法是一个原地操作，返回 `None`，并且它并不是在 `np.unique()` 的结果上操作 

切片对象 slice() 直接通过 slice() 创建, 可以作用于 np 等等对象。
```python 
s = slice(1,5,2) 
a[s]
# 实际上等同于 a[1:5:2]
```

如果我们需要<b><mark style="background: transparent; color: orange">利用两个向量建立一一对应的字典, 往往采用 dict(zip()) 的方式, 例如下方所示:</mark></b>
```python
a = [1, 2, 3]  
b = [4, 5, 6]  
c = dict(zip(a, b))  
```

```python
x[i]
x[i:j]
x[i:j:k]   # 从 x 开始 每隔 j 取一个取到 k  
s = ['a','b','c']
# 常见的函数如下: 
s.count('a') 
s.index('b')   # 第一个下标
s.index('b', 1,2)  # 在某个范围内的第一个下标
s.append()  #  添加元素 
s.extend()   #  直接添加带有元素的列表 
s.insert(4,'d')   # 插入元素 
s.pop()   | s.pop(e)   # e 可以指定元素
s.remove(x)
s.reverse()     # 倒序 
s.clear() 
s.copy()  
sorted(s)   # 排序 
```

zip 跨数组迭代:
```python
a_arr = [1, 2, 3] b_arr = ['a', 'b', 'c'] 
for a, b in zip(a_arr, b_arr): 
	print(a, b)
```

采用  groupby 方案, 减少多次对大型数据集的循环扫描: 
`grouped` 返回的是一个 `Series` 对象（通过 `groupby` 和 `size` 方法生成），以下是一些常用属性:
1. **`index`**：返回 `Series` 的索引，其包含分组的键。
2. **`values`**：返回 `Series` 的值，以 NumPy 数组的形式返回。
3. **`dtype`**：返回数据类型。
4. **`name`**：返回 `Series` 的名称，如果在创建时指定了名称的话。
5. **`shape`**：返回 `Series` 的形状（行数，）。
6. **`size`**：返回 `Series` 中的元素总数。
7. **`count()`**：计算非 NA/null 值的数量。
8. **`sum()`**、**`mean()`**、**`max()`**、**`min()`** 等：返回基于分组后的统计信息。

例如对于以下源码, 统计每个 itemid 和 visitor id 出现的次数, 并构建稀疏矩阵， 原始错误且无法运行的代码如下: 
```python
itms = data.itemid.unique()  
usrs = data.visitorid.unique()  
# generate a unique key  
unique_pairs = set(zip(data.itemid, data.visitorid))  
# num of the opertation of the specific user for specific item is the value  
nums = [  
    data.loc[(data.itemid == pair[0]) & (data.visitorid == pair[1])].shape[0]  
    for pair in unique_pairs
]
# 计算下标
vid = [......] # 获取 nums 中每一个的下标
uid = [......] # 获取 usrs 中每一个的下标

# 构建 user 稀疏矩阵 
usr_matrix = csr_matrix(  
    (nums,(usrs, itms)),  
    shape=(max(usrs), max(itms)), 
dtype=np.int32)
```
上述中的 nums 一句实际上每次都会遍历整个矩阵来查询某个元素, 实际上会消耗大量的时间;

实际建立 UserCF 的 SVD 分解矩阵时, 不需要将 user_id 另做变换, 可直接作为下标.
可以采用 groupby 进行优化上述代码, 实际上会生成如下矩阵:
![[attachments/Pasted image 20241118194532.png|150]]
其代码如下: 比较重要的是先转换为 dict, 获取其 values 并转换为 list 
```python
# generate the event based on the user provided and the operation
grouped_nums = data.groupby(['visitorid','itemid']).size()  
# calculate the index  
rid = [v for (v, i) in grouped_nums.index]  
cid = [i for (v, i) in grouped_nums.index]  
nums_dict = grouped_nums.to_dict()           # change the data to dict  
data_values = np.array(list(nums_dict.values()))   # change its values to array (must use list first)  
  
usr_matrix = csr_matrix(  
    ( data_values, (rid, cid)),  
    shape=(np.max(data.visitorid) + 1, np.max(data.itemid) + 1),  
dtype=np.int32)
```
该代码更加简洁同时, 也减少了大量不必要的运算,  极大提高了速度和效率


#### 4. 用键列表取多个字典中的值组成列表
方法一是列表推导式, 例如:
```python
visitor_data = ["1212931", "143794"]  # 存储 user id 
usr_idx_list = [self.usr_dict[id] for id in visitor_data] #  用子典将 user id 映射为下标列表后返回 
```

将字典的键值序列转换为数组:
```python
tmp = np.array(list(item_dict.keys()))
```


#### 5. 字典拼接, 更新
在 Python 的字典构造中（如 `{key: value}`），**key 必须是唯一的**。如果在构造过程中有重复的 `visitorid`（即重复的 key），后出现的值会覆盖之前的值。也就是说，对于 `visitorid: labels` 的映射，如果 `visitorid` 相同而 `labels` 不同，最终字典会只保留最后一次出现的 `labels` 值。

The `update()` method inserts the specified items to the dictionary.

```python
car = {  
  "brand": "Ford",  
  "model": "Mustang",  
  "year": 1964  
}  
  
car.update({"color": "White"})  
print(car)
```

例如, 将 usr_dict_new 中每一项作为新的项
```python
# 更新 usr_dict
new_usrs = np.unique(user_data_new)
usr_num = len(self.usr_dict)  # 当前用户数量
usr_dict_new = {usr: idx + usr_num for idx, usr in enumerate(new_usrs) if usr not in self.usr_dict}
self.usr_dict.update(usr_dict_new)
```

```python
# there may be new user id, so we update the dictionary here to allocate index to new usrs  
unique_users = np.unique(visitor_data)  
new_usrid = unique_users[~np.isin(unique_users, list(self.usr_dict.keys()))]  
new_usr_dict = { v : i+len(self.usr_dict) for i, v in enumerate(new_usrid)}  
usr_dict = copy.deepcopy(self.usr_dict)  
usr_dict.update(new_usr_dict)  
  
usr_idx_list = [usr_dict[idx] for idx in visitor_data]   # transform the usrid to index  
labels_result = [labels[idx] for idx in usr_idx_list]  
np.array(labels_result)
```


### (2) Python 中的函数定义
#### 1) 指定函数输入和返回类型 
不使用的参数可以采用 _ 代替, 如 `_ = plt.show()` 
在函数编写时, 可以指定输入的格式类型, 具体方法如下:
```python 
def set_axis(axes:matplotlib.axes.Axes, xlabel:str, ylabel:str, xlim, ylim, xscale, yscale, legend):  
    axes.set_xlabel(xlabel);    axes.set_ylabel(ylabel)  
    axes.set_title(title);
```

方法是在 def 后加上 `-> 类型` 指定返回类型, 如果没有返回类型, 则认为是 None.
```python
class A:
	def __init__(self) -> None:
		A.name = "wreg"
		pass
	def sum(a:int, b:int) -> int:
		return a + b
```

如果是返回多个指定类型的参数, 则可以使用:
```python
def generate_sample(self, W, b) -> tuple [int, int]:
    # 你的代码
    return X, y
```

#### 2) 自定义迭代器和迭代类型
基本的方法是使用 yield 进行迭代返回, 
```python
def get_dataloader():
	indics = list(range(0, 100))
	batch_indices =   torch.tensor( indices[i : i + self.batch_size] )  # if batch size = 10,  return the first 10 element at first. 
	yield self.x[batch_indices], self.y[batch_indices]

# 使用方法如下:
X,y = next(iter(data.get_dataloader()))
```

```python
iter_dict = iter(dic.items())
next(iter_dict) 
```

#### 3) 类中函数的私有化
在 Python 中，可以通过在函数名前加上双下划线 `__` 来将其定义为私有方法。私有方法只能在类的内部访问，不能在类的外部直接调用。

#### 4) 函数解包字典和传参
在 Python 中，`**context` 语法允许将==**字典中的键值对解包成关键字参数传递给函数**==。这样可以轻松地将多个参数传递到模板中。

在 `render_template` 方法中，`context` 字典可以包含多个键值对，这些对会在调用 `render_template` 函数时解包。假设有一个字典:
```python
context = {
    'title': 'My Page',
    'user': 'Alice',
    'items': [1, 2, 3],
}
def render_template(self, template_name, context):  
    return render_template(self.get_template_name(), **context)
```

此时,  在模板 `view1.html` 中，就可以直接使用 `title`、`user` 和 `items` 这些变量。

### (3) 常用的关键字
yield 关键字 : 作用是保存当前程序执行状态, 虽然可以理解为 return 操作, 但是yield执行时还保存了当前的执行内容, 再一次调用这个函数时，他会找到你在此函数中的yield关键字，然后从yield的下一句开始执行。
```python
def generator():
    for i in range(10):
        yield i * i   # 需要单个逐一返回 
gen = generator()
print(gen)
```

例如读取大型文本文件的方案:
```python
with open("file.txt", "rb") as f:
	while(True):
		line = f.readline()
		if  content == "":  # 判断文件末尾
			break
		yield content
```

[assert 用法](https://blog.csdn.net/qq_42269354/article/details/89476880) 即后面布尔必须为真,如果为假则触发异常。

map 函数: map 是一个内置函数, 用于将一个函数应用到可迭代对象的每个元素上。如图所示:
```python
def square(x):
    return x * x

numbers = [1, 2, 3, 4, 5]
squared_numbers = map(square, numbers)
print(list(squared_numbers))  # 输出: [1, 4, 9, 16, 25]
```

### (4) Collections 容器类
collection 提供了包括双端队列(deque)等多种数据类型
```python
from colloection import namedtuple,deque
```
参考 [python 官方文档](https://docs.python.org/3/library/collections.html)

```python
def forward(self, input: Tensor, target: Tensor) -> Tensor: return F.mse_loss(input, target, reduction=self.reduction)	
```

### (5) Python 继承的使用
下面讲解了继承 torch.nn.Module 类的方法, 首先需要在类名后面括号加上继承的类, 并且使用 super() 调用父类的 \_\_init\_\_()函数 
```python
import torch  
import numpy as np  
import time  
import torch.nn as nn  
from deeplearning_util_functions import plot_figure  
from matplotlib import pyplot as plt  
  
class Regression_Module(nn.Module):   # if class is in bracket, it will inherit this class  
    def __init__(self, learning_rate:float=0.001) :  
        # for the  method inherit from other method: use:  
        super().__init__()  # inherit the  init method of the parent  
  
        self.learning_rate = learning_rate  
        self.wrapper('learning_rate', 0.2)  
        print(self.learning_rate)  
        print(self.cpu())  
        print(torch.cpu.current_device())  
    def wrapper(self, attr:str, value):  
        setattr(self, attr, value)  
        assert hasattr(self, 'learning_rate') # refer to https://blog.csdn.net/qq_42269354/article/details/89476880  
    def __call__(self, *args, **kwargs):  
        print("executing the method")  
  
a = Regression_Module(0.01)   # create a new class  
a()  # call the __call__ method
```

需要说明, python 允许将一个类像一个实例一样调用, 实际上是调用了其中的 `__call__` 方法
```python
assert hasattr(u.name, '__call__')    # 判断是否可以调用
u()   # 调用其中的 __call__ 方法
```

### (6) html 和 xml 的解析方法 
常见的 html 去除 html 标签, 可以采用 lxml 库
```python
from lxml import etree, html  
  
file_path = "html/UserManual_Bayesian.html"  
  
with open(file_path, 'rb') as fp:  
    contents =  fp.read()  
    text_doc = html.document_fromstring(contents)  # parse the file  
    print(text_doc.text_content())
```

如果是提取 html 中的纯文本内容, 则采用 BeautifulSoup
```python
from bs4 import BeautifulSoup
with open("./html/" + file, "rb") as f:  
    contents = f.read()  
    text_content = BeautifulSoup(contents, parser="html.parser", features='lxml').get_text()
```

## 五、os 库常用操作

```python
file_list = os.listdir(dir1)
for path in file_list:
	print(path)

os.path.exists(dir) 
os.makedir(dir) 
```

执行shell指令
```python
import subprocess  
print(subprocess.run("ls /", shell=True).stdout)
```


```python 
import importlib  
import sys  
  
importlib.reload(sys)  
print(sys.getdefaultencoding())
```


### 设置当前工作目录
在使用 PowerShell 和 CMD 运行 Python 脚本时，可能行为不一致, 当采用 to_csv("Hello, world.csv") 时, 如果当前工作目录处于其他目录, 则 to_csv 会建立到其他目录下, 而解决的办法是通过os.chdir 定位到当前目录:

在脚本中添加打印当前工作目录的代码：
 ```python
 import os
 print("Current working directory:", os.getcwd())
 # 设置工作目录为脚本所在的目录 
 os.chdir(os.path.dirname(os.path.abspath(__file__)))
 ```
2. 脚本中指定保存路径为绝对路径：
 ```python
 df.to_csv(r"C:\Users\Parrot\Desktop\KKX\output.csv", index=False)
 ```

通过上述步骤，你可以找到 CMD 和 PowerShell 行为不一致的原因，并加以修正。如果工作目录不同是主要原因，确保在脚本中使用绝对路径通常是最简便的解决方案。


