## ä¸€ã€Scipy å¸¸ç”¨æ“ä½œ
#### æ¦‚ç‡ç»Ÿè®¡å¸¸ç”¨
scipy.stats æ˜¯å¸¸ç”¨çš„æ¦‚ç‡ç»Ÿè®¡çš„åˆ†å¸ƒå‡½æ•°åº“:
```python
from scipy.stats import norm       # æ­£æ€åˆ†å¸ƒ
from scipy.stats import uniform   # å‡åŒ€åˆ†å¸ƒ

norm.cdf(x) # è¿”å›æ­£æ€å¯†åº¦ 
norm.pdf(x) # è¿”å›æ­£æ€åˆ†å¸ƒæ¦‚ç‡å¯†åº¦
uniform.cdf(1)
uniform.pdf(1)
```

ç”Ÿæˆå‡åŒ€åˆ†å¸ƒæˆ–è€…æ­£æ€åˆ†å¸ƒæ•°æ®:
```python
x1_sample =  uniform.rvs(loc=-pi, scale=2* pi, size=(1,10))
x2_sample = uniform(-5, 10).rvs(size=100)
```

#### ç¨€ç–çŸ©é˜µåˆ†è§£
ç¨€ç–çŸ©é˜µ svd åˆ†è§£å’Œæ±‚ç§©:
```python
import numpy as np
from scipy.sparse import csc_matrix
from scipy.sparse.linalg import svds

# åˆ›å»ºä¸€ä¸ªç¨€ç–çŸ©é˜µ
row = np.array([0, 2, 2, 0, 1, 2, 0])
col = np.array([0, 0, 1, 2, 2, 2, 0])
data = np.array([1, 2, 3, 4, 5, 6, 5])
sp_A = csc_matrix((data, (row, col)), shape=(3, 3), dtype=float)

# ä½¿ç”¨å¥‡å¼‚å€¼åˆ†è§£æ±‚è§£ç¨€ç–çŸ©é˜µçš„ç§©
u, s, vt = svds(sp_A, k=min(sp_A.shape)-1)
rank = np.sum(s > 1e-10)  # è®¾å®šä¸€ä¸ªé˜ˆå€¼æ¥åˆ¤æ–­å¥‡å¼‚å€¼æ˜¯å¦ä¸ºé›¶

print("ç¨€ç–çŸ©é˜µçš„ç§©:", rank)
```

## äºŒã€numpy å¸¸ç”¨æ“ä½œ
### 1. çŸ©é˜µæ“ä½œ
åˆ›å»ºæ–¹æ³•å‚è€ƒ [array-creationæ–‡æ¡£](https://numpy.org/devdocs/reference/routines.array-creation.html)  
æ“ä½œæ–¹æ³•å…·ä½“å‚è€ƒ[array-manipulationæ–‡æ¡£](https://numpy.org/devdocs/reference/routines.array-manipulation.html) 
numpy çŸ©é˜µç´¢å¼•æ–¹æ³•: å¦‚æœæ˜¯å–è¡Œ,åˆ™ç›´æ¥é‡‡ç”¨`[[1,2,3,4,5]]`, å¦‚æœæ˜¯å–ç¬¬äºŒç»´æˆ–è€…ç¬¬ä¸‰ç»´, åˆ™é‡‡ç”¨ `[:,[1,2,3,4,5]]` , ç¤ºä¾‹å¦‚ä¸‹:
```python 
data =   self.train_data.data[tar_range][:, dec_range] 
```
é›¶çŸ©é˜µ np.zeros
å•ä½å¯¹è§’çŸ©é˜µ eye 
éšæœºçŸ©é˜µ np.random.rand((3,3))
è½¬æ¢åˆ—è¡¨ä¸ºçŸ©é˜µ np.mat 
çŸ©é˜µæ±‚å’Œ np.sum  (å¯ä»¥é€‰æ‹©axis, keep_dims = True) ä¿è¯å‰åç»´æ•°ç›¸åŒ
æŸä¸ªå‘é‡æˆ–è€…çŸ©é˜µä¸­çš„æœ€å¤§å€¼: m.max() , np.max(m) 
æŒ‰å…ƒç´ ä¹˜ç§¯(ä¸€èˆ¬çš„ * æ˜¯æŒ‰çŸ©é˜µåšçŸ©é˜µä¹˜æ³•) np.multiply 
æŒ‰å…ƒç´ æ–½åŠ å‡½æ•° np.ufunc  
å‘é‡ç‚¹ä¹˜(æŒ‰å…ƒç´ ç›¸ä¹˜) np.dot 
å¯¹è§’çŸ©é˜µ np.diag 
è¿”å›æ’åºåçš„ä¸‹æ ‡ np.argsort()
è¿”å›**æ‰€æœ‰çš„ç‹¬ç«‹å…ƒç´ ** np.unique()
**æŒ‰ç…§ä¸‹æ ‡åºåˆ—å–å…ƒç´ ** ndarray.take 
é‡å¤å…ƒç´  np.repeat, np.tile()
æŠ½å–æŸäº›ç¬¦åˆæ¡ä»¶çš„å…ƒç´  np.extract() 
åˆ é™¤æŸäº›ä¸‹æ ‡ä¸Šçš„å…ƒç´  np.delete(a, idx) (ä¹Ÿå¯ä»¥æŒ‡å®šåˆ é™¤æŸäº›è½´ axis = m) 
```python 
a = np.array([1,2,3,4,5])             
a.take([0,3])             
array([1, 4])
```

åˆ¤å®šæ˜¯å¦ä¸º NaN    np.isnan()
å¦å¤–ä¹Ÿå¯ä»¥é€šè¿‡å–è¡¥è¿ç®—ç¬¦ ~ è¿›è¡Œæ“ä½œ
np.choose æŒ‰choicesä¸­æ¯ä¸€ä¸ªä¸‹æ ‡è¿›è¡Œé€‰å–,æ„é€ æ–°çš„å‘é‡
```python
choices = np.array([[10, 20, 30, 40], [50, 60, 70, 80], [90, 100, 110, 120], [130, 140, 150, 160]])     
b = np.array([0,1,2,3])     
np.choose(b,choices) 
array([ 10,  60, 110, 160])
```

| ç¿»è½¬å’Œæ—‹è½¬æ•°ç»„                                                                                                           | è§£é‡Š                                                              |
| ----------------------------------------------------------------------------------------------------------------- | --------------------------------------------------------------- |
| [`flip`](https://numpy.org/devdocs/reference/generated/numpy.flip.html#numpy.flip "numpy.flip")(m[,Â axis])        | Reverse the order of elements in an array along the given axis. |
| [`fliplr`](https://numpy.org/devdocs/reference/generated/numpy.fliplr.html#numpy.fliplr "numpy.fliplr")(m)        | Reverse the order of elements along axis 1 (left/right).        |
| [`flipud`](https://numpy.org/devdocs/reference/generated/numpy.flipud.html#numpy.flipud "numpy.flipud")(m)        | Reverse the order of elements along axis 0 (up/down).           |
| [`roll`](https://numpy.org/devdocs/reference/generated/numpy.roll.html#numpy.roll "numpy.roll")(a,Â shift[,Â axis]) | Roll array elements along a given axis.                         |
| [`rot90`](https://numpy.org/devdocs/reference/generated/numpy.rot90.html#numpy.rot90 "numpy.rot90")(m[,Â k,Â axes]) | Rotate an array by 90 degrees in the plane specified by axes.   |
numpy.swapaxes äº¤æ¢è½´
numpy.rollaxes æ»šåŠ¨è½´
numpy.broadcast 
np.broadcast_to 

np.expand_dims æ’å…¥è½´ (ç±»ä¼¼äºunsqueeze)
np.squeeze     åˆ é™¤è½´  

æ›¿æ¢æŸäº›ç¬¦åˆè¦æ±‚çš„å…ƒç´  cls_prop = np.where(cls_prop == 0,1e-10, cls_prop)
åˆ é™¤arrayä¸­æŸä¸ªä¸‹æ ‡çš„å…ƒç´  `a = np.delete(a, [1,2])`  
å¡«å……å¯¹è§’çº¿å…ƒç´ (å¸¸å¸¸ç”¨äºå¯¹è§’çº¿ç½®ä¸€æˆ–è€…ç½®é›¶): `np.fill_diagnoal` 
çŸ©é˜µæŒ‰æ‰¾å…ƒç´ é™¤ : ä¸€èˆ¬ `/` å’Œ np.divide ç­‰æ•ˆ, ä½† `np.divide`Â æä¾›äº†æ›´å¤šçš„å‚æ•°é€‰é¡¹ï¼Œä¾‹å¦‚Â `out`Â å‚æ•°å¯ä»¥æŒ‡å®šè¾“å‡ºæ•°ç»„ï¼Œ`where`Â å‚æ•°å¯ä»¥æŒ‡å®šæ¡ä»¶æ©ç ç­‰ã€‚

np.where : è·å–æŸäº›ç¬¦åˆæ¡ä»¶çš„ä¸‹æ ‡ ()
np.isin : ä¸€ä¸ªæ•°ç»„ä¸­çš„å…ƒç´ æ˜¯å¦åœ¨å¦ä¸€ä¸ªæ•°ç»„ä¸­, ç¤ºä¾‹ä»£ç å¦‚ä¸‹:
```python 
target = np.array([0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0])
left_tar_idx = [0, 1]
# è·å–åŒ…å«åœ¨ left_tar_idx ä¸­çš„ä¸‹æ ‡
indices = np.where(np.isin(target, left_tar_idx))[0]
```
np.cumsum()  # ç´¯è®¡æ±‚å’Œ  
np.cumpod()  # ç´¯è®¡ä¹˜ç§¯

```python
# çŸ©é˜µè½¬ç½® 
m = np.mat([1,2,3,4], dtype=np.float32)  
m.transpose()
m.T # å¾—åˆ°ç»“æœç›¸åŒ
```
ç»Ÿè®¡éé›¶å…ƒç´ çš„ä¸ªæ•°: é‡‡ç”¨nonzeroè¿”å›æ•°ç»„æˆ–è€…çŸ©é˜µ**éé›¶å…ƒç´ çš„ä¸‹æ ‡**(æ³¨æ„è¿”å›çš„æ˜¯å…ƒç»„, å’Œç»´æ•°æ˜¯ç›¸åŒçš„)
```python
idx_zero = np.nonzero(A)  # è¿”å›çš„éƒ¨åˆ†ä¸ºæ‰€æœ‰çš„éé›¶ä¸‹æ ‡, len(idx_zero)ä¸ºéé›¶å…ƒç´ ä¸ªæ•°:
idx_zero = (array([0, 0, 0, 1, 1, 1, 2, 2], dtype=int64), array([0, 1, 2, 0, 1, 2, 0, 1], dtype=int64))
#  å…¶ä¸­ A[2][2] = 0 , å› æ­¤  idx_zero[0] ä¸º
```

`idx_les = (dist_mat < r).nonzero()[0]` è·å–æ»¡è¶³æŸä¸ªæ¡ä»¶çš„å…ƒç´ çš„ä¸‹æ ‡(æ³¨æ„:nonzeroè¿”å›ä¸€ä¸ªå’Œè¡Œ, åˆ—ç›¸åŒçš„å…ƒç»„)

æ­¤å¤–, numpy.save å’Œ numpy.load, savetxt() ç­‰ç­‰æä¾›äº†ä¿å­˜å’Œè¯»å–çš„å‡½æ•°, ä¸€èˆ¬ä¿å­˜åœ¨.npy æ–‡ä»¶ä¸­.

### 2. æ¦‚ç‡è®ºç›¸å…³
èˆå…¥ np.around 
å‡å€¼: np.mean 
æ–¹å·®: $\sigma$ = np.std 
å‡æ–¹å·®: np.var () (å®é™…ä¸Šæ˜¯æ¯ä¸ªå…ƒç´ ä¸å¹³å‡å€¼å·®çš„å¹³æ–¹å’Œçš„å‡å€¼)

<b><mark style="background: transparent; color: orange">è®¡ç®—ä¸¤ä¸ªå‘é‡çš„ç›¸å…³ç³»æ•° (Pearson ç›¸å…³ç³»æ•°)</mark></b>: rowvar æ˜¯é‡è¦å‚æ•°
```python 
x = [1,2,3]
y = [4,5,6]
np.corrcoef(x,y)

# æ³¨æ„:  é€šè¿‡  rowvar æŒ‡å®šæ˜¯è¡Œä½œä¸ºå˜é‡è¿˜æ˜¯åˆ—ä½œä¸ºå˜é‡
data = np.random.rand(10, 2)
correlation_matrix = np.corrcoef(data, rowvar=True)  
# å¾—åˆ°çš„æ˜¯ 10 \times  10 çŸ©é˜µ (å¦‚æœæ˜¯  False, å¾—åˆ°  2x2 çŸ©é˜µä¸ºåˆ—å‘é‡ç›¸å…³æ€§)
```

```python
np.sort()       
np.argsort()
np.lexsort() #  ç”¨äºå¯¹å¤šä¸ªåºåˆ—è¿›è¡Œæ’åº, è¿”å›å¯¹åº”çš„ä¸‹æ ‡
```

å…¶ä¸­, lexsort ä¸­çš„æ¯ä¸€åˆ—æ˜¯ä¸€ä¸ªåºåˆ—, å¹¶ä¸”åœ¨æ’åºæ—¶, é åçš„ä¼˜å…ˆè¿›è¡Œæ’åºï¼Œæœ€ç»ˆè¿”å›æ’åºä¹‹åçš„ä¸‹æ ‡ã€‚

### 3. np.linalg çº¿æ€§ä»£æ•°çŸ©é˜µåº“ç›¸å…³
#### 1. å¸¸ç”¨çŸ©é˜µæ“ä½œ
å‚è€ƒ[linalg.htmlæ–‡æ¡£](https://numpy.org/devdocs/reference/routines.linalg.html)çº¿æ€§ä»£æ•°åº“é›†æˆäº†åŒ…æ‹¬æ±‚è§£è¡Œåˆ—å¼å’ŒçŸ©é˜µæ±‚é€†ç­‰ç­‰å†…å®¹ã€‚
```python
import numpy as np
import numpy.linalg as la

np.dot(a,b) # ç‚¹ç§¯ 
np.inner   # å†…ç§¯(å¯¹äºé«˜ç»´åº¦è¿”å›æœ€åä¸€ä¸ªè½´ä¸Šçš„å’Œçš„ä¹˜ç§¯)
np.outer   # å¤–ç§¯
la.det(a)  # æ±‚è¡Œåˆ—å¼ 
la.inv(a)   # çŸ©é˜µæ±‚é€†
la.pinv(a) # ä¼ªæ‹Ÿ 
lmbda, v = la.eig(A) # æ±‚è§£**ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡**
la.norm(b);  la.norm(A) # å–å‘é‡çš„æ¨¡æˆ–è€…é•¿åº¦, è¿›è¡Œè§„èŒƒåŒ–; ç­‰åŒäºnp.sqrt(np.sum(np.multiply(A,A))) 
la.matrix_rank(A) # çŸ©é˜µæ±‚ç§© 
```
ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡æ¦‚å¿µå’Œä¸€èˆ¬å…¬å¼å‚è€ƒ[[ğŸ“˜ClassNotes/ğŸ“Mathmatics/ğŸ“linear algebra/ç¬¬äº”ç«  çŸ©é˜µçš„ç›¸ä¼¼å˜æ¢|çŸ©é˜µçš„ç›¸ä¼¼å˜æ¢]] 
æ¡ä»¶æ•°: [`linalg.cond`](https://numpy.org/devdocs/reference/generated/numpy.linalg.cond.html#numpy.linalg.cond "numpy.linalg.cond")(x[,Â p]) å®šä¹‰ä¸º
$$\kappa  = ||A|| \space ||A^{-1}||$$

è§£æ–¹ç¨‹:
$$A x = b$$
```python
æ±‚è§£çŸ©é˜µæ–¹ç¨‹: la.solve()
A = np.mat([[1,2,3], [4,10,6],[7,3,2]])
b = np.mat([10, 20, 30]).T
la.inv(A) * b , la.solve(A,b)  # ä¸¤ç§æ˜¯ç­‰åŒçš„
```

#### 2. çŸ©é˜µçš„åˆ†è§£ (SVD, QR åˆ†è§£ç­‰ç­‰)
U,S, VT = la.svd(A) # å¥‡å¼‚å€¼SVDåˆ†è§£(å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æ·±åº¦å­¦ä¹ ç®—æ³•åŸç†(sklearn)/3. æ¨èç³»ç»Ÿå’Œéœ€æ±‚æœå¯»ç®—æ³•(CF,PCA,SVD)#(3) ä¸€èˆ¬çŸ©é˜µçš„ SVD åˆ†è§£åŠå…¶è¯æ˜|ä¸€èˆ¬çŸ©é˜µçš„ SVD åˆ†è§£åŠå…¶è¯æ˜]])  
```python
from numpy.linalg import 
from numpy.linalg import svd
fromm numpy.linalg import qr 

la.cholesky(A) # cholesky åˆ†è§£
U, s, V = svd(matrix)
Q, R = qr(matrix)
```

## ä¸‰ã€pandas æ•°æ®åˆ†æå¸¸ç”¨æ“ä½œ
pandas ä¸­æœ€å¸¸ç”¨çš„ä¸¤ä¸ªæ•°æ®ç»“æ„æ˜¯ Series å’Œ DataFrame 
<mark style="background: transparent; color: red">Series æ˜¯å¿…é¡»åŒ…å«æ ‡ç­¾è¿›è¡Œåˆ›å»ºçš„ç±»å‹, ä¹Ÿå¯ä»¥ä»å­—å…¸è¿›è¡Œåˆ›å»º</mark>ã€‚å…¶æ–¹æ³•æ˜¯ 
```python
dic = {'a': 1, 'b':2}
s= pd.Series(dic);      bl_s = pd.Series(5, index=range(3));  # ä¹Ÿå¯ä»¥ä»æ ‡é‡åˆ›å»º   
dic2 = dict(s)   #  ååºåˆ—åŒ–ä¸ºå­—å…¸
>>> a = pd.Series(['A', 'B', 'C'])
>>> a.str.cat(sep=',')
```
DataFrame(æ•°æ®å¸§) ä¹Ÿå¯ä»¥ä»å€¼ä¸º list æˆ–è€… ndarray çš„å­—å…¸è¿›è¡Œåˆ›å»º 
å¦å¤–, å¯ä»¥åˆ›å»ºé¢æ¿ (pandas.Panel(data, items, major_axis, minor_axis)), ä½†æ˜¯åŸºæœ¬ä¸ç”¨

### (1) loc, iloc åˆ‡ç‰‡ç´¢å¼•
é¦–å…ˆ, ç»™å‡º pandas é‡‡å–çš„å­˜å‚¨ç»“æ„å¦‚ä¸‹(A,B ä¸ºcolumns, åé¢çš„ä¸º index), å®é™…ä»¥å­—å…¸å­˜å‚¨:
```python
df = pd.DataFrame({'A': [10, 20, 30], 'B': [40, 50, 60]})
   A   B
0  10  40
1  20  50
2  30  60
```

```python 
DataFrame.shape()
DataFrame.ndim()
DataFrame.head(n)  # è¿”å›å°æ ·æœ¬
DataFrame.tail(n)  # è¿”å›å°æ ·æœ¬
```
å–æŸå‡ è¡Œ(.loc å‡½æ•°) æˆ–è€…æŸå‡ åˆ— `df[col]`, æ­¤å¤– <mark style="background: transparent; color: red">iloc å‡½æ•°ä¹Ÿç”¨äºè®¿é—®å¤šä¸ªåˆ—çš„å…ƒç´ </mark>:
```python
features = data.iloc[0:2]                    # å–0-1è¡Œ
print(df.iloc[:, 0]) # è®¿é—®ç¬¬1åˆ— 
features = data[data.columns[0:2]]  # å–æŸå‡ åˆ—
features.shape[1]         # è·å–æŸäº›æ–¹å‘ä¸Šçš„å°ºå¯¸
data_tensor = torch.tensor(data.values)  # è½¬æ¢pd.dataframe åˆ° torch.tensor
```

å¯¹äºæ–°çš„åˆ—æ·»åŠ å’Œåˆ é™¤, å¯ä»¥ç›´æ¥é‡‡ç”¨å­—ç¬¦ä¸²ç´¢å¼•, è€Œ loc å’Œ iloc ä¸­,å¯ä»¥é‡‡ç”¨ axis å‚æ•°é€‰æ‹©è¡Œ, å› æ­¤å½“ axis = 0 æ—¶, å¯ä»¥ç›´æ¥ä¼ é€’è¡Œæ ‡ç­¾; 
```python
df["new column"] = data   # æ–°çš„åˆ—æ·»åŠ  
df.pop(["column1", "col2"])   # åˆ é™¤æŸä¸€åˆ—
df.iloc(axis=0)[1]    # é»˜è®¤çš„ axis æ˜¯ 0, å› æ­¤æ˜¯å–ç¬¬ä¸€è¡Œçš„ 
df.iloc(axis=1)[0] 
```
loc ç”¨äºæŒ‰ç…§æ ‡ç­¾ç´¢å¼•, å¹¶ä¸”å¯ä»¥é€šè¿‡  `[:,]` æŒ‡å®šä¸åŒç»´æ•°, ä¾‹å¦‚: 
```python
print(df.loc['x'])       # è®¿é—®ç´¢å¼•ä¸º 'x' çš„è¡Œ
print(df.loc[:, 'A'])    # è®¿é—®åˆ— 'A'
print(df.loc['x', 'A'])  # è®¿é—® 'x' è¡Œçš„ 'A' åˆ—
print(df.loc['x':'y', :])# åˆ‡ç‰‡è®¿é—®ä» 'x' åˆ° 'y' çš„è¡Œ
```

### (2) å…¶ä»–ç´¢å¼•æ“ä½œ
#### 1. æ··åˆç´¢å¼• .at å’Œ .iat
- `.at`: åŸºäºæ ‡ç­¾è®¿é—®å•ä¸ªå…ƒç´ ï¼Œæ•ˆç‡é«˜ã€‚
- `.iat`: åŸºäºä½ç½®è®¿é—®å•ä¸ªå…ƒç´ ï¼Œæ•ˆç‡é«˜ã€‚
```python
print(df.at['x', 'A']) # è®¿é—® 'x' è¡Œçš„ 'A' åˆ— 
print(df.iat[0, 0]) # è®¿é—®ç¬¬1è¡Œç¬¬1åˆ—
```

#### 2. è®¾ç½®æ–°ç´¢å¼•
set_index
```python
 df = df.set_index('A');  # å¾—åˆ°çš„ A å®é™…ä¸Šä¸‹é™äº†ä¸€çº§
```
æ­¤å¤–æ”¯æŒå¤šå±‚ç´¢å¼•:
```python
multi_index = pd.MultiIndex.from_tuples([('A', 1), ('A', 2), ('B', 1), ('B', 2)])
df = pd.DataFrame({'Value': [10, 20, 30, 40]}, index=multi_index)
print(df)
# å¯é€šè¿‡ loc ,  xs è®¿é—®å¤šå±‚ç´¢å¼•
print(df.loc['A'])         # è®¿é—®ç¬¬ä¸€å±‚ç´¢å¼• 'A'
print(df.xs(1, level=1))   # è®¿é—®ç¬¬äºŒå±‚ç´¢å¼•ä¸º 1 çš„è¡Œ
```

rename:
```python
df1.rename(columns={'col1':'c1', 'col2':'c2'});
```

#### 3. åˆ é™¤è¡Œåˆ—
```python
df1 = df.append()  # 
df2 = df.drop(0)   # åˆ é™¤ç¬¬ä¸€è¡Œ 
del df['A'] # åˆ é™¤æŸä¸€åˆ— 
df.pop['A']
```

### (3) Pandas ç»Ÿè®¡åŸºç¡€
pd.sum()
pd.mean()
pd.std()
pd.describe()  # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯ (ç›¸å¯¹æ¯”è¾ƒå…¨)
pd.repeat()
pd.count()
pd.pct_change() # è®¡ç®—å˜åŒ–ç™¾åˆ†æ¯”
pd.rolling() 
.expanding() 
æ’åº: `df.sort_values('timestamp')` å°† df æŒ‰ç…§ timestamp è¿›è¡Œæ’åº

```python
pd.find() 
pd.findall()
```

#### 1. ç¼ºå¤±å€¼å¤„ç†
pd.fillna()  # æ›¿æ¢ç¼ºå¤±å€¼ï¼Œ å…·ä½“ç”¨æ³•å¦‚ä¸‹:
dropna() # åˆ é™¤ç¼ºå¤±å€¼æ‰€åœ¨çš„è¡Œåˆ—
replace(), interpolate(), mask() ç­‰ç­‰
`isna` / `isnull` å’Œ `notna` / `notnull` (å‰åä¸¤è€…ç­‰æ•ˆ): æ£€æŸ¥æ˜¯å¦ä¸ºç¡®å®å€¼ 
```python
# ç”¨ 0 å¡«å……
df.fillna(0)
# ç”¨åˆ—å‡å€¼å¡«å……
df.fillna(df.mean())
# å‰å‘å¡«å……ï¼ˆå°† NaN æ›¿æ¢ä¸ºä¸Šä¸€ä¸ªå€¼ï¼‰
df.fillna(method='ffill')
# åå‘å¡«å……ï¼ˆå°† NaN æ›¿æ¢ä¸ºä¸‹ä¸€ä¸ªå€¼ï¼‰
df.fillna(method='bfill')
# æŒ‡å®šæ¯åˆ—ä¸åŒå€¼å¡«å……
df.fillna({'A': 0, 'B': 99, 'C': df['C'].mean()})

# åˆ é™¤å«æœ‰ä»»ä½• NaN çš„è¡Œ
df.dropna()
# åˆ é™¤å«æœ‰ä»»ä½• NaN çš„åˆ—
df.dropna(axis=1)
# åˆ é™¤æ‰€æœ‰å€¼ä¸º NaN çš„è¡Œï¼ˆå…¨ç¼ºå¤±ï¼‰
df.dropna(how='all')
# åªåˆ é™¤ç‰¹å®šåˆ—å« NaN çš„è¡Œ
df.dropna(subset=['A', 'B'])

# æ›¿æ¢ NaN ä¸ºæŒ‡å®šå€¼
df.mask(df.isna(), other=0)
# æ›¿æ¢å¤§äºæŸå€¼çš„å…ƒç´ ä¸º NaN
df.mask(df > 3, np.nan)
```

#### 2. è¡¨æ ¼æ“ä½œ
æœ€å¸¸ç”¨çš„å‡½æ•°åŒ…æ‹¬ **apply, applymap å’Œ pipe** å‡ ç§ 
<mark style="background: transparent; color: red">1. apply: è¡Œåˆ—åˆç†å‡½æ•°</mark> : é’ˆå¯¹å•åˆ—æˆ–å•è¡Œï¼ˆ`Series`ï¼‰ã€‚é’ˆå¯¹æŸä¸€è½´ä¸Šçš„æ•°æ®ï¼ˆ`DataFrame`ï¼‰ã€‚
<b><mark style="background: transparent; color: orange">2. applymap: å…ƒç´ åˆç†å‡½æ•°</mark></b> : **ä½œç”¨**ï¼šé’ˆå¯¹ `DataFrame` ä¸­çš„**æ¯ä¸€ä¸ªå…ƒç´ **åº”ç”¨å‡½æ•°ã€‚**é€‚ç”¨èŒƒå›´**ï¼šä»…é€‚ç”¨äº `DataFrame` (ä¸è€ƒè™‘è½´ï¼Œç›´æ¥æ“ä½œæ¯ä¸ªå…ƒç´ )
<mark style="background: transparent; color: red">3. pipe() è¡¨æ ¼å‡½æ•°</mark>  : å¾€å¾€ç”¨äºé“¾å¼å¤„ç†çš„å‡½æ•°, å¹¶è®© apply å’Œ applymap æ›´åŠ ç®€æ´;
å…·ä½“å–å†³äºåœ¨è¡Œ, åˆ—æˆ–è€…å…ƒç´ ä¸Šè¿›è¡Œæ“ä½œ. 
```python
df.apply(sum, axis=0) # å¯¹æ¯åˆ—æ±‚å’Œ
df.apply(lambda row: row['A'] + row['B'], axis=1) # è¡ŒåŠ æ€»
# å°†æ¯ä¸ªå…ƒç´ å¹³æ–¹ 
df.applymap(lambda x: x**2)
```

```python title:pipeç”¨æ³•ç¤ºä¾‹
# ç¤ºä¾‹ DataFrame
df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [4, 5, 6]
})
# å®šä¹‰å¤„ç†å‡½æ•°
def add_constant(df, constant):
    return df + constant
def multiply_constant(df, constant):
    return df * constant
# ä½¿ç”¨ pipe é“¾å¼æ“ä½œ
df.pipe(add_constant, constant=2).pipe(multiply_constant, constant=3)
```

pandas ä¸­æœ‰ä¸¤ç§æ’åºæ–¹å¼: æŒ‰ç…§æ ‡ç­¾å’ŒæŒ‰ç…§å®é™…å€¼æ’åº
1. sort_index ç”¨äºé»˜è®¤æŒ‰ç…§å‡åºæ–¹æ³•æ’åº, 
2. sort_values ç”¨äºæŒ‰ç…§å®é™…å€¼æ’åº
```python
df = pd.DataFrame(np.random.randn(10,2), index=[1,4,2,3,5])
df.sort_index(axis=0,ascending=false)
df.sort_values(by='col1', kind='quicksort')
```

**get_dummies è½¬æ¢ä¸ºç‹¬çƒ­ç¼–ç çš„æ•°æ®å¸§**
`pd.get_dummies(a)`

### (4) è½¬æ¢ pandas æ•°æ®åˆ°å…¶ä»–æ ¼å¼
#### 1. csv æ–‡ä»¶è½¬æ¢
read_csv å’Œ write_csv éƒ¨åˆ†:
```python
data = pd.DataFrame(pd.read_csv("Book_data.csv"))  
x,y, z = np.array(data.values).squeeze(0)  
print(x, y, z)
```
squeeze ç”¨äºå‡å°ä¸€ç»´, è€Œåœ¨ pytorch ä¸­, unsqueeze ç”¨äºå¢åŠ å¼ é‡çš„ç»´æ•°, ä¾‹å¦‚å°†ä¸€ä¸ªä¸€ç»´å¼ é‡è½¬æ¢ä¸ºäºŒç»´, åˆ™ä½¿ç”¨:
```python
targets  = data_tensor[:,3].unsqueeze(1)   # add a dimension to it 
```
DataFrame.values() è¿”å›ä¸€ä¸ª ndarray å½¢å¼çš„æ•°ç»„;
torchå¼ é‡: åœ¨ torch ä¸­æœ€ä¸ºå¸¸ç”¨çš„æ˜¯ torch.utils.data åŒ…, 
```python
from torch.utils.data import dataloader
```

æœ€ä¸ºç®€å•çš„å°æ‰¹é‡ä¾æ¬¡è¾“å‡ºçš„æ–¹æ³•å¦‚ä¸‹, éœ€è¦æ³¨æ„ `data_tensor = torch.tensor(data.values, dtype=torch.float32) ` å°† DataFrame è½¬æ¢ä¸º float32 æ•°æ®ç±»å‹, å¦‚æœé»˜è®¤, åˆ™æ˜¯double æ•°æ®ç±»å‹ï¼Œä¼šäº§ç”Ÿé—®é¢˜

```python 
import deeplearning_util_functions  
import pandas as pd  
import torch  
from torch.utils.data import DataLoader, TensorDataset  
  
# Boston housing problem  
data = pd.read_csv("../datasheets/housing.csv")  
data_tensor = torch.tensor(data.values, dtype=torch.float32)  # note from 
  
features = data_tensor[:, 0:3]  #  
targets  = data_tensor[:,3].unsqueeze(1)   # add a dimension to it  to keep 2 dims
n = features.shape[0] 

# create the linear regression minibatch stochastic gradient descent  
w = torch.ones(n)  
b = torch.zeros(n)  
  
X = features  
Y = targets  
  
DataLoader1 = DataLoader(torch.cat((X,Y), 1),batch_size=20,shuffle=True)
for minibatch in DataLoader1:  
    print(minibatch)
```

#### 2. æ–‡ä»¶çš„åˆ†å—åŠ è½½æ–¹å¼å’Œå†…å­˜é‡Šæ”¾æ–¹æ³•
```python
self.item_properties_data = pd.concat([
    pd.read_csv(path.join(self.dataset_path, 'item_properties_part1.csv')),
    pd.read_csv(path.join(self.dataset_path, 'item_properties_part2.csv'))
])
# ä¾‹å¦‚, è°ƒç”¨ 
item1 = pd.read_csv(path.join(self.dataset_path, 'item_properties_part1.csv'))
item2 = pd.read_csv(path.join(self.dataset_path, 'item_properties_part2.csv'))
# å¯ä»¥é€šè¿‡å¦‚ä¸‹æ–¹æ³•, åˆ é™¤å˜é‡ä»¥é‡Šæ”¾å†…å­˜
del item1
del item2
# éœ€è¦è¯´æ˜çš„æ˜¯, ä¸€èˆ¬è°ƒç”¨ del ä¹‹å, ä¸ä¼šç«‹å³é‡Šæ”¾å†…å­˜, éœ€è¦è°ƒç”¨ gc. collect è¿›è¡Œå†…å­˜å›æ”¶:
import gc 
gc.collect()

#  æ­¤å¤–,   å¯ä»¥é‡‡ç”¨ chunksize åˆ†å—è¯»å–å’Œåˆå¹¶, è¿™æ ·æ—¢èƒ½èŠ‚çœå†…å­˜ï¼Œä¹Ÿèƒ½é¿å…åœ¨å†…å­˜ä¸­é•¿æœŸä¿ç•™å¤§æ•°æ®é›†çš„å¤šä¸ªå‰¯æœ¬, è¿›ä¸€æ­¥é™ä½å†…å­˜å ç”¨
chunks1 = pd.read_csv(path.join(self.dataset_path, 'item_properties_part1.csv'), chunksize=10000)
chunks2 = pd.read_csv(path.join(self.dataset_path, 'item_properties_part2.csv'), chunksize=10000)
self.item_properties_data = pd.concat([chunk for chunk in chunks1] + [chunk for chunk in chunks2])
# éœ€è¦è¯´æ˜, ä¸Šè¿°æ–¹æ³•å®é™…ä¸Šæ˜¯é‡‡ç”¨æ—¶é—´æ¢å–ç©ºé—´, å®é™…åŠ è½½ä¼šæ¯”è¾ƒæ…¢
```


### (5) è¿­ä»£å™¨å¯¹è±¡å’Œ next() ç”¨æ³•
ä¸€èˆ¬ range() å¯¹è±¡æ˜¯ä¸€ä¸ª range å¯¹è±¡, è€Œ iter(range)è¿­ä»£å™¨å¯ä»¥å°† range è½¬æ¢ä¸ºè¿­ä»£å™¨å¯¹è±¡ã€‚

`next()` ç”¨äºè¿­ä»£å™¨ä¸­è·å–ä¸‹ä¸€ä¸ªå…ƒç´ , å¦‚æœè¾¾åˆ°æœ«å°¾åˆ™æŠ›å‡º StopIteration å¼‚å¸¸ 
```python 
# è·å–ä¸‹ä¸€ä¸ªå…ƒç´ 
numbers = [1, 2, 3, 4, 5]
numbers_iter = iter(numbers)
print(next(numbers_iter))  # è¾“å‡ºï¼š1
print(next(numbers_iter))  # è¾“å‡ºï¼š2
```

å¦‚æœæ˜¯è¿­ä»£å™¨å¯¹è±¡, åˆ™å¿…é¡»å®ç° `__iter__()` å’Œ `__next__()` ä¸¤ä¸ªæ–¹æ³•
- `__iter__()`æ–¹æ³•ï¼šè¿”å›è¿­ä»£å™¨å¯¹è±¡æœ¬èº«ã€‚
- `__next__()`æ–¹æ³•ï¼šè¿”å›è¿­ä»£å™¨å¯¹è±¡çš„ä¸‹ä¸€ä¸ªæ•°æ®å…ƒç´ ï¼Œå¦‚æœæ²¡æœ‰å…ƒç´ å¯è¿­ä»£ï¼Œåˆ™æŠ›å‡º`StopIteration`å¼‚å¸¸ã€‚ä¾‹å¦‚å®šä¹‰ MyIterator è¿­ä»£å™¨å¯¹è±¡ 
```python
class MyIterator:
    def __init__(self, data):
        self.data = data
        self.index = 0

    def __iter__(self):
        return self

    def __next__(self):
        if self.index >= len(self.data):
            raise StopIteration
        result = self.data[self.index]
        self.index += 1
        return result
numbers = [1, 2, 3, 4, 5] 
my_iter = MyIterator(numbers) 

for num in my_iter:  
	print(num)   # å®é™…ä¸Šæ˜¯ä»next è¿­ä»£å™¨æ–¹æ³•ä¸­è·å–åˆ°çš„numå¯¹è±¡
```

## å››ã€Python å®˜æ–¹åº“ç”¨æ³•æ•´ç†
åˆ—å‡ºæŸä¸ªç›®å½•ä¸‹çš„æ–‡ä»¶ `dir(tensorflow)` 
è·å–encoding å‡½æ•°:
isinstance(value, dict)

Python ä¸­ä¼ å€¼æ˜¯æŒ‰ç…§å¼•ç”¨ä¼ é€’çš„, è€Œä¸ºäº†å€¼ä¼ é€’, ä¸€èˆ¬é‡‡ç”¨ copy.deepcopy() æ–¹æ³• (.copy() è¿”å›çš„ä¹Ÿåªæ˜¯æµ…æ‹·è´)
```python
a = [1,2]
b = a
b.append(3)
>>> a
[1, 2, 3]
```

### (1) æœ€å¸¸è§ä½¿ç”¨
#### 1) printæ ¼å¼æ§åˆ¶å’Œè¿›åˆ¶è½¬æ¢
```python
x = 1
y = 2
print(f'x = {x:.3f}, z = {x+y:.3f}')  # ç›´æ¥åµŒå…¥å¼æ ¼å¼æ§åˆ¶ 
print('score:{:.3f}\n'.format(score))  # é‡‡ç”¨å­—ç¬¦ä¸²çš„ .format æ§åˆ¶ 
```

å…¶ä¸­ç¬¬äºŒä¸ªæ˜¾ç¤º z = 3.00, å³é€šè¿‡string ä¸­çš„ f å®ç°äº†æ ¼å¼æ§åˆ¶;
è¿›åˆ¶è½¬æ¢å¸¸ç”¨å‡½æ•°
```python
bin()
oct()
int()
hex()
```
å½“å…¶ä»–æ•°å­—è½¬æ¢æˆå¦å¤–çš„è¿›åˆ¶æ—¶, åŠ ä¸Š0b,0o, æ— å‰ç¼€, ohå³å¯
int('10110001',2) -> 177,  int(0b10110001)
bin(0xbe) # å¯¹äºä½¿ç”¨å…¶ä»–è¿›åˆ¶

','.split å’Œ .splitlines() æ–¹æ³•,å¯ä»¥è¿”å›åˆ—è¡¨å¼çš„è¿­ä»£å¯¹è±¡ã€‚

åˆ©ç”¨Pythonçš„å¹¿æ’­æœºåˆ¶, å¯ä»¥å°† ä¸‹é¢çš„æ•´ä¸ªéƒ¨åˆ†ç¼©å†™ä¸ºä¸€å¥:
```python
# cnt_mat = np.mat(np.zeros((targets.size, decisions.size))) # number of samples of each class for each decision attribute 
# for c in range(targets.size):  
#     for d in range(decisions.size):  
#         tar = targets[c]  
#         dec = decisions[d]  
#         cnt_mat[c,d] = np.sum(counts_arr[(decision_arr == dec) & (target_arr == tar)])

# æ­£ç¡®çš„ç®€ä»‹å†™æ³•å¦‚ä¸‹ : 
cnt_mat = np.array([  
    [np.sum(counts_arr[(decision_arr == dec) & (target_arr == tar)]) for dec in decisions]  
    for tar in targets  
])
```

ä¸‹é¢çš„ä¾‹å­ç»™å‡ºäº†<b><mark style="background: transparent; color: orange">åˆ©ç”¨ any ç»“åˆç”Ÿæˆå™¨è¡¨è¾¾å¼, å®ç°åˆ¤æ–­ä¸¤ä¸ªé›†åˆæ˜¯å¦æœ‰é‡å å…ƒç´ , åŒæ—¶é€‚ç”¨äºç¨€ç–çŸ©é˜µ</mark></b>:
```python
a = [1, 2, 3]  
b = [4, 5, 6]  

# ä½¿ç”¨ any å‡½æ•°åˆ¤æ–­é‡å   
if any(item in b for item in a):  
    print("æœ‰é‡å å…ƒç´ ")  
else:  
    print("æ²¡æœ‰é‡å å…ƒç´ ")
```

#### 2) æ•°æ®ç±»å‹å’ŒåŸºæœ¬è¿ç®—
id(a) å¯ä»¥è¿”å›å¯¹åº”çš„å­˜å‚¨åœ°å€; å¯¹äº ndarray.copy() å¯ä»¥è¿”å›å…¶ä»–å‰¯æœ¬;

```python title:æ£€æŸ¥å™¨
hasattr(X, "ndim")   # æ£€æŸ¥æŸä¸ªç±»å¯¹è±¡æ˜¯å¦å…·æœ‰æŸç§å±æ€§: hasattr
isinstance(X, list)    #  æ£€æŸ¥æŸä¸ªå¯¹è±¡æ˜¯å¦æ˜¯æŸä¸ªç±»:isinstance 
```
åˆ—è¡¨æ‹¼æ¥ç›´æ¥ä½¿ç”¨ + è¿›è¡Œ  `b =  a + item` 

python è‡ªå¸¦äº†å¤æ•°ç±»å‹å’Œ bytes æ•°æ®ç±»å‹, é‡‡ç”¨ j è¡¨ç¤ºå¤æ•° 
```python
b =  1 + 2j
type(b)   # complex 
b.conjugate()   # å…±è½­ 
b.imag()
b.real()              # å®éƒ¨
d, m = divmod(3, 2)    # è¿”å› x/y , x%y

c = bytes(12)   # bytes æ•°æ®ç±»
bytes("ä½ å¥½",encoding="utf-8")
```

åœ¨ python ä¸­, C è¯­è¨€çš„æ•´é™¤(%)é‡‡ç”¨ `//` è¿›è¡Œ,  åŒæ—¶æ¥å— `nan` å’Œ `inf`, å®šä¹‰ 0\*\*0 = 1 ä¾‹å¦‚: 
``` python 
5.2 // 2  #  2
d = float("inf") ;  - d
d = float("nan")
```

```python
math.trunc(x);   # å–æ•´æ•°éƒ¨åˆ†
round(x, n);    # å– n ä½å°æ•°éƒ¨åˆ† 
math.floor  | math.ceil()
```

#### 3) åˆ—è¡¨æ“ä½œå’Œä¸‹æ ‡éå†æŒ‡å®š 

`np.unique(cluster_labels).sort()` 
è¯´æ˜Â `sort()`Â æ–¹æ³•æ˜¯ä¸€ä¸ªåŸåœ°æ“ä½œï¼Œè¿”å›Â `None`ï¼Œå¹¶ä¸”å®ƒå¹¶ä¸æ˜¯åœ¨Â `np.unique()`Â çš„ç»“æœä¸Šæ“ä½œ 

åˆ‡ç‰‡å¯¹è±¡ slice() ç›´æ¥é€šè¿‡ slice() åˆ›å»º, å¯ä»¥ä½œç”¨äº np ç­‰ç­‰å¯¹è±¡ã€‚
```python 
s = slice(1,5,2) 
a[s]
# å®é™…ä¸Šç­‰åŒäº a[1:5:2]
```

å¦‚æœæˆ‘ä»¬éœ€è¦<b><mark style="background: transparent; color: orange">åˆ©ç”¨ä¸¤ä¸ªå‘é‡å»ºç«‹ä¸€ä¸€å¯¹åº”çš„å­—å…¸, å¾€å¾€é‡‡ç”¨ dict(zip()) çš„æ–¹å¼, ä¾‹å¦‚ä¸‹æ–¹æ‰€ç¤º:</mark></b>
```python
a = [1, 2, 3]  
b = [4, 5, 6]  
c = dict(zip(a, b))  
```

```python
x[i]
x[i:j]
x[i:j:k]   # ä» x å¼€å§‹ æ¯éš” j å–ä¸€ä¸ªå–åˆ° k  
s = ['a','b','c']
# å¸¸è§çš„å‡½æ•°å¦‚ä¸‹: 
s.count('a') 
s.index('b')   # ç¬¬ä¸€ä¸ªä¸‹æ ‡
s.index('b', 1,2)  # åœ¨æŸä¸ªèŒƒå›´å†…çš„ç¬¬ä¸€ä¸ªä¸‹æ ‡
s.append()  #  æ·»åŠ å…ƒç´  
s.extend()   #  ç›´æ¥æ·»åŠ å¸¦æœ‰å…ƒç´ çš„åˆ—è¡¨ 
s.insert(4,'d')   # æ’å…¥å…ƒç´  
s.pop()   | s.pop(e)   # e å¯ä»¥æŒ‡å®šå…ƒç´ 
s.remove(x)
s.reverse()     # å€’åº 
s.clear() 
s.copy()  
sorted(s)   # æ’åº 
```

zip è·¨æ•°ç»„è¿­ä»£:
```python
a_arr = [1, 2, 3] b_arr = ['a', 'b', 'c'] 
for a, b in zip(a_arr, b_arr): 
	print(a, b)
```

é‡‡ç”¨  groupby æ–¹æ¡ˆ, å‡å°‘å¤šæ¬¡å¯¹å¤§å‹æ•°æ®é›†çš„å¾ªç¯æ‰«æ: 
`grouped`Â è¿”å›çš„æ˜¯ä¸€ä¸ª `Series`Â å¯¹è±¡ï¼ˆé€šè¿‡Â `groupby`Â å’ŒÂ `size`Â æ–¹æ³•ç”Ÿæˆï¼‰ï¼Œä»¥ä¸‹æ˜¯ä¸€äº›å¸¸ç”¨å±æ€§:
1. **`index`**ï¼šè¿”å›Â `Series`Â çš„ç´¢å¼•ï¼Œå…¶åŒ…å«åˆ†ç»„çš„é”®ã€‚
2. **`values`**ï¼šè¿”å›Â `Series`Â çš„å€¼ï¼Œä»¥ NumPy æ•°ç»„çš„å½¢å¼è¿”å›ã€‚
3. **`dtype`**ï¼šè¿”å›æ•°æ®ç±»å‹ã€‚
4. **`name`**ï¼šè¿”å›Â `Series`Â çš„åç§°ï¼Œå¦‚æœåœ¨åˆ›å»ºæ—¶æŒ‡å®šäº†åç§°çš„è¯ã€‚
5. **`shape`**ï¼šè¿”å›Â `Series`Â çš„å½¢çŠ¶ï¼ˆè¡Œæ•°ï¼Œï¼‰ã€‚
6. **`size`**ï¼šè¿”å›Â `Series`Â ä¸­çš„å…ƒç´ æ€»æ•°ã€‚
7. **`count()`**ï¼šè®¡ç®—é NA/null å€¼çš„æ•°é‡ã€‚
8. **`sum()`**ã€**`mean()`**ã€**`max()`**ã€**`min()`**Â ç­‰ï¼šè¿”å›åŸºäºåˆ†ç»„åçš„ç»Ÿè®¡ä¿¡æ¯ã€‚

ä¾‹å¦‚å¯¹äºä»¥ä¸‹æºç , ç»Ÿè®¡æ¯ä¸ª itemid å’Œ visitor id å‡ºç°çš„æ¬¡æ•°, å¹¶æ„å»ºç¨€ç–çŸ©é˜µï¼Œ åŸå§‹é”™è¯¯ä¸”æ— æ³•è¿è¡Œçš„ä»£ç å¦‚ä¸‹: 
```python
itms = data.itemid.unique()  
usrs = data.visitorid.unique()  
# generate a unique key  
unique_pairs = set(zip(data.itemid, data.visitorid))  
# num of the opertation of the specific user for specific item is the value  
nums = [  
    data.loc[(data.itemid == pair[0]) & (data.visitorid == pair[1])].shape[0]  
    for pair in unique_pairs
]
# è®¡ç®—ä¸‹æ ‡
vid = [......] # è·å– nums ä¸­æ¯ä¸€ä¸ªçš„ä¸‹æ ‡
uid = [......] # è·å– usrs ä¸­æ¯ä¸€ä¸ªçš„ä¸‹æ ‡

# æ„å»º user ç¨€ç–çŸ©é˜µ 
usr_matrix = csr_matrix(  
    (nums,(usrs, itms)),  
    shape=(max(usrs), max(itms)), 
dtype=np.int32)
```
ä¸Šè¿°ä¸­çš„ nums ä¸€å¥å®é™…ä¸Šæ¯æ¬¡éƒ½ä¼šéå†æ•´ä¸ªçŸ©é˜µæ¥æŸ¥è¯¢æŸä¸ªå…ƒç´ , å®é™…ä¸Šä¼šæ¶ˆè€—å¤§é‡çš„æ—¶é—´;

å®é™…å»ºç«‹ UserCF çš„ SVD åˆ†è§£çŸ©é˜µæ—¶, ä¸éœ€è¦å°† user_id å¦åšå˜æ¢, å¯ç›´æ¥ä½œä¸ºä¸‹æ ‡.
å¯ä»¥é‡‡ç”¨ groupby è¿›è¡Œä¼˜åŒ–ä¸Šè¿°ä»£ç , å®é™…ä¸Šä¼šç”Ÿæˆå¦‚ä¸‹çŸ©é˜µ:
![[attachments/Pasted image 20241118194532.png|150]]
å…¶ä»£ç å¦‚ä¸‹: æ¯”è¾ƒé‡è¦çš„æ˜¯å…ˆè½¬æ¢ä¸º dict, è·å–å…¶ values å¹¶è½¬æ¢ä¸º list 
```python
# generate the event based on the user provided and the operation
grouped_nums = data.groupby(['visitorid','itemid']).size()  
# calculate the index  
rid = [v for (v, i) in grouped_nums.index]  
cid = [i for (v, i) in grouped_nums.index]  
nums_dict = grouped_nums.to_dict()           # change the data to dict  
data_values = np.array(list(nums_dict.values()))   # change its values to array (must use list first)  
  
usr_matrix = csr_matrix(  
    ( data_values, (rid, cid)),  
    shape=(np.max(data.visitorid) + 1, np.max(data.itemid) + 1),  
dtype=np.int32)
```
è¯¥ä»£ç æ›´åŠ ç®€æ´åŒæ—¶, ä¹Ÿå‡å°‘äº†å¤§é‡ä¸å¿…è¦çš„è¿ç®—,  æå¤§æé«˜äº†é€Ÿåº¦å’Œæ•ˆç‡


#### 4. ç”¨é”®åˆ—è¡¨å–å¤šä¸ªå­—å…¸ä¸­çš„å€¼ç»„æˆåˆ—è¡¨
æ–¹æ³•ä¸€æ˜¯åˆ—è¡¨æ¨å¯¼å¼, ä¾‹å¦‚:
```python
visitor_data = ["1212931", "143794"]  # å­˜å‚¨ user id 
usr_idx_list = [self.usr_dict[id] for id in visitor_data] #  ç”¨å­å…¸å°† user id æ˜ å°„ä¸ºä¸‹æ ‡åˆ—è¡¨åè¿”å› 
```

å°†å­—å…¸çš„é”®å€¼åºåˆ—è½¬æ¢ä¸ºæ•°ç»„:
```python
tmp = np.array(list(item_dict.keys()))
```


#### 5. å­—å…¸æ‹¼æ¥, æ›´æ–°
åœ¨ Python çš„å­—å…¸æ„é€ ä¸­ï¼ˆå¦‚ `{key: value}`ï¼‰ï¼Œ**key å¿…é¡»æ˜¯å”¯ä¸€çš„**ã€‚å¦‚æœåœ¨æ„é€ è¿‡ç¨‹ä¸­æœ‰é‡å¤çš„ `visitorid`ï¼ˆå³é‡å¤çš„ keyï¼‰ï¼Œåå‡ºç°çš„å€¼ä¼šè¦†ç›–ä¹‹å‰çš„å€¼ã€‚ä¹Ÿå°±æ˜¯è¯´ï¼Œå¯¹äº `visitorid: labels` çš„æ˜ å°„ï¼Œå¦‚æœ `visitorid` ç›¸åŒè€Œ `labels` ä¸åŒï¼Œæœ€ç»ˆå­—å…¸ä¼šåªä¿ç•™æœ€åä¸€æ¬¡å‡ºç°çš„ `labels` å€¼ã€‚

TheÂ `update()`Â method inserts the specified items to the dictionary.

```python
car = {  
Â Â "brand":Â "Ford",  
Â Â "model":Â "Mustang",  
Â Â "year":Â 1964  
}  
  
car.update({"color":Â "White"})  
print(car)
```

ä¾‹å¦‚, å°† usr_dict_new ä¸­æ¯ä¸€é¡¹ä½œä¸ºæ–°çš„é¡¹
```python
# æ›´æ–° usr_dict
new_usrs = np.unique(user_data_new)
usr_num = len(self.usr_dict)  # å½“å‰ç”¨æˆ·æ•°é‡
usr_dict_new = {usr: idx + usr_num for idx, usr in enumerate(new_usrs) if usr not in self.usr_dict}
self.usr_dict.update(usr_dict_new)
```

```python
# there may be new user id, so we update the dictionary here to allocate index to new usrs  
unique_users = np.unique(visitor_data)  
new_usrid = unique_users[~np.isin(unique_users, list(self.usr_dict.keys()))]  
new_usr_dict = { v : i+len(self.usr_dict) for i, v in enumerate(new_usrid)}  
usr_dict = copy.deepcopy(self.usr_dict)  
usr_dict.update(new_usr_dict)  
  
usr_idx_list = [usr_dict[idx] for idx in visitor_data]   # transform the usrid to index  
labels_result = [labels[idx] for idx in usr_idx_list]  
np.array(labels_result)
```


### (2) Python ä¸­çš„å‡½æ•°å®šä¹‰
#### 1) æŒ‡å®šå‡½æ•°è¾“å…¥å’Œè¿”å›ç±»å‹ 
ä¸ä½¿ç”¨çš„å‚æ•°å¯ä»¥é‡‡ç”¨ _ ä»£æ›¿, å¦‚ `_ = plt.show()` 
åœ¨å‡½æ•°ç¼–å†™æ—¶, å¯ä»¥æŒ‡å®šè¾“å…¥çš„æ ¼å¼ç±»å‹, å…·ä½“æ–¹æ³•å¦‚ä¸‹:
```python 
def set_axis(axes:matplotlib.axes.Axes, xlabel:str, ylabel:str, xlim, ylim, xscale, yscale, legend):  
    axes.set_xlabel(xlabel);    axes.set_ylabel(ylabel)  
    axes.set_title(title);
```

æ–¹æ³•æ˜¯åœ¨ def ååŠ ä¸Š `-> ç±»å‹` æŒ‡å®šè¿”å›ç±»å‹, å¦‚æœæ²¡æœ‰è¿”å›ç±»å‹, åˆ™è®¤ä¸ºæ˜¯ None.
```python
class A:
	def __init__(self) -> None:
		A.name = "wreg"
		pass
	def sum(a:int, b:int) -> int:
		return a + b
```

å¦‚æœæ˜¯è¿”å›å¤šä¸ªæŒ‡å®šç±»å‹çš„å‚æ•°, åˆ™å¯ä»¥ä½¿ç”¨:
```python
def generate_sample(self, W, b) -> tuple [int, int]:
    # ä½ çš„ä»£ç 
    return X, y
```

#### 2) è‡ªå®šä¹‰è¿­ä»£å™¨å’Œè¿­ä»£ç±»å‹
åŸºæœ¬çš„æ–¹æ³•æ˜¯ä½¿ç”¨ yield è¿›è¡Œè¿­ä»£è¿”å›, 
```python
def get_dataloader():
	indics = list(range(0, 100))
	batch_indices =   torch.tensor( indices[i : i + self.batch_size] )  # if batch size = 10,  return the first 10 element at first. 
	yield self.x[batch_indices], self.y[batch_indices]

# ä½¿ç”¨æ–¹æ³•å¦‚ä¸‹:
X,y = next(iter(data.get_dataloader()))
```

```python
iter_dict = iter(dic.items())
next(iter_dict) 
```

#### 3) ç±»ä¸­å‡½æ•°çš„ç§æœ‰åŒ–
åœ¨ Python ä¸­ï¼Œå¯ä»¥é€šè¿‡åœ¨å‡½æ•°åå‰åŠ ä¸ŠåŒä¸‹åˆ’çº¿Â `__`Â æ¥å°†å…¶å®šä¹‰ä¸ºç§æœ‰æ–¹æ³•ã€‚ç§æœ‰æ–¹æ³•åªèƒ½åœ¨ç±»çš„å†…éƒ¨è®¿é—®ï¼Œä¸èƒ½åœ¨ç±»çš„å¤–éƒ¨ç›´æ¥è°ƒç”¨ã€‚

#### 4) å‡½æ•°è§£åŒ…å­—å…¸å’Œä¼ å‚
åœ¨ Python ä¸­ï¼Œ`**context` è¯­æ³•å…è®¸å°†==**å­—å…¸ä¸­çš„é”®å€¼å¯¹è§£åŒ…æˆå…³é”®å­—å‚æ•°ä¼ é€’ç»™å‡½æ•°**==ã€‚è¿™æ ·å¯ä»¥è½»æ¾åœ°å°†å¤šä¸ªå‚æ•°ä¼ é€’åˆ°æ¨¡æ¿ä¸­ã€‚

åœ¨ `render_template` æ–¹æ³•ä¸­ï¼Œ`context` å­—å…¸å¯ä»¥åŒ…å«å¤šä¸ªé”®å€¼å¯¹ï¼Œè¿™äº›å¯¹ä¼šåœ¨è°ƒç”¨ `render_template` å‡½æ•°æ—¶è§£åŒ…ã€‚å‡è®¾æœ‰ä¸€ä¸ªå­—å…¸:
```python
context = {
    'title': 'My Page',
    'user': 'Alice',
    'items': [1, 2, 3],
}
def render_template(self, template_name, context):  
    return render_template(self.get_template_name(), **context)
```

æ­¤æ—¶,  åœ¨æ¨¡æ¿ `view1.html` ä¸­ï¼Œå°±å¯ä»¥ç›´æ¥ä½¿ç”¨ `title`ã€`user` å’Œ `items` è¿™äº›å˜é‡ã€‚

### (3) å¸¸ç”¨çš„å…³é”®å­—
yield å…³é”®å­— : ä½œç”¨æ˜¯ä¿å­˜å½“å‰ç¨‹åºæ‰§è¡ŒçŠ¶æ€, è™½ç„¶å¯ä»¥ç†è§£ä¸º return æ“ä½œ, ä½†æ˜¯yieldæ‰§è¡Œæ—¶è¿˜ä¿å­˜äº†å½“å‰çš„æ‰§è¡Œå†…å®¹, å†ä¸€æ¬¡è°ƒç”¨è¿™ä¸ªå‡½æ•°æ—¶ï¼Œä»–ä¼šæ‰¾åˆ°ä½ åœ¨æ­¤å‡½æ•°ä¸­çš„yieldå…³é”®å­—ï¼Œç„¶åä»yieldçš„ä¸‹ä¸€å¥å¼€å§‹æ‰§è¡Œã€‚
```python
def generator():
    for i in range(10):
        yield i * i   # éœ€è¦å•ä¸ªé€ä¸€è¿”å› 
gen = generator()
print(gen)
```

ä¾‹å¦‚è¯»å–å¤§å‹æ–‡æœ¬æ–‡ä»¶çš„æ–¹æ¡ˆ:
```python
with open("file.txt", "rb") as f:
	while(True):
		line = f.readline()
		if  content == "":  # åˆ¤æ–­æ–‡ä»¶æœ«å°¾
			break
		yield content
```

[assert ç”¨æ³•](https://blog.csdn.net/qq_42269354/article/details/89476880) å³åé¢å¸ƒå°”å¿…é¡»ä¸ºçœŸ,å¦‚æœä¸ºå‡åˆ™è§¦å‘å¼‚å¸¸ã€‚

map å‡½æ•°: map æ˜¯ä¸€ä¸ªå†…ç½®å‡½æ•°, ç”¨äºå°†ä¸€ä¸ªå‡½æ•°åº”ç”¨åˆ°å¯è¿­ä»£å¯¹è±¡çš„æ¯ä¸ªå…ƒç´ ä¸Šã€‚å¦‚å›¾æ‰€ç¤º:
```python
def square(x):
    return x * x

numbers = [1, 2, 3, 4, 5]
squared_numbers = map(square, numbers)
print(list(squared_numbers))  # è¾“å‡º: [1, 4, 9, 16, 25]
```

### (4) Collections å®¹å™¨ç±»
collection æä¾›äº†åŒ…æ‹¬åŒç«¯é˜Ÿåˆ—(deque)ç­‰å¤šç§æ•°æ®ç±»å‹
```python
from colloection import namedtuple,deque
```
å‚è€ƒ [python å®˜æ–¹æ–‡æ¡£](https://docs.python.org/3/library/collections.html)

```python
def forward(self, input: Tensor, target: Tensor) -> Tensor: return F.mse_loss(input, target, reduction=self.reduction)	
```

### (5) Python ç»§æ‰¿çš„ä½¿ç”¨
ä¸‹é¢è®²è§£äº†ç»§æ‰¿ torch.nn.Module ç±»çš„æ–¹æ³•, é¦–å…ˆéœ€è¦åœ¨ç±»ååé¢æ‹¬å·åŠ ä¸Šç»§æ‰¿çš„ç±», å¹¶ä¸”ä½¿ç”¨ super() è°ƒç”¨çˆ¶ç±»çš„ \_\_init\_\_()å‡½æ•° 
```python
import torch  
import numpy as np  
import time  
import torch.nn as nn  
from deeplearning_util_functions import plot_figure  
from matplotlib import pyplot as plt  
  
class Regression_Module(nn.Module):   # if class is in bracket, it will inherit this class  
    def __init__(self, learning_rate:float=0.001) :  
        # for the  method inherit from other method: use:  
        super().__init__()  # inherit the  init method of the parent  
  
        self.learning_rate = learning_rate  
        self.wrapper('learning_rate', 0.2)  
        print(self.learning_rate)  
        print(self.cpu())  
        print(torch.cpu.current_device())  
    def wrapper(self, attr:str, value):  
        setattr(self, attr, value)  
        assert hasattr(self, 'learning_rate') # refer to https://blog.csdn.net/qq_42269354/article/details/89476880  
    def __call__(self, *args, **kwargs):  
        print("executing the method")  
  
a = Regression_Module(0.01)   # create a new class  
a()  # call the __call__ method
```

éœ€è¦è¯´æ˜, python å…è®¸å°†ä¸€ä¸ªç±»åƒä¸€ä¸ªå®ä¾‹ä¸€æ ·è°ƒç”¨, å®é™…ä¸Šæ˜¯è°ƒç”¨äº†å…¶ä¸­çš„ `__call__` æ–¹æ³•
```python
assert hasattr(u.name, '__call__')    # åˆ¤æ–­æ˜¯å¦å¯ä»¥è°ƒç”¨
u()   # è°ƒç”¨å…¶ä¸­çš„ __call__ æ–¹æ³•
```

### (6) html å’Œ xml çš„è§£ææ–¹æ³• 
å¸¸è§çš„ html å»é™¤ html æ ‡ç­¾, å¯ä»¥é‡‡ç”¨ lxml åº“
```python
from lxml import etree, html  
  
file_path = "html/UserManual_Bayesian.html"  
  
with open(file_path, 'rb') as fp:  
    contents =  fp.read()  
    text_doc = html.document_fromstring(contents)  # parse the file  
    print(text_doc.text_content())
```

å¦‚æœæ˜¯æå– html ä¸­çš„çº¯æ–‡æœ¬å†…å®¹, åˆ™é‡‡ç”¨ BeautifulSoup
```python
from bs4 import BeautifulSoup
with open("./html/" + file, "rb") as f:  
    contents = f.read()  
    text_content = BeautifulSoup(contents, parser="html.parser", features='lxml').get_text()
```

## äº”ã€os åº“å¸¸ç”¨æ“ä½œ

```python
file_list = os.listdir(dir1)
for path in file_list:
	print(path)

os.path.exists(dir) 
os.makedir(dir) 
```

æ‰§è¡ŒshellæŒ‡ä»¤
```python
import subprocess  
print(subprocess.run("ls /", shell=True).stdout)
```


```python 
import importlib  
import sys  
  
importlib.reload(sys)  
print(sys.getdefaultencoding())
```


### è®¾ç½®å½“å‰å·¥ä½œç›®å½•
åœ¨ä½¿ç”¨ PowerShell å’Œ CMD è¿è¡Œ Python è„šæœ¬æ—¶ï¼Œå¯èƒ½è¡Œä¸ºä¸ä¸€è‡´, å½“é‡‡ç”¨ to_csv("Hello, world.csv") æ—¶, å¦‚æœå½“å‰å·¥ä½œç›®å½•å¤„äºå…¶ä»–ç›®å½•, åˆ™ to_csv ä¼šå»ºç«‹åˆ°å…¶ä»–ç›®å½•ä¸‹, è€Œè§£å†³çš„åŠæ³•æ˜¯é€šè¿‡os.chdir å®šä½åˆ°å½“å‰ç›®å½•:

åœ¨è„šæœ¬ä¸­æ·»åŠ æ‰“å°å½“å‰å·¥ä½œç›®å½•çš„ä»£ç ï¼š
 ```python
 import os
 print("Current working directory:", os.getcwd())
 # è®¾ç½®å·¥ä½œç›®å½•ä¸ºè„šæœ¬æ‰€åœ¨çš„ç›®å½• 
 os.chdir(os.path.dirname(os.path.abspath(__file__)))
 ```
2. è„šæœ¬ä¸­æŒ‡å®šä¿å­˜è·¯å¾„ä¸ºç»å¯¹è·¯å¾„ï¼š
 ```python
 df.to_csv(r"C:\Users\Parrot\Desktop\KKX\output.csv", index=False)
 ```

é€šè¿‡ä¸Šè¿°æ­¥éª¤ï¼Œä½ å¯ä»¥æ‰¾åˆ° CMD å’Œ PowerShell è¡Œä¸ºä¸ä¸€è‡´çš„åŸå› ï¼Œå¹¶åŠ ä»¥ä¿®æ­£ã€‚å¦‚æœå·¥ä½œç›®å½•ä¸åŒæ˜¯ä¸»è¦åŸå› ï¼Œç¡®ä¿åœ¨è„šæœ¬ä¸­ä½¿ç”¨ç»å¯¹è·¯å¾„é€šå¸¸æ˜¯æœ€ç®€ä¾¿çš„è§£å†³æ–¹æ¡ˆã€‚


