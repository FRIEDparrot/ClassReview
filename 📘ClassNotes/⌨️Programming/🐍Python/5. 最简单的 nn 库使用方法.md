
```python
import matplotlib.pyplot as plt  
import numpy as np  
import torch  
from torchvision.datasets import mnist # 导入 pytorch 内置的 mnist 数据  
from torch import nn  
from torch.autograd import Variable  
from torch.utils.data import DataLoader  
  
# 使用内置函数下载 mnist 数据集  
train_set = mnist.MNIST('../data/mnist', train=True,  download=True)  
test_set  = mnist.MNIST('../data/mnist', train=False, download=True)  
  
def data_tf(x):  
    x = np.array(x, dtype='float32') / 255  
    x = (x - 0.5) / 0.5 # 标准化，这个技巧之后会讲到  
    x = x.reshape((-1,)) # 拉平成一维向量  
    x = torch.from_numpy(x)  
    return x  
  
# 载入数据集，申明定义的数据变换  
train_set = mnist.MNIST('../data/mnist', train=True,  transform=data_tf, download=True)  
test_set  = mnist.MNIST('../data/mnist', train=False, transform=data_tf, download=True)  
# show a image of the dataset  
  
# 使用 pytorch 自带的 DataLoader 定义一个数据迭代器  
train_data = DataLoader(train_set, batch_size=64,  shuffle=True)  
test_data  = DataLoader(test_set,  batch_size=128, shuffle=False)  
  
# 使用 Sequential 定义 4 层神经网络  
net = nn.Sequential(  
    nn.Linear(784, 400),  
    nn.ReLU(),  
    nn.Linear(400, 200),  
    nn.ReLU(),  
    nn.Linear(200, 100),  
    nn.ReLU(),  
    nn.Linear(100, 10)  
)  
  
# 定义 loss 函数  
criterion = nn.CrossEntropyLoss()  
optimizer = torch.optim.SGD(net.parameters(), 1e-1) # 使用随机梯度下降，学习率 0.1  
# 开始训练  
losses = []  
acces = []  
eval_losses = []  
eval_acces = []  
  
for e in range(20):  
    train_loss = 0  
    train_acc = 0  
    net.train()  
    for im, label in train_data:  
        im = Variable(im)  # 注意，这里使用Variable将  
        label = Variable(label)  
        # print(im.data.shape)     # 64*784  
        # print(label.data.shape)  # 64        # 前向传播  
        out = net(im)  
        loss = criterion(out, label)   # out是64 * 10和64的比较  
        # 反向传播  
        optimizer.zero_grad()  
        loss.backward()  
        optimizer.step()  
        # 记录误差  
        train_loss += loss.item()  
        # 计算分类的准确率  
        _, pred = out.max(1)  
        num_correct = float((pred == label).sum().item())  
        acc = num_correct / im.shape[0]  
        train_acc += acc  
  
    losses.append(train_loss / len(train_data))  
    acces.append(train_acc / len(train_data))  
    # 在测试集上检验效果  
    eval_loss = 0  
    eval_acc = 0  
    net.eval()  # 将模型改为预测模式  
    for im, label in test_data:  
        im = Variable(im)  
        label = Variable(label)  
        out = net(im)  
        loss = criterion(out, label)  
        # 记录误差  
        eval_loss += loss.item()  
        # 记录准确率  
        _, pred = out.max(1)  
        num_correct = float((pred == label).sum().item())  
        acc = num_correct / im.shape[0]  
        eval_acc += acc  
  
    eval_losses.append(eval_loss / len(test_data))  
    eval_acces.append(eval_acc / len(test_data))  
    print('epoch: {}, Train Loss: {:.6f}, Train Acc: {:.6f}, Eval Loss: {:.6f}, Eval Acc: {:.6f}'  
          .format(e, train_loss / len(train_data), train_acc / len(train_data),  
                  eval_loss / len(test_data), eval_acc / len(test_data)))
```

