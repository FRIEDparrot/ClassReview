在使用大批量数据进行训练时，确实可能因为显存占满而导致性能瓶颈。为了确保显存高效使用，关键是及时清理不必要的数据。以下是一些具体的措施：

![[attachments/Pasted image 20250616154748.png]]
### **1. 使用 `torch.no_grad()` 避免保存梯度**

如果在验证或评估阶段不需要计算梯度，可以使用 `torch.no_grad()` 包裹相关代码，避免显存占用。例如：

```python
with torch.no_grad():
    for data, target in dataloader:
        data, target = data.to(device), target.to(device)
        outputs = model(data)
```

---

### **2. 及时清理 GPU 显存**

使用 `torch.cuda.empty_cache()` 释放不再需要的显存。虽然 PyTorch 的动态显存管理会自动处理，但显存紧张时主动清理可能会有所帮助。例如：

```python
import torch

# 每完成一个 epoch 后清理显存
torch.cuda.empty_cache()
```

---

### **3. 确保中间变量释放**

PyTorch 中的某些操作会在显存中保存不需要的中间变量，比如保存梯度信息。为避免显存泄漏，可以：

- 确保所有未使用的变量及时删除。
- 使用 `del` 删除不需要的变量：

```python
del variable
torch.cuda.empty_cache()
```

---

### **4. 分离数据加载和模型计算**

使用 `DataLoader` 的 `pin_memory=True` 加速数据传输，同时避免显存中存储多余数据：

```python
DataLoader(
    dataset=train_dataset, 
    batch_size=batch_size, 
    shuffle=True, 
    pin_memory=True
)
```

---

### **5. 使用梯度累积减少批量大小对显存的压力**

将大批量拆分成若干小批量，累积梯度后再进行优化更新。例如：

```python
accumulation_steps = 4  # 累积的步数
optimizer.zero_grad()

for i, (data, target) in enumerate(dataloader):
    data, target = data.to(device), target.to(device)
    output = model(data)
    loss = criterion(output, target)
    loss = loss / accumulation_steps  # 梯度缩放
    loss.backward()
    
    if (i + 1) % accumulation_steps == 0:
        optimizer.step()
        optimizer.zero_grad()
```

这样有效减少了单次显存占用，同时保持整体的批量规模。

---

### **6. 减少模型规模或优化网络**

- 如果显存不足，可以尝试减少网络参数，比如：
    - 使用更少的特征通道。
    - 减少全连接层的规模。
- 或者使用混合精度训练 (`torch.cuda.amp`)：

```python
from torch.cuda.amp import GradScaler, autocast

scaler = GradScaler()

for data, target in dataloader:
    data, target = data.to(device), target.to(device)

    with autocast():  # 混合精度计算
        output = model(data)
        loss = criterion(output, target)

    scaler.scale(loss).backward()
    scaler.step(optimizer)
    scaler.update()
```

混合精度训练不仅减少显存占用，还能加速训练。

---

### **7. 限制 GPU 内存的最大分配**

在极端情况下，可以限制 PyTorch 使用的显存上限：

```python
torch.cuda.set_per_process_memory_fraction(0.8, device=0)  # 限制使用 80% 显存
```

---

### **总结**

通过及时清理不需要的数据、合理分配批量大小、使用混合精度等方法，可以在训练过程中更好地管理显存。结合 RTX 3090 的大显存容量，这些优化可以有效提升训练效率，同时避免因显存占满而导致崩溃。