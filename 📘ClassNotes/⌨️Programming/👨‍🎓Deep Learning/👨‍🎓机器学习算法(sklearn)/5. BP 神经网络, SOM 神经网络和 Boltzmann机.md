## ä¸€ã€BP ç¥ç»ç½‘ç»œç†è®º
### (1) BP ç¥ç»ç½‘ç»œåŸºæœ¬ç®€ä»‹
åˆå§‹çš„ç¥ç»ç½‘ç»œæ¨¡å‹æ˜¯MPæ¨¡å‹. å°†äººå·¥ç¥ç»å…ƒè§†ä¸ºä¸€ä¸ªäºŒå€¼å¼€å…³å…ƒä»¶ã€‚å¹¶æ ¹æ®ç»„åˆæ–¹å¼å¤„ç†é€»è¾‘è¿ç®—ã€‚
æœ€æ—©çš„æœ‰ä½¿ç”¨ä»·å€¼çš„ç¥ç»ç½‘ç»œæ¨¡å‹æ˜¯æ„ŸçŸ¥å™¨æ¨¡å‹ï¼ˆæ¢¯åº¦ä¸‹é™ä¹Ÿæ˜¯æ„ŸçŸ¥å™¨ç½‘ç»œï¼‰ã€‚è€ŒåæœŸå‘å±•çš„ RBF ç¥ç»ç½‘ç»œæ¨¡å‹å¯ä»¥å®¹æ˜“åœ°æ¨¡æ‹Ÿå‡ºä»»ä½•ä¸€ç§éçº¿æ€§æ•°æ®çš„å˜åŒ–è¶‹åŠ¿ã€‚

BP ç®—æ³•å³å¤šå±‚å‰é¦ˆç¥ç»ç½‘ç»œçš„å­¦ä¹ ç®—æ³•ã€‚ä¸€èˆ¬æ˜¯åˆ©ç”¨å¤–ç•Œçš„è¾“å…¥æ ·æœ¬çš„æ¬¡çº§ï¼Œ å¹¶é€šè¿‡ä¸æ–­è¿­ä»£ä¿®æ­£æƒé‡å‘é‡ï¼Œä½¿ç½‘ç»œè¾“å‡ºä¸æœŸæœ›ç›¸ç¬¦åˆã€‚<mark style="background: transparent; color: red">ä¸€ä¸ªåŸºæœ¬çš„ BP ç¥ç»ç½‘ç»œåˆ†ä¸ºå¦‚ä¸‹å‡ ä¸ªéƒ¨åˆ†</mark>:
1. è¾“å…¥å±‚
2. æ¿€æ´»å‡½æ•°å±‚ 
3. è¯¯å·®è®¡ç®— 
4. è¾“å‡ºå±‚ 
5. è¿­ä»£å…¬å¼

ä¸‹å›¾è¯´æ˜äº†å•ä¸ªç¥ç»å…ƒå’Œ BP ç½‘ç»œçš„åŸºæœ¬ç»“æ„ï¼Œ
![[Excalidraw/5. ç¥ç»ç½‘ç»œç†è®ºåˆæ­¥ 2024-09-29 15.49.56|600]]
è¾“å‡ºå±‚å³è¾“å…¥ä¸Šä¸€å±‚çš„æƒé‡å’Œä¸Šä¸€å±‚éƒ¨åˆ†çš„ä¹˜ç§¯ï¼Œç„¶åè¾“å‡ºåˆ†ç±»æ ‡ç­¾å‘é‡éƒ¨åˆ†ã€‚

### (2) BP ç½‘ç»œçš„åå‘ä¼ æ’­æœºåˆ¶
<b><mark style="background: transparent; color: blue">å’Œå¤šå±‚æ„ŸçŸ¥æœºä¸åŒ, BPç¥ç»ç½‘ç»œçš„æ¯ä¸€éƒ½è®¡ç®—ä¸æœŸæœ›ç»“æœçš„åå·®, å¹¶æŒ‰ç…§åå‘ä¼ æ’­çš„æ–¹æ³•å°†è¯¯å·®ä¼ é€’åˆ°ä¸Šä¸€å±‚ï¼Œ ç”¨äºä¿®æ­£ä¸Šä¸€å±‚çš„æƒé‡</mark></b>ã€‚
#### 1. æ­£å‘ä¼ æ’­
æ­£å‘ä¼ æ’­è¿‡ç¨‹ä¸­, è®¾è¾“å…¥ä¸º $i$ è¾“å‡ºä¸º $o$, éšè—å±‚ $h$, 
$$\text{net} =  w^{T} o +b$$
å…¶ä¸­, b ä¸ºé˜ˆå€¼, å®é™…ä¸Šä¹Ÿæ˜¯åœ¨ $x$ é¦–åˆ—åŠ å…¥å‡ä¸º 1 çš„å‘é‡; 

å®é™…ä¸ŠæŒ‰ç…§ä¸Šå›¾å³ä¾§çš„éƒ¨åˆ†: i~h, h~o ä¸­å„æœ‰ä¸€ç³»æƒ $w_{ih}, w_{ho}$, æ˜¯ä¸€ä¸ªå¸¦æœ‰ä¸¤ä¸ªæƒé‡å±‚çš„è¾“å…¥è¾“å‡ºç»“æ„ã€‚å¹¶ä¾æ¬¡ä¼ é€’è®¡ç®—ä¸º:
$$\Large  \boxed{h_{i} =  w_{ih} x_{i} + b_{h} \quad h_{o} =f_{1}(hi), \quad yi = w_{ho} \times  h_{o} + b_{o}  \quad  y_{o} = f_{2}(y_{i})}$$
å…¶ä¸­, æ¯ä¸€å±‚çš„ä¼ é€’å‡½æ•°(æ¿€æ´»å‡½æ•°)ä¸º:
$$f(x) = \frac{1}{1 + e^{-x}} = y$$
#### 2. è¯¯å·®è®¡ç®—
åœ¨è¯¯å·®è®¡ç®—ä¸­, é¦–å…ˆä¼š**è®¡ç®—ç½‘ç»œå®é™…è¾“å‡º $y_{o}$ å’ŒæœŸæœ›è¾“å‡º $y_d$ çš„å·®**ã€‚<mark style="background: transparent; color: red">å¹¶åˆ¤æ–­å·®æ˜¯å¦ä½äºå®¹é™</mark>, å¦‚æœé«˜äºå®¹é™ï¼Œåˆ™è¿›è¡Œè¯¯å·®åå‘ä¼ æ’­ã€‚å³å–:
1. è¯¯å·®å‘é‡
$$\text{err} =d_{o}- y_{o}$$
2. å…¨å±€è¯¯å·®å‡½æ•°
æˆ‘ä»¬åœ¨åé¢è®¡ç®—è¯¯å·®åå‘ä¼ æ’­æ—¶, å®é™…ä¸Šæ˜¯æœ€å°åŒ–å…¨å±€è¯¯å·®å‡½æ•°: 
$$e  = f_{\text{err}} = \frac{1}{2} \sum (d_{o} - y_{o})^{2}$$
#### 3. åå‘ä¼ æ’­
æˆ‘ä»¬å– dlogit å‡½æ•°ä¸º sigmoid å‡½æ•°çš„å¯¼å‡½æ•°:
$$f'(\text{net}) = \frac{1}{1 + e^{-\text{net}}} - \frac{1}{(1 + e^{-net})^{2}}  = y(1-y)$$
è¾“å‡ºå±‚çš„è¯¯å·®å¯¹äº$w_{ho}$çš„å¾®åˆ†å¯ä»¥å†™ä¸º:
$$\frac{\partial \text{e}}{\partial w_{ho}} = \frac{\partial \text{e}}{\partial y_{i}} \frac{\partial y_{i}}{\partial w_{ho}}$$
å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/æ¨å¯¼éƒ¨åˆ†/BP ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­è®¡ç®—.pdf|BP ç¥ç»ç½‘ç»œçš„åå‘ä¼ æ’­è®¡ç®—.pdf]]ï¼Œå¯ä»¥è·å–åˆ°æ¯ä¸€é¡¹çš„å¯¼æ•°:
$$\Large\boxed{\frac{\partial e}{\partial w_{ho}} = - \delta_{0} h_{o}\qquad  \frac{\partial e}{\partial w_{ih}} =  - \delta_{h} x_{i}}$$
å…¶ä¸­, è®¾ $\delta$ ä¸ºæ¯ä¸€é¡¹çš„æ¢¯åº¦, åˆ™æ ¹æ®ä¸‹å¼å¾—åˆ°<b><mark style="background: transparent; color: blue"></mark></b>ä¸º:
$$\boxed{\frac{\partial e}{\partial h_{o}}  = - \delta_{o}\qquad  \delta_{o} = (d-y_{o}) f_{2}'(y_{i})}\tag{1}$$
$$\boxed{\frac{\partial e}{\partial h_{i}} =  - \delta_{h}\qquad  \delta_{h} = - \delta_{0} w_{ho} f_{1}'(h_{i})}\tag{2}$$
å¹¶å¾—åˆ°æ¯ä¸€å±‚çš„æƒé‡è¿­ä»£æ›´æ–°å…¬å¼:
$$\boxed{\Large\begin{cases}
w_{ho} ^{N+1} = w_{ho}^{N} + \eta_{1} \cdot  \delta_{o} h_{o} \\
w_{ih}^{N+1} = w_{ih}^{N} +\eta_{2}  \cdot   \delta_{h} x_{i}
\end{cases}}$$
### (3) BP ç½‘ç»œçš„åŠ¨é‡å› å­ç®€ä»‹
é™¤äº†å­¦ä¹ ç‡ $\eta$, è¿­ä»£æ¬¡æ•° (max_iter) å’Œè¯¯å·®å®¹é™ (error_boundary), å¾€å¾€æˆ‘ä»¬è¿˜ä½¿ç”¨<mark style="background: transparent; color: red">åŠ¨é‡å› å­</mark>æ¥è¿›è¡Œ BP ç½‘ç»œçš„å‚æ•°è°ƒä¼˜ã€‚ä¸€èˆ¬å¯ä»¥å–ä¸º0.3å·¦å³; 

å¼•å…¥åŠ¨é‡å› å­çš„å¥½å¤„: æœ€æ—©çš„BPç®—æ³•åœ¨ä¿®æ­£æƒå€¼æ—¶, éœ€è¦**æŒ‰ç…§è¿­ä»£æ¬¡æ•° t çš„æ¢¯åº¦è¿›è¡Œè°ƒæ•´**ã€‚è€Œä¸è€ƒè™‘åœ¨ t-1 éƒ¨åˆ†çš„æ¢¯åº¦æ–¹å‘çš„å½±å“, <mark style="background: transparent; color: red">å¯¼è‡´ç½‘ç»œå‘ç”Ÿéœ‡è¡, æ”¶æ•›ç¼“æ…¢ç­‰ç­‰</mark>, è€Œ<mark style="background: transparent; color: red">åŠ¨é‡å› å­è€ƒè™‘åˆ†é… t æ—¶åˆ»å’Œ t-1 æ—¶åˆ»çš„æ¢¯åº¦</mark>; æ­¤å¤–ï¼Œ<u>æ²¡æœ‰é™„åŠ åŠ¨é‡å› å­æ—¶, ç½‘ç»œæœ‰å¯èƒ½é™·å…¥å±€éƒ¨æå°å€¼ã€‚</u>

å…·ä½“çš„åˆ†é…æ–¹æ³•æ˜¯è®¾åŠ¨é‡å› å­ä¸º $MC$ å¹¶**è®°å½•ä¸Šä¸€æ¬¡çš„æ¢¯åº¦å¤§å°**:
$$w_{ih}^{N+1} = w_{ih} + (1 - MC)\times  \eta \left. \frac{\partial e}{\partial w_{ih}}\right|_{t} + MC \times \eta \left. \frac{\partial e}{\partial w_{ih}} \right|_{t =  t-1}$$

å¦å¤–, ç”±äºç½‘ç»œçš„åˆå§‹æƒå€¼æ˜¯éšæœºé€‰å–çš„, BPç½‘ç»œå¯¹äºæƒé‡çš„åˆå§‹å€¼æ˜¯éå¸¸æ•æ„Ÿçš„,  å¯¼è‡´è¿­ä»£è¿‡ç¨‹ä¸­è¯¯å·®å‡½æ•°çš„è®¡ç®—ç»“æœä¹Ÿä¸ç›¸åŒ, å¾—åˆ°æ›²çº¿ä¹Ÿä¸ç›¸åŒã€‚

è¯¯å·®ä¿¡å·åå‘ä¼ æ’­è®¡ç®—è¿‡ç¨‹ä¸­, å‚è€ƒ(1),(2); é¦–å…ˆè®¡ç®— output å’Œ y_true çš„å·® err, å¹¶æ ¹æ® output = y, å¯ä»¥ç›´æ¥é‡‡ç”¨ $f_{2}'(y) = y(1-y)$ è®¡ç®—å‡ºè¾“å‡ºå±‚æ¢¯åº¦, ç„¶åç›´æ¥é‡‡ç”¨ $\text{err}* f_{2}'(x)$ ç›´æ¥å¾—åˆ° $\delta_{o}$ï¼Œç„¶åå³å¯ç›´æ¥é‡‡ç”¨ $\delta_o * h$ å¾—åˆ°ç¬¬ä¸€ä¸ªæ¢¯åº¦ $\frac{\partial e}{\partial w_{ho}}$ , åŒæ—¶è®°å½•è¿™ä¸ªæ¢¯åº¦ä»¥å¤‡åŠ¨é‡å› å­ä½¿ç”¨ã€‚

å¯¹äºå­¦ä¹ é€Ÿç‡çš„åŠ¨æ€è°ƒèŠ‚, ç­–ç•¥æ˜¯<mark style="background: transparent; color: red">åœ¨è¿­ä»£ä¸­æ£€éªŒæƒå€¼æ˜¯å¦å¯¼è‡´è¯¯å·®å‡½æ•°å€¼çš„é™ä½; å¦‚æœé™ä½, åˆ™è¯´æ˜å½“å‰çš„å­¦ä¹ é€Ÿç‡å¯ä»¥å¢åŠ , åˆ™é€‚å½“å¢åŠ ä¸€ä¸ªé‡; å¦‚æœä¸æ˜¯, åˆ™è¯´æ˜è°ƒæ•´è¿‡åº¦, æ­¤æ—¶å¯ä»¥é™ä½å­¦ä¹ é€Ÿç‡</mark>.

## äºŒã€è‡ªç»„ç»‡ç‰¹å¾æ˜ å°„ç¥ç»ç½‘ç»œ(SOM)
### (1) SOM ç½‘ç»œæ¡†æ¶
è‡ªç»„ç»‡æ˜ å°„ç¥ç»ç½‘ç»œ(Self-Organization Feature Map, SOM)æ˜¯æ ¹æ®ä»¿ç”Ÿæ€æƒ³è®¾è®¡çš„ä¸€ç±»ç¥ç»ç½‘ç»œ, ä¹Ÿç§°ä¸ºKohonen æ˜ å°„ï¼Œæ˜¯ä¸€ç§æ— ç›‘ç£å­¦ä¹ ç®—æ³•ï¼Œå¹¶ç”¨äºè§£å†³æ¨¡å¼è¯†åˆ«ç±»çš„é—®é¢˜ã€‚åŒæ—¶ï¼ŒSOMæ–¹æ³•ä¸éœ€è¦æä¾›é¢„å…ˆçš„èšç±»æ•°é‡ï¼Œè€Œæ˜¯ç”±ç½‘ç»œè‡ªåŠ¨è¯†åˆ«å‡ºæ¥çš„ã€‚ä¸€èˆ¬ä»ç„¶æ˜¯<mark style="background: transparent; color: red">å°†è·ç¦»å°çš„ä¸ªä½“åˆ’åˆ†ä¸ºåŒä¸€ç±»åˆ«, è€Œè·ç¦»å¤§åˆ’åˆ†ä¸ºä¸åŒçš„ç±»åˆ«</mark>ã€‚

åŸºæœ¬åŸç†æ˜¯, åœ¨å¤–ç•Œä¿¡æ¯è¾“å…¥æ—¶, å¤§è„‘çš®å±‚çš„ç›¸åº”åŠŸèƒ½åŒºä¼šäº§ç”Ÿå…´å¥‹, æ­¤æ—¶ä½ç½®ç›¸é‚»çš„ç¥ç»å…ƒå…·æœ‰ç›¸è¿‘çš„æ¨¡å¼,è€Œè¿œç¦»çš„ç¥ç»å…ƒåˆ™å…·æœ‰è¾ƒå¤§å·®åˆ«ã€‚ä¾‹å¦‚<mark style="background: transparent; color: red">å½“å£°æ³¢çš„é¢‘ç‡ä¸å¤§è„‘çš®å±‚ç¥ç»å…ƒä¸­çš„æŸäº›å­˜å‚¨æ¨¡å¼æ¥è¿‘, åˆ™ç›¸åº”çš„æ¨¡å¼å®¹æ˜“è¢«è¯†åˆ«ã€‚</mark> 

ä¸å…¶å®ƒç¥ç»ç½‘ç»œä¸åŒçš„æ˜¯,  SOM æ–¹æ³•ä¸<mark style="background: transparent; color: red">åŒå±‚çš„ç¥ç»å…ƒä¹‹é—´å»ºç«‹ä¾§å‘è¿æ¥</mark>, å¹¶é€šè¿‡æƒå€¼å­¦ä¹ å½¢æˆç‰¹å®šçš„æ¨¡å¼, è€Œè¾“å‡ºå±‚ä¸ºæ£‹ç›˜å½¢çŠ¶, å…¶ç¥ç»å…ƒå¯ä»¥å½¢æˆå¤šç§å½¢å¼å¹¶æ˜ å°„å‡ºä¸åŒçš„æ¨¡å¼ã€‚

<b><mark style="background: transparent; color: red">SOM ç½‘ç»œä»…åŒ…å«è¾“å…¥å±‚å’Œè¾“å‡ºå±‚ä¸¤å±‚</mark></b>, å…¶ä¸­, èŠ‚ç‚¹æ•°å³ä¸ºæ ·æœ¬çš„ç»´åº¦ã€‚å¹¶**é€šè¿‡æƒé‡å‘é‡å°†è®­ç»ƒæ•°æ®ä¼ é€’åˆ°å„ä¸ªè¾“å‡ºå•å…ƒ**ã€‚
![[Excalidraw/5. ç¥ç»ç½‘ç»œç†è®ºåˆæ­¥ 2024-10-04 10.33.18|350]]

1. é¦–å…ˆåœ¨è¾“å…¥æ—¶, éœ€è¦å½’ä¸€åŒ–æ•°æ®é›†
2. æ„å»º==è¾“å‡ºå±‚ç½‘ç»œ==, ä¾‹å¦‚<mark style="background: transparent; color: red"> 2ç»´è¾“å…¥ä¸”èƒ½å¤Ÿåˆ†ä¸º 4 ç±»</mark>, åˆ™é‡‡ç”¨ 4 x 2 çš„çŸ©é˜µè¿›è¡Œåˆ†ç±»ã€‚éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œ 4æ˜¯è¾“å‡ºå±‚çš„é¢„ä¼°åˆ†ç±»æ•°, å®é™…çš„èšç±»æ•°é‡æ˜¯ç”±æ•°æ®æœ¬èº«çš„åˆ†å¸ƒå†³å®šçš„ã€‚
3. æƒé‡èŠ‚ç‚¹çš„ç»´åº¦æ˜¯**ç”±è¾“å…¥å±‚æ•°æ®é›†çš„ç»´åº¦å’Œé¢„ä¼°åˆ†ç±»æ•°å†³å®šçš„**, æƒé‡åˆ—æ•°ä¸€èˆ¬é€‰æ‹©å’Œåˆ†ç±»æ•°ç›¸åŒï¼Œ è€Œ<mark style="background: transparent; color: red">è¡Œæ•°ä¸€èˆ¬å’Œè¾“å…¥æ•°æ®çš„ç»´æ•°ç›¸åŒ</mark>, ä¾‹å¦‚, 2 ç»´è¾“å…¥æ•°æ®åˆ†ä¸º 4 ç±», åˆ™<mark style="background: transparent; color: red">æƒé‡çš„è¡Œæ•°è®¾ç½®ä¸º 2, æƒé‡åˆ—æ•°è®¾ç½®ä¸º 4</mark>.
4. åŠ¨æ€å­¦ä¹ å‡½æ•°å®šä¹‰
5. <b><mark style="background: transparent; color: blue">èšç±»åŠå¾„å‡½æ•°å®šä¹‰</mark></b>: ä¸€èˆ¬è€Œè¨€, SOM æ–¹æ³•é‡‡ç”¨**å®šä¹‰çš„å­¦ä¹ åŠå¾„**è¿›è¡Œåˆ†ç±», è€Œå­¦ä¹ åŠå¾„ä¸åŒ, åˆ™èšç±»æ•ˆæœä¹Ÿä¸åŒ

åœ¨ SOM ç½‘ç»œä¸­, éœ€è¦**å®šä¹‰ç½‘ç»œçš„è¡Œæ•° m å’Œåˆ—æ•°** n, å¹¶ä¸”æ»¡è¶³ $m \times  n =$ èšç±»çš„æ€»ä¸ªæ•°ã€‚(å»ºç«‹ç½‘æ ¼çš„ç»´æ•° = è¾“å…¥æ•°æ®çš„ç»´æ•°)
```python
def __init_net_grid(self, net_m, net_n):  
    """  
    :param net_m: ç½‘ç»œçš„è¡Œæ•°  
    :param net_n: ç½‘ç»œçš„åˆ—æ•°  
    """   
	self.M = net_m  
    self.N = net_n  
    self.cls = self.M * self.N  # number of approximate clusters  
    net_grid  = np.zeros((self.cls, self.nd))  
  
    for i in range(self.M):  
        for j in range(self.N):  
            net_grid[i * self.N + j] = np.array([i, j])  # ç”Ÿæˆç½‘æ ¼èŠ‚ç‚¹
```

åˆå§‹ç”Ÿæˆçš„ç½‘ç»œå¦‚å›¾æ‰€ç¤º: 
![[Excalidraw/5. ç¥ç»ç½‘ç»œç†è®ºåˆæ­¥ 2024-10-04 15.39.50|700]]

SOM æ–¹æ³•çš„èšç±»è¿‡ç¨‹å¦‚ä¸‹:
1. <mark style="background: transparent; color: red">é¦–å…ˆè®¡ç®—å­¦ä¹ ç‡å’Œå­¦ä¹ åŠå¾„, å¹¶ä¸”ä»è®­ç»ƒé›†ä¸­éšæœºé€‰å–ä¸€ä¸ªæ ·æœ¬</mark>ä½œä¸º**åˆå§‹èŠ‚ç‚¹**ã€‚ 
2. ä»¥ç‰¹å¾æ•°é‡ (n) * åˆ†ç±»æ•°ç›® (cls) ä¸ºå¤§å°å»ºç«‹æƒé‡çŸ©é˜µ,
3. ä¼˜èƒœé‚»åŸŸ : æ ¹æ®ä¸¤ä¸ªèŠ‚ç‚¹è®¡ç®—å‡ºèšç±»çš„é‚»åŸŸ, å¹¶æ‰¾å‡ºé‚»åŸŸå†…æ‰€æœ‰çš„èŠ‚ç‚¹ 
4. **è°ƒæ•´æƒé‡** 

å¯¹äº iris æ•°æ®é›†, è¾“å…¥ç»´æ•°æ˜¯ç‰¹å¾çš„ä¸ªæ•°, ä¸€èˆ¬ä¸º 4 

SOM æ ¸å¿ƒæ€è·¯: 
1. é¦–å…ˆ<mark style="background: transparent; color: red">é’ˆå¯¹äºæ¯ä¸€ä¸ªç›®æ ‡ç±», ç”Ÿæˆä¸€ä¸ªå¤§å°ä¸º n (ç‰¹å¾æ•°é‡) çš„å‘é‡, å®é™…ä¸Šå½¢æˆä¸€ä¸ª n * cls çš„æƒé‡çŸ©é˜µ wt, è¡¨ç¤ºæ¯ä¸ªåˆ†ç±»çš„å‘é‡æ–¹å‘</mark>,  å–<mark style="background: transparent; color: red">å…¶ä¸­å’Œå½“å‰éšæœºæ ·è·ç¦»æœ€è¿‘çš„ä¸€æ¡</mark>ä¸ºä¼˜èƒœèŠ‚ç‚¹
2. æ„é€ ä¸€ä¸ªç±»ä¼¼å¤§è„‘çš®å±‚çš„, ä»…ç”¨äºè¡¨ç¤ºè·ç¦»çš„ç½‘æ ¼ (grid), å…¶å¤§å°ä¸º ndim * cls 
3. æ¯ä¸€æ¬¡éšæœºé€‰å–ä¸€ä¸ªæ ·æœ¬, æ‰¾åˆ°ä¸ä¹‹æœ€è¿‘çš„å‘é‡ `wt[i]` å¹¶æŠ•åˆ°å¤§è„‘çš®å±‚ grid ä¸­(æ‰¾åˆ° grid ä¸­ç›¸åº”çš„ç‚¹), æ­¤æ—¶å¯»æ‰¾ grid ä¸­è·ç¦»å°äº r çš„ç‚¹, å¹¶åæŠ•å°„åˆ° wt ä¸­ã€‚
4. å¯¹äºæ‰€æœ‰wtä¸­æŠ•å°„è·ç¦»å°äº r çš„ç‚¹, æ›´æ–°æƒé‡, æ–¹æ³•æ˜¯ç”¨è¿™ä¸ªæ ·æœ¬ç‚¹çš„å€¼ * å­¦ä¹ ç‡;
5. é¢„æµ‹æ—¶, é‡‡ç”¨è·ç¦»æœ€è¿‘çš„ $wt$ ä½œä¸ºå®é™…åˆ†ç±»çš„é¢„æµ‹å€¼ã€‚
```python fold title:å¯¹äºSOMæ–¹æ³•çš„pythonä»£ç å®ç°
import numpy as np  
from sklearn.preprocessing import StandardScaler  
from sklearn.datasets import load_iris  
import matplotlib.pyplot as plt  
  
maxr = 1.5  
minr = 0.5  
max_iter = 3000 # è¿­ä»£æ¬¡æ•°è®¾å®š 
  
lr_max = 0.2  
lr_min = 0.001  
  
class SOM:  
    def __init__(self):  
        x, y_true = load_iris(return_X_y=True)  
        std = StandardScaler()  
        self.x = np.array(std.fit_transform(x), dtype=np.float32)  
        self.y = np.array(y_true)  
        self.nd = np.ndim(self.x)  # number of dimensions  
        self.m, self.n = x.shape   # 5-features input dataset (shape is m x n)  
        self.grid = self.__init_net_grid(1,3)  # generate 1x3 grid  

    def lr_radius(self, t):  
        lr = lr_max - (t + 1) * (lr_max - lr_min) / max_iter  
        r = maxr - (t + 1) * (maxr - minr) / max_iter  
        return lr, r 
        
    def dist(self, x1, x2):  
        return np.sqrt(np.sum((x1 - x2)**2, axis = -1))  # sum distance in the last axis  
  
    # åˆå§‹åŒ–ç½‘æ ¼  
    def __init_net_grid(self, net_m, net_n):  
        """  
        :param net_m: ç½‘ç»œçš„è¡Œæ•°  
        :param net_n: ç½‘ç»œçš„åˆ—æ•°  
        """       
        self.M = net_m  
        self.N = net_n  
        self.cls = self.M * self.N  # number of approximate clusters  
        net_grid  = np.zeros((self.cls, self.nd))  
        for i in range(self.M):  
            for j in range(self.N):  
                net_grid[i * self.N + j] = np.array([i, j])  # ç”Ÿæˆç½‘æ ¼èŠ‚ç‚¹  
        return net_grid
        
    def train_net(self):  
        # initialize input layer5 
        self.wt = np.random.rand(self.cls, self.n)  # n-dimension x cluster  
        # train the network 
         for iter in range(max_iter):  
            lr, r = self.lr_radius(iter)   # è·å–æƒé‡å‘é‡ä»¥åŠå­¦ä¹ ç‡
            # select a sample randomly from the input  
            rid = np.random.randint(0, len(self.x))  
            xr = self.x[rid,:]  
  
            # calculate the distance between the sample and the weight nodes  
            idx_min = np.argmin(self.dist(xr, self.wt), axis=0)      # find the nearest node  
  
            """è¯´æ˜: idx_min æ˜¯å„ä¸ªæƒé‡å‘é‡ä¸­, ä¸ xr æœ€è¿‘çš„æƒé‡å‘é‡çš„ä¸‹æ ‡, æ˜¾ç„¶ idx_min < self.M * self.N """            
            d1 = np.ceil(idx_min/self.N) # è·å–è¯¥æƒé‡å‘é‡åœ¨ç½‘æ ¼ä¸­çš„è¡Œä¸‹æ ‡  
            d2 =  idx_min // self.N      # è·å–è¯¥æƒé‡å‘é‡åœ¨ç½‘æ ¼ä¸­çš„åˆ—ä¸‹æ ‡  
  
            # æ„é€ è·ç¦»çŸ©é˜µ, è®¡ç®—æ¯ä¸ªgrid ä¸æ‰€å¾—éƒ¨åˆ†æŠ•å½±ä¹‹é—´çš„è·ç¦»  
            dist_mat = self.dist(np.array([d1, d2], dtype=np.float32), self.grid)  
            idx_les = (dist_mat < r).nonzero()[0]  # åœ¨ç½‘ç»œä¸­, è·å–æ‰€æœ‰ç¥ç»å…ƒé—´è·å°äº r çš„èŠ‚ç‚¹çš„ä¸‹æ ‡  
  
            # æ›´æ–°åˆ†ç±»çš„æƒé‡, å°†æŠ•å½±è·ç¦»å°äºåˆ†ç±»éƒ¨åˆ†çš„æƒé‡è¿›è¡Œå­¦ä¹ æ›´æ–°  
            self.wt[idx_les, :] += lr * (xr - self.wt[idx_les, :])  
  
    def predict(self):  
        y_true = self.y  
        y_pred = np.zeros(self.m)  
        for i in range(self.m):  
            y_pred[i] = np.argmin(self.dist(self.x[i,:], self.wt))  # é‡‡ç”¨æœ€ç»ˆçš„ wt å’Œ è¾“å…¥è¿›è¡Œæ¯”è¾ƒ, æ‰¾åˆ°è·ç¦»æœ€è¿‘çš„æƒé‡å‘é‡ä½œä¸ºåˆ†ç±»é¢„æµ‹å€¼  
  
        fig, axes = plt.subplots(1,2, figsize=(10, 5))  
        axes[0].scatter(self.x[:,0],self.x[:,1], c = y_true)  
        axes[0].set_title('True Labels')  
        axes[1].scatter(self.x[:,0],self.x[:,1], c = y_pred)  
        axes[1].set_title('Predicted Labels')  
        plt.show()  
  
if __name__ == '__main__':  
    som = SOM()  
    som.train_net()  
    som.predict()
```

ç»“æœå¦‚å›¾æ‰€ç¤º :
![[attachments/Pasted image 20241004205950.png|450]]

### (2) é‡‡ç”¨ç¬¬ä¸‰æ–¹åº“å»ºç«‹ SOM ç½‘ç»œ
å¯¹äº sklearn ä¸­, æ²¡æœ‰æä¾› SOM ç½‘ç»œçš„å»ºç«‹å‡½æ•°, ä½†æ˜¯å¯ä»¥é‡‡ç”¨å¦‚ä¸‹çš„æ–¹æ³•è¿›è¡Œå»ºç«‹: 
```shell 
pip install sklearn-som
from sklearn_som.som import SOM 
```

å®é™…çš„ SOM ç½‘ç»œå»ºç«‹å’Œç¼–å†™, å¯ä»¥é‡‡ç”¨å¦‚ä¸‹æ–¹æ³•è¿›è¡Œ:
```python fold title:SOMè‡ªç»„ç»‡æ˜ å°„ç¥ç»ç½‘ç»œçš„å»ºç«‹
import numpy as np  
from sklearn_som.som import SOM  
from sklearn.datasets import load_iris  
from sklearn.preprocessing import StandardScaler  
from sklearn.pipeline import Pipeline  
import matplotlib.pyplot as plt  
from sklearn.inspection import DecisionBoundaryDisplay  
from sklearn.decomposition import PCA 

class CustomSOM(SOM):  
    """  
    é‡å®šä¹‰ SOM ç±»ï¼Œæ·»åŠ  fit_predict æ–¹æ³•  
    SOM æ˜¯ç»§æ‰¿SOMç±», ç”¨äºç»™ pipeline è¿›è¡Œä½¿ç”¨  
    """    def fit_predict(self, X, y=None):  
        self.fit(X)  
        return self.predict(X)  
  
X, y_true = load_iris(return_X_y=True)  
  
# åˆ›å»ºPipeline  
clf = Pipeline(steps=[  
    ('scaler', StandardScaler()),  
    ('som', CustomSOM(m=1, n=3, dim=4))  
])  
  
# è®­ç»ƒå¹¶é¢„æµ‹  
y_pred = clf.fit_predict(X)  
fig, axes = plt.subplots(1, 3, figsize=(15, 5))  
axes[0].scatter(X[:, 0], X[:, 1], c=y_true)  
axes[0].set_title('True Labels')  
axes[1].scatter(X[:, 0], X[:, 1], c=y_pred)  
axes[1].set_title('Predicted Labels')  

# ç”¨äºä»äºŒç»´æ•°æ®ä¸­ Pipeline æå– SOM åˆ†ç±»è¾¹ç•Œæ¨¡å‹  
clf2 = Pipeline(steps=[  
    ('scaler2', StandardScaler()),  
    ('som2', CustomSOM(m=1, n=3, dim=2))  
])  
  
y_pred2 = clf2.fit_predict(X[:, 0:2], y_true)  
DecisionBoundaryDisplay.from_estimator(clf2,  
                                       X[:, 0:2],  
                                       response_method="predict",  
                                       xlabel="sepal length (cm)",  
                                       ylabel="sepal width (cm)",  
                                       ax=axes[2])  
axes[2].set_title('Decision Boundary')  
axes[2].scatter(X[:, 0], X[:, 1], c=y_pred2)  
plt.show()
```
æ˜¾ç„¶æ–°çš„ SOM æ–¹æ³•æ¯”åˆå§‹çš„ SOM æ–¹æ³•è·å¾—äº†æ›´å¥½çš„åˆ†ç±»æ•ˆæœ;
![[attachments/Pasted image 20241004204653.png|600]]

### (3) Boltzmann æœºç®—æ³•(æ¨¡æ‹Ÿé€€ç«ç®—æ³•)
Boltzmannæœºæ–¹æ³•æ˜¯åœ¨ç ”ç©¶[Hopfield ç½‘ç»œ](https://en.wikipedia.org/wiki/Hopfield_network#:~:text=The%20Hopfield%20network%2C%20named%20for,neuron%20j%20to%20neuron%20i.)æ—¶æå‡ºçš„æ€æƒ³, è¿™æ˜¯ç”±äºé‡‡ç”¨ boltzmann åˆ†å¸ƒ(æˆ–Gibbsåˆ†å¸ƒ)ä½œä¸ºç½‘ç»œçš„æ¿€æ´»å‡½æ•°.
æ¨¡æ‹Ÿé€€ç«ç®—æ³•å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/ğŸŒŸæœºå™¨å­¦ä¹ ä¼˜åŒ–ç®—æ³•åˆé›†/1. æ¨¡æ‹Ÿé€€ç«ç®—æ³•(SA)|1. æ¨¡æ‹Ÿé€€ç«ç®—æ³•(SA)]], ç†µå’Œ Gibbs æ–¹ç¨‹å‚è€ƒ [[ğŸ“˜ClassNotes/ğŸ‘¨â€ğŸ”§Mechanics/ğŸŒŠThermal and Fluid dynamics/â™¨ï¸Engineering thermodynamics/ç¬¬ä¸‰ç«  ç†æƒ³æ°”ä½“çš„æ€§è´¨ä¸è¿‡ç¨‹|ç†æƒ³æ°”ä½“çš„æ€§è´¨ä¸è¿‡ç¨‹]];  
é¦–å…ˆæˆ‘ä»¬äº†è§£ [Boltzmann åˆ†å¸ƒ](https://en.wikipedia.org/wiki/Boltzmann_distribution), è¯¥åˆ†å¸ƒç”¨äºæè¿°ä¸€ä¸ªç³»ç»Ÿåœ¨æŸç§çŠ¶æ€çš„æ¦‚ç‡. å…¶åˆ†å¸ƒå½¢å¼æ˜¯:
$$p_{i} \propto \exp  \left(- \frac{\varepsilon_{i}}{k T}\right)$$
å…¶ä¸­,  $\varepsilon$ ä¸ºçŠ¶æ€çš„èƒ½é‡, $k$ ä¸ºç»å°”å…¹æ›¼å¸¸æ•°, è€Œ $T$ ä¸ºæ¸©åº¦,å®é™…åˆ†å¸ƒå¦‚å›¾æ‰€ç¤º:
![[attachments/Pasted image 20241004221753.png|300]]
å¯¹äºèƒ½é‡è¾ƒä½çš„éƒ¨åˆ†, å¾€å¾€ä¼šå…·æœ‰è¾ƒé«˜çš„å¯èƒ½æ€§ã€‚åŒæ—¶æœ‰ä¸¤ä¸ªçŠ¶æ€ä¹‹é—´çš„è½¬ç§»å…³ç³»:
$$\frac{p_{i} }{p_{j}} = \exp \left( \frac{\varepsilon_{j} -  \varepsilon_{i}}{k T }\right)$$
åˆ†å¸ƒçš„æ¦‚ç‡å¯†åº¦å‡½æ•°ç»™å‡ºä¸º:
$$\Large \boxed {p_{i} = \frac{\exp (- \frac{\varepsilon_{i}}{k T} )}{\sum_{j = 1}^{M} \exp  (- \frac{\varepsilon_{i}}{k T })}}$$
æ­¤æ—¶, ç»å°”å…¹æ›¼åˆ†å¸ƒçš„æœ€å¤§åŒ–ç†µéƒ¨åˆ†å®é™…ä¸Šæ˜¯:
$$S(p_{1},  p_{2}, \dots p_{M }) = - \sum_{i = 1}^{M} p_{i} \log_{2} p_{i}$$
æˆ‘ä»¬åœ¨è¾“å‡ºå‘é‡ä¸­å–æ¦‚ç‡ä¸º $p$ æˆ‘ä»¬ä»…å°†ä¸€èˆ¬ç¥ç»ç½‘ç»œä¸­çš„ $\text{net} = w^T x$ è¿›è¡Œä¿®æ”¹ã€‚
$$P\left\{ Y = 1 | x \right\} = p(x) = \frac{1}{1 + e^{-\frac{\text{net}}{T}}}\qquad  P \left\{Y = 0| x \right\} = \frac{1}{1 + e^{\frac{\text{net}}{T}}}$$
å…¶ä¸­, å¦‚æœ Y=1ï¼Œåˆ™æ¦‚ç‡ä¸º $p$, åŒæ—¶ç¬¦åˆ(å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/4. æœ€ä¼˜åŒ–æ–¹æ³•, æ¢¯åº¦å¯»ä¼˜æ³•åŠLogistic å›å½’#(2) Logistic å‡½æ•°å’Œ Logistic æ¢¯åº¦ä¸‹é™æ³•|Logistic å‡½æ•°]]):
$$\Delta = \frac{P\left\{ Y = 1| x\right\}}{P\left\{Y = 0| x\right\}} = e^{\frac{\text{net}}{T}}$$
å…¶ä¸­ $\Delta$ ç§°ä¸º Boltzmann å› å­, <b><mark style="background: transparent; color: orange">å¯¹åº”åœ°, ä½¿ç”¨è¿™ç§åˆ†å¸ƒçš„ç¥ç»ç½‘ç»œç§°ä¸º Boltzmann æœºæˆ–è€… Boltzmann ç¥ç»ç½‘ç»œ</mark></b> 
ä¸€èˆ¬åœ°, T çš„é€‰æ‹©ä¼šå¯¹ä¼˜åŒ–ç»“æœäº§ç”Ÿå¾ˆå¤§å½±å“, T è¶Šå¤§, åˆ™logistic æ›²çº¿è¶Šå¹³æ»‘, <mark style="background: transparent; color: red">å½“æœ‰ T = 0 æ—¶, åˆ™å‡½æ•°å˜ä¸º hardlim ç¡¬é™å¹…å‡½æ•°</mark>;
![[Excalidraw/5. ç¥ç»ç½‘ç»œç†è®ºåˆæ­¥ 2024-10-04 23.43.45|300]]
ä¸€èˆ¬å– $T(k + 1) = \lambda T(k)$ , è€Œåœ¨å®é™…æƒ…å†µä¸‹, ä¸ºäº†åœ¨è¿­ä»£è¿‡ç¨‹ä¸­æœ€å°åŒ– $\varepsilon$, æˆ‘ä»¬æ¯ä¸€æ¬¡é€€ç«æ—¶,é‡‡ç”¨å¦‚ä¸‹æ–¹æ³•å†³å®šè·³å˜:
$$\lambda = \frac{p_{k + 1} }{p_{k}} =\min\left\{ \exp\left(-\frac{\varepsilon_{k} - \varepsilon_{k + 1 } }{T}  \right), 1\right\}$$
```python
def boltzmann(new, old, T):
	return (new - old)/T
```
ç„¶åéšæœºç”Ÿæˆä¸€ä¸ªæ•°å­— t,  å½“æœ‰ $t < \lambda$ æ—¶, åˆ™è¿›è¡Œè·³å˜($\text{cur\_val} +=  lr * (\varepsilon_{k+1} - \varepsilon_k)$) æˆ–è€…è¿›è¡Œäº¤æ¢å½“å‰çŠ¶æ€, æœ€ç»ˆå³å¯æ±‚å¾—æœ€å°å€¼çš„è§£ã€‚

