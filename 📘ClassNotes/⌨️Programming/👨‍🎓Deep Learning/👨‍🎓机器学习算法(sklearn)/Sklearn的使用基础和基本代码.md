# 1. Sklearn åº“çš„ä½¿ç”¨ 
sklearn æ˜¯æœ€å¸¸ç”¨çš„æœºå™¨å­¦ä¹ åº“, å…¶åŒ…å«åˆ†ç±», å›å½’ç®—æ³•, èšç±»ç®—æ³•, ç»´åº¦åŒ–ç®€, æ¨¡å‹é€‰æ‹©, äº¤å‰éªŒè¯, æ•°æ®é¢„å¤„ç†ç­‰ç­‰åŠŸèƒ½. ä¾‹å¦‚å²­å›å½’ï¼Œ æ”¯æŒå‘é‡æœº, KNN , æœ´ç´ è´å¶æ–¯, å†³ç­–æ ‘, ç‰¹å¾é€‰æ‹©, ä¿åºå›å½’ç­‰ç­‰ç®—æ³•

ç›¸æ¯”äº Pytorch,`sklearn` ä¸­çš„æ¨¡å‹ï¼ˆä¾‹å¦‚ `AdaBoostClassifier`ï¼‰å¹¶ä¸ç›´æ¥æ”¯æŒé€šè¿‡ `torch.DataLoader` è¿›è¡Œå¤šæ¬¡è¾“å…¥å’Œè®­ç»ƒï¼Œå› ä¸º `sklearn` <mark style="background: transparent; color: red">æ¨¡å‹é€šå¸¸æ˜¯åŸºäºæ‰¹é‡è®­ç»ƒçš„</mark>ï¼Œè€Œä¸åƒ PyTorch é‚£æ ·é‡‡ç”¨é€æ‰¹ï¼ˆmini-batchï¼‰è®­ç»ƒçš„æ–¹å¼ã€‚ä»è€Œæä¾›æ›´å¥½çš„æ–¹æ³•ã€‚
##  åŸºç¡€éƒ¨åˆ†
### (1) sklearn ä¸­çš„ Bunch ç±»
Bunch æ˜¯ sklearn ä¸­æœ€å¸¸ç”¨çš„ç»“æ„, ç±»ä¼¼äºå­—å…¸ï¼Œå…·ä½“å‚è€ƒ [[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸPython/ğŸŒŸPython åŸºç¡€éƒ¨åˆ†/2. Python åŸºæœ¬æ•°æ®ç»“æ„å’Œå¯è§†åŒ–æ–¹æ³•|2. Python åŸºæœ¬æ•°æ®ç»“æ„å’Œå¯è§†åŒ–æ–¹æ³•]] 
```python 
from sklearn.datasets._base import Bunch
```
ä¸€èˆ¬åœ°, å¯ä»¥é€šè¿‡
```python
print(bunch.keys())
```
è·å–å…¶ä¸­çš„keysé”®, å¯¹äºbunchçš„keyséƒ¨åˆ†å‡å¯ä»¥é€šè¿‡ `.` è¿›è¡Œè®¿é—®ã€‚

> [!CAUTION] scipy ä¸­çš„ toarray æ–¹æ³•
> éœ€è¦æ³¨æ„çš„æ˜¯, scipy.spare.toarray() å’Œ numpy.array å¹¶ä¸ç›¸é€š, ç¨€ç–çŸ©é˜µå¯ä»¥é€šè¿‡ toarray() æ–¹æ³•è¿›è¡Œè½¬æ¢ä¸ºæ ‡å‡†çš„ numpy æ•°ç»„
### (2) æ•°æ®é›†è®­ç»ƒå’Œæµ‹è¯•éƒ¨åˆ†
sklearn å¯ä»¥ç›´æ¥è·å–å¤§é‡çš„å­¦ä¹ æ•°æ®é›†ï¼Œ åŒæ—¶æœ‰åˆ†å‰²è®­ç»ƒé›†å’Œæµ‹è¯•é›†åŠŸèƒ½, ä¸‹é¢ç®€ä»‹
<mark style="background: transparent; color: red">train_test_split åˆ†å‰²æ•°æ®é›†</mark> å’Œ <mark style="background: transparent; color: red">StandardScaler æ ‡å‡†åŒ–çš„æ–¹æ³•</mark> 

```python 
from sklearn.dataset import load_iris 
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import StandardScaler   # æ ‡å‡†åŒ–å™¨ç±»å‹ 

X_train, X_test, y_train, y_test =  train_test_split(iris_data, iris_target, test_size=0.2, random_state=None)  
stdsca = StandardScaler.fit(X_train)
X_train_new = stdsca.transform(X_train)
X_test_new = stdsca.transform(X_test)
```

å¯¹äºæµ‹è¯•å‡†ç¡®åº¦, å¯ä»¥é‡‡ç”¨ [sklearn.metrics æ¨¡å—](https://scikit-learn.org/stable/api/sklearn.metrics.html)éƒ¨åˆ†: 
```python
from sklearn.metrics import accuracy_score, classification_report 
from sklearn.metrics import precision score, recall_score 
from sklearn.metrics import f1_score  # F1æ ‡å‡†, å‚è€ƒsklearn éƒ¨åˆ†
```

[`accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html#sklearn.metrics.accuracy_score "sklearn.metrics.accuracy_score") ,[`average_precision_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.average_precision_score.html#sklearn.metrics.average_precision_score "sklearn.metrics.average_precision_score"), [`balanced_accuracy_score`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.balanced_accuracy_score.html#sklearn.metrics.balanced_accuracy_score "sklearn.metrics.balanced_accuracy_score"), [`brier_score_loss`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.brier_score_loss.html#sklearn.metrics.brier_score_loss "sklearn.metrics.brier_score_loss") , 
æ­¤å¤–, æµ‹è¯• MSE, MAE ä¹Ÿå¯ä»¥é‡‡ç”¨ sklearn,metrics ä¸­ç›´æ¥import:

| [`mean_squared_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html#sklearn.metrics.mean_squared_error "sklearn.metrics.mean_squared_error")                 | Mean squared error regression loss.(MSE)        |
| --------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ----------------------------------------------- |
| [`mean_squared_log_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_log_error.html#sklearn.metrics.mean_squared_log_error "sklearn.metrics.mean_squared_log_error") | Mean squared logarithmic error regression loss. |
| [`mean_absolute_error`](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_absolute_error.html#sklearn.metrics.mean_absolute_error "sklearn.metrics.mean_absolute_error")             | Mean absolute error regression loss.(MAE)       |

### (3) ç‰¹å¾æå–å’Œåˆ†ç±» 
```python
from sklearn.linear_model import LogisticRegression
```

å¦‚æœç”Ÿæˆåˆ†ç±»æ•°æ®ç¤ºä¾‹,  å¯ä»¥é‡‡ç”¨ `from sklearn.datasets import make_classification`  å¾—åˆ°
```python
from sklearn.ensemble import AdaBoostClassifier
from sklearn.datasets import make_classification
from sklearn.model_selection import train_test_split
from sklearn.metrics import classification_report

# ç”Ÿæˆç¤ºä¾‹æ•°æ® (1000 ä¸ªæ ·æœ¬, æ¯ä¸ªæ ·æœ¬ 20 ä¸ªç‰¹å¾)
X, y = make_classification(
    n_samples=1000,    # æ ·æœ¬æ•°é‡
    n_features=20,     # ç‰¹å¾æ•°é‡
    n_informative=15,  # æœ‰ç”¨ç‰¹å¾æ•°é‡
    n_redundant=5,     # å†—ä½™ç‰¹å¾æ•°é‡
    random_state=42
)

# åˆ’åˆ†æ•°æ®ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# åˆå§‹åŒ– AdaBoostClassifier
clf = AdaBoostClassifier(n_estimators=50, random_state=42)

# è®­ç»ƒæ¨¡å‹
clf.fit(X_train, y_train)

# é¢„æµ‹æµ‹è¯•é›†
y_pred = clf.predict(X_test)

# è¾“å‡ºåˆ†ç±»æŠ¥å‘Š
print(classification_report(y_test, y_pred))
```

#### 1. å­—ç¬¦ä¸²æ ‡ç­¾ç¼–ç (LabelEncoder)
Label ç”¨äºè¿›è¡Œå­—ç¬¦ä¸²æ ‡ç­¾ç¼–ç ä¸ºæ•°å­—, ä¾‹å¦‚å¯¹äºå¦‚ä¸‹å†³ç­–æ ‘è¡¨æ ¼(å…¶ä¸­ç¬¬ä¸€åˆ—ä¸éœ€è¦ç¼–ç ): 
![[attachments/Pasted image 20240912111152.png]]
å…¶ä¸­é‡‡ç”¨ apply_map çš„æ–¹æ³•, å»é™¤äº†æ¯ä¸ªå­—ç¬¦ä¸²å…ƒç´ çš„ç©ºæ ¼; åŒæ—¶é‡‡ç”¨stripå»é™¤äº†æ¯ä¸ªæ ‡ç­¾çš„ç©ºæ ¼ã€‚  
```python
import pandas as pd  
from sklearn.preprocessing import LabelEncoder  # encoder labels  
  
data_raw = pd.DataFrame(pd.read_excel("seals_data.xlsx"))  
data_proceed = pd.DataFrame()  
label_encoder = LabelEncoder()  
  
# eliminate all the white space 
data_raw = data_raw.applymap(lambda x: x.strip() if isinstance(x, str) else x)  
data_proceed['è®¡æ•°'] = data_raw.iloc[:,0]  

# ç¼–ç å¹´é¾„, æ”¶å…¥, å­¦ç”Ÿ, ä¿¡èª‰, æ˜¯å¦è´­ä¹°å‡ åˆ— 
for column in data_raw.columns[1:]:
    data_proceed[str(column).strip()] = label_encoder.fit_transform(data_raw[column])  
print(data_proceed)
```
å¾—åˆ°å†³ç­–æ ‘ç¼–ç ç»“æœå¦‚ä¸‹:
![[attachments/Pasted image 20240912113356.png|200]]
#### 2. åˆ†ç±»å™¨: ç‰¹å¾é€‰æ‹©, æå–å’Œä¸»æˆåˆ†åˆ†æ
å‚è€ƒ [[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/1.æœºå™¨å­¦ä¹ ç®—æ³•å’Œæ–‡æœ¬åˆ†ç±»æŒ–æ˜(Naive Bayes)|æœºå™¨å­¦ä¹ ç®—æ³•å’Œæ–‡æœ¬åˆ†ç±»æŒ–æ˜(Naive Bayes)]], ç‰¹å¾æå–å¯ä»¥é€šè¿‡ `from sklearn import feature_extraction` å¾—åˆ°
å…¶ä¸­ç‰¹å¾æå–ä¸­æœ‰ image, text ç­‰ç­‰å‡ ä¸ªæ¨¡å—; å¸¸ç”¨åˆ° tf-idf æ¨¡å‹ç­‰æ–‡æœ¬ tf-idf ç‰¹å¾å‘é‡è®¡ç®—æ¨¡å‹ã€‚
![[attachments/Pasted image 20240910160939.png|300]]

```python
# ç‰¹å¾é€‰æ‹©å’Œç‰¹å¾æå–éƒ¨åˆ†
from sklearn import feature_extraction
from sklearn import feature_selection 
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.feature_extraction.text import TfidfTransformer 
vectorizer.fit_transform(contents_dictionary)
```

å¯¹äºå¤šæ ‡ç­¾åˆ†ç±»éƒ¨åˆ†, éœ€è¦é‡‡ç”¨å¤šè¾“å‡º
```python
from sklearn.multioutput import MultiOutputClassifier, MultiOutputEstimator
# å°†ä¸€ä¸ªéƒ¨åˆ†è½¬æ¢ä¸ºå¤šè¾“å‡º:
model = MultiOutputClassifier(MultinomialNB(alpha=0.01))
```

2. ä¸»æˆåˆ†åˆ†æ(PCAæ¨¡å—) å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/3. æ¨èç³»ç»Ÿå’Œéœ€æ±‚æœå¯»ç®—æ³•(CF,PCA,SVD)|3. æ¨èç³»ç»Ÿå’Œéœ€æ±‚æœå¯»ç®—æ³•(CF,PCA,SVD)]] éƒ¨åˆ†
```python 
from sklearn.decomposition import PCA
```

3. KNN, KMeans åˆ†ç±»å™¨
```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.cluster import KMeans
```


## 2. PipeLine çš„ä½¿ç”¨
PipeLine æ˜¯ sklearn ä¸­çš„ä¸€ä¸ªå¾ˆæ–¹ä¾¿çš„å®¹å™¨ç±»,  å¯ä»¥ç›´æ¥åœ¨ PipeLine ä¸­å®šä¹‰ Steps, ç„¶åè¿›è¡Œ fit æ“ä½œã€‚ (ç±»ä¼¼çš„æ˜¯ `torchvision.transforms.v2` çš„ `v2.Compose` å’Œ `nn.Sequential`)
è€Œé€šè¿‡ set_params æ–¹æ³•å¯ä»¥å¯¹ pipeline ä¸­çš„æŸä¸ªåç§°å¯¹è±¡å±æ€§è¿›è¡Œè®¾ç½®, å…·ä½“æ–¹æ³•æ˜¯é‡‡ç”¨ `__` è¿›è¡Œå‘½ååŒºåˆ†: 
å³ `set_params(name__param = new_param)` 

éœ€è¦åˆ†ç±»è¾¹ç•Œæ˜¾ç¤ºæ—¶, åˆ™å¯ä»¥é‡‡ç”¨  sklearn.inspection ä¸­çš„ DecisionBoundaryDisplay æ–¹æ³•ã€‚
xlabel å’Œ ylabel é€‰é¡¹å’Œç»˜å›¾ plt è®¾ç½®å®Œå…¨ç›¸åŒã€‚
ä¸‹å›¾é‡‡ç”¨ pipeline è¿›è¡Œåˆ†ç±»è¾¹ç•Œæ˜¾ç¤º
```python
from sklearn.pipeline import Pipeline
from sklearn.inspection import DecisionBoundaryDisplay

clf = Pipeline(  
    steps=[("scaler", StandardScaler()), ("kmeans", KMeans(n_clusters = 3))]  
)
clf.set_params(kmeans__max_iter = max_iter).fit(X_train, y_train)
disp = DecisionBoundaryDisplay.from_estimator(  
    clf,  
    X_test,  
    response_method="predict",  
    plot_method="pcolormesh",  
    xlabel=iris.feature_names[0],  
    ylabel=iris.feature_names[1],  
    shading="auto",  
    alpha=0.5,  
    ax=ax,  
)
```

éœ€è¦è¯´æ˜,  PipeLineä¸­çš„æ¯ä¸ªéƒ¨åˆ†å¿…é¡»æ¥å— x,y ä½œä¸º fit_predict çš„å‚æ•°, å› æ­¤å½“ fit ç­‰ä»…æ¥å—ä¸€ä¸ªå‡½æ•° x æ—¶, éœ€è¦é‡å®šä¹‰ç±»å‹ (é‡å®šä¹‰ SOM ç±»), å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/5. BP ç¥ç»ç½‘ç»œ, SOM ç¥ç»ç½‘ç»œå’Œ Boltzmannæœº#(2) é‡‡ç”¨ç¬¬ä¸‰æ–¹åº“å»ºç«‹ SOM ç½‘ç»œ|5. BP ç¥ç»ç½‘ç»œ, SOM ç¥ç»ç½‘ç»œå’Œ Boltzmannæœº]] 
```python
from sklearn_som.som import SOM
clf = Pipeline(steps=[  
    ('scaler', StandardScaler()),  
    ('som', CustomSOM(m=1, n=3, dim=4))  
]) 
```

### 3. è¶…å‚æ•°è°ƒä¼˜é—®é¢˜æ–¹æ³•

ä½¿ç”¨GridSearchCVå’ŒKFoldè¿›è¡Œäº¤å‰éªŒè¯
```python
from sklearn.neighbors import KNeighborsClassifier
from sklearn.model_selection import GridSearchCV, KFold
from sklearn.datasets import load_iris
 
# åŠ è½½ç¤ºä¾‹æ•°æ®é›†ï¼ˆè¿™é‡Œä»¥é¸¢å°¾èŠ±æ•°æ®é›†ä¸ºä¾‹ï¼‰
data = load_iris()
X = data.data
y = data.target
 
# å®šä¹‰Kæœ€è¿‘é‚»æ¨¡å‹
knn = KNeighborsClassifier()
 
# å®šä¹‰å‚æ•°ç½‘æ ¼
param_grid = {
    'n_neighbors': [3, 5, 7],
    'weights': ['uniform', 'distance']
}
#weightsï¼šæŒ‡å®šåœ¨é¢„æµ‹æ—¶å¦‚ä½•å¯¹é‚»å±…çš„æƒé‡è¿›è¡ŒåŠ æƒï¼Œå¸¸è§å–å€¼æœ‰uniformï¼ˆæ‰€æœ‰é‚»å±…æƒé‡ç›¸ç­‰ï¼‰å’Œdistanceï¼ˆæƒé‡ä¸è·ç¦»æˆåæ¯”ï¼‰ã€‚
 
# ä½¿ç”¨GridSearchCVå’ŒKFoldè¿›è¡Œäº¤å‰éªŒè¯
kf = KFold(n_splits=5, shuffle=True, random_state=0)
grid_search = GridSearchCV(knn, param_grid, cv=kf, scoring='accuracy')
grid_search.fit(X, y)
 
# è¾“å‡ºæœ€ä½³å‚æ•°å’Œæœ€ä½³å¾—åˆ†
print("æœ€ä½³å‚æ•°ï¼š", grid_search.best_params_)
print("æœ€ä½³å¾—åˆ†ï¼š", grid_search.best_score_)
```
