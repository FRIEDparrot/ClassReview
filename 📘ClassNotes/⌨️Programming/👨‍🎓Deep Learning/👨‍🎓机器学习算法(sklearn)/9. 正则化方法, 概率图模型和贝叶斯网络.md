å¸¸è§çš„æ·±åº¦å­¦ä¹ ç®—æ³•åŒ…å«: 
1. å¤šå±‚æ„ŸçŸ¥å™¨ 
2. å·ç§¯ç¥ç»ç½‘ç»œ (LeNet) 
3. é€’å½’ç¥ç»ç½‘ç»œ (RNN) 
4. LSTM ç½‘ç»œ 
5. ç¨€ç–ç¼–ç å™¨ 
6. å †å è‡ªåŠ¨ç¼–ç å™¨ 
7. æ·±åº¦ç½®ä¿¡ç½‘ç»œ 
8. æ··åˆ MonteCarlo æŠ½æ · 
9. å‹ç¼©è‡ªåŠ¨ç¼–ç å™¨   
10. RNN-RBM ç½‘ç»œ 

ä¸€èˆ¬åœ°, æ­£åˆ™åŒ–æ–¹æ³•æ˜¯ç¥ç»ç½‘ç»œä¸­çš„å¸¸ç”¨æ–¹æ³•ã€‚è®­ç»ƒæ¨¡å‹æ—¶ï¼Œå¦‚æœ MSGD ç®—æ³•ä¸è€ƒè™‘æ­£åˆ™åŒ–æ–¹æ³•, åˆ™æœ‰å¯èƒ½å¯¼è‡´è¿‡æ‹Ÿåˆã€‚è€Œåœ¨å®é™…ç¥ç»ç½‘ç»œä¸­, æœ€å¸¸ç”¨çš„æ­£åˆ™åŒ–æ–¹æ³•åŒ…æ‹¬ä¸¤ç±», Early Stop å’Œ L1/L2 æ­£åˆ™åŒ–, æ˜¯åœ¨æœ‰ç›‘ç£çš„æ·±åº¦å­¦ä¹ ä¸­å¸¸ç”¨åˆ°çš„é˜²æ­¢è¿‡æ‹Ÿåˆçš„åŠæ³•ã€‚

#### 1. Early Stop æ­£åˆ™åŒ–
è¯¥æ–¹æ³•çš„æ€è·¯éƒ¨åˆ†, å®é™…ä¸Šæ˜¯<b><mark style="background: transparent; color: orange">é€šè¿‡æ£€æµ‹æ–°çš„éªŒè¯é›†ä¸­çš„æŒ‡æ ‡æ¥é˜²æ­¢è¿‡æ‹Ÿåˆ</mark></b>, ä¸€èˆ¬ä¼šè®¾ç½®ä¸€ä¸ªéªŒè¯é¢‘ç‡(çº§æ•°å¢é•¿), å¤šæ¬¡è®­ç»ƒä¹‹åéªŒè¯ä¸€æ¬¡ã€‚å¦‚æœæ¨¡å‹çš„æ€§èƒ½åœ¨éªŒè¯é›†ä¸Šä¸å‘ç”Ÿæ˜¾è‘—æé«˜(æŸå¤±ä¸‹é™ < best_loss * threshold), ç”šè‡³ä¸‹é™æ—¶, åˆ™è§¦å‘æå‰ç»ˆæ­¢æ¡ä»¶ã€‚

#### 2. L1/L2 æ­£åˆ™åŒ–æ–¹æ³•
L1/L2 æ­£åˆ™åŒ–æ–¹æ³•æ˜¯ä½¿ç”¨äº MLP(Multilayer perceptionï¼Œå¤šå±‚æ„ŸçŸ¥å™¨ç½‘ç»œ)çš„<mark style="background: transparent; color: red">æƒé‡æ³›åŒ–é—®é¢˜</mark>çš„æ­£åˆ™åŒ–æ–¹æ³•ã€‚
å¦‚æœæŸå¤±å‡½æ•°ä¸º:
$$NLL(\theta, D) = - \sum_{i = 0}^{|D|} \log P  (Y= y^{(i)}|  x^{(i)} , \theta)$$
åˆ™æœ‰æ­£åˆ™åŒ–çš„æŸå¤±: 
$$E (\theta, D) = NLL(\theta, D) + \lambda R(\theta)$$
å…¶ä¸­å–æƒ©ç½šå‚æ•°(é™ä½éçº¿æ€§) $R(\theta)$ å¯å–ä¸º $\theta$ çš„[[ğŸ“˜ClassNotes/ğŸ“Mathmatics/âœ–ï¸Matrix Theory/2. èŒƒæ•°ç†è®ºåŠå…¶åº”ç”¨|pèŒƒæ•°]]:
$$R(\theta) = ||\theta||_{p}^{p} = \left(\sum_{j = 0}^{n} |\theta_{j}|^{p}  \right)^{\frac{1}{p}}$$
å…¶ä¸­, $\lambda$ æ§åˆ¶æ­£åˆ™åŒ–å‚æ•°çš„é‡è¦æ€§, å¹¶ä¸”**æŒ‰ç…§ p = 1, 2 åˆ†åˆ«ç§°ä¸º L1, L2 æ­£åˆ™åŒ–æ–¹æ³•**ã€‚ä½†æ˜¯è¿™ç§æ³›åŒ–æ–¹æ³•ä¸€èˆ¬åœ¨å°è§„æ¨¡æ•°æ®é›†ä¸Šæœ‰ä¸€å®šçš„å¸®åŠ©ã€‚

ä¾‹å¦‚ä¸‹é¢ç»™å‡ºä¸€ä¸ªé‡‡ç”¨ torch è¿›è¡Œ L1 æ­£åˆ™åŒ–çš„ç®€å•ç¤ºä¾‹, å…¶ä¸­é‡‡ç”¨ model.parameters è®¿é—®äº†æ‰€æœ‰çš„ paramï¼Œå¹¶ä¸”<mark style="background: transparent; color: red">è®¡ç®—å¹³æ–¹å’Œé™„åŠ åˆ° loss ä¸­</mark>, å³å¯¹å®é™…ä¸Šçš„å‚æ•°éƒ¨åˆ†æ–½åŠ äº†æ­£åˆ™åŒ–æ–¹æ³•:
```python
lambda_l1 = 0.01 # L1 æ­£åˆ™åŒ–å¼ºåº¦ 
lambda_l2 = 0.01 # L2 æ­£åˆ™åŒ–å¼ºåº¦
# åˆå§‹åŒ–æ¨¡å‹ã€æŸå¤±å‡½æ•°å’Œä¼˜åŒ–å™¨
model = LogisticRegressionModel(input_dim, output_dim)
criterion = nn.BCELoss()  # äºŒåˆ†ç±»äº¤å‰ç†µæŸå¤±
optimizer = optim.SGD(model.parameters(), lr=learning_rate)
# è®­ç»ƒæ¨¡å‹
for epoch in range(epochs):
    # å‰å‘ä¼ æ’­
    y_pred = model(X)
    loss = criterion(y_pred, y)
    # æ·»åŠ  L1 å’Œ L2 æ­£åˆ™åŒ–
    l1_penalty = torch.tensor(0.0)
    l2_penalty = torch.tensor(0.0)
    for param in model.parameters():
        l1_penalty += torch.sum(torch.abs(param))  # L1 æ­£åˆ™åŒ–é¡¹
        l2_penalty += torch.sum(param ** 2)  # L2 æ­£åˆ™åŒ–é¡¹
    loss += lambda_l1 * l1_penalty + lambda_l2 * l2_penalty # æ›´æ–° loss å‚æ•° 
    # åå‘ä¼ æ’­å’Œä¼˜åŒ–
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    # æ‰“å°è®­ç»ƒè¿›åº¦
    if (epoch + 1) % 100 == 0:
        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')

# æ¨¡å‹æµ‹è¯•
with torch.no_grad():
    test_input = torch.tensor([[0.5, -0.5], [-1.0, 1.0], [1.0, 1.0]])
    test_output = model(test_input)
    print("\nTest Input:", test_input)
    print("Predicted Output:", test_output)
```

éœ€è¦è¯´æ˜çš„æ˜¯, ä¸€èˆ¬é‡‡ç”¨çš„ L2 æ­£åˆ™åŒ–æ–¹æ³•ä¹Ÿç§°ä¸ºæƒé‡è¡°å‡æ–¹æ³•(weight decay), å¦‚ä¸‹: 

`````ad-note
title: Weight decay
collapse: open

Weight decay, also known as **L2 regularization**, is a technique used in deep learning to prevent overfitting by penalizing large weights in the model. Hereâ€™s a detailed introduction to weight decay:

### What is Weight Decay?

Weight decay is a regularization technique that adds a penalty term to the loss function, which is proportional to the sum of the squared weights of the model. [This penalty term discourages the model from assigning too much importance to any single feature, thereby promoting simpler models that generalize better to unseen data](https://d2l.ai/chapter_linear-regression/weight-decay.html)[1](https://d2l.ai/chapter_linear-regression/weight-decay.html)[2](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/).

### How Does Weight Decay Work?

The primary loss function (L_{\text{original}}(w)) is modified to include the weight decay term, resulting in a new loss function (L_{\text{new}}(w)):

$$L_{\text{new}}(w) = L_{\text{original}}(w) + \lambda \sum_{i} w_i^2$$

Here, (w) represents the weights of the model, and (\lambda) is a hyperparameter that controls the strength of the regularization. [The larger the value of (\lambda), the more the weights are penalized](https://d2l.ai/chapter_linear-regression/weight-decay.html)[3](https://paperswithcode.com/method/weight-decay).

### Why Use Weight Decay?

Weight decay helps in:

1. [**Reducing Overfitting**: By penalizing large weights, weight decay prevents the model from fitting the noise in the training data, leading to better generalization on new data](https://d2l.ai/chapter_linear-regression/weight-decay.html)[2](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/).
2. [**Improving Model Stability**: Smaller weights lead to a more stable model that is less sensitive to small changes in the input data](https://d2l.ai/chapter_linear-regression/weight-decay.html)[1](https://d2l.ai/chapter_linear-regression/weight-decay.html).

### Implementing Weight Decay

Weight decay can be implemented in various deep learning frameworks. For example, in Keras, you can add weight regularization to a layer using the `kernel_regularizer` argument:

```python
from keras.layers import Dense
from keras.regularizers import l2

model.add(Dense(32, kernel_regularizer=l2(0.01)))
```

[This code snippet adds an L2 regularizer with a penalty factor of 0.01 to a dense layer](https://d2l.ai/chapter_linear-regression/weight-decay.html)[2](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/).

### Conclusion 
Weight decay is a powerful and widely-used regularization technique in deep learning. By adding a penalty term to the loss function, it helps in reducing overfitting and improving the generalization of the model. Understanding and effectively using weight decay can significantly enhance the performance of your deep learning models.
`````

éœ€è¦è¯´æ˜çš„æ˜¯, ç»å¤§å¤šæ•° Pytorch ä¸­çš„æ¨¡å‹éƒ½æ”¯æŒé‡‡ç”¨ weight-decay å‚æ•°, ä¾‹å¦‚:
```python
# åˆ›å»ºä¼˜åŒ–å™¨ï¼Œå¹¶è®¾ç½® weight_decay å‚æ•° 
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01) # L2 æƒé‡è¡°å‡
```

éœ€è¦è¯´æ˜çš„æ˜¯, å¦‚æœå¸Œæœ›åç½®å±‚æˆ–è€…å½’ä¸€åŒ–å±‚ç­‰çš„éƒ¨åˆ†ä¸å—æƒé‡è¡°å‡å½±å“,åˆ™å¯ä»¥è¿›è¡Œæƒé‡åˆ†ç»„:
```python
# æ‰‹åŠ¨å°†å‚æ•°åˆ†ç»„
param_groups = [
    {'params': [param for name, param in model.named_parameters() if 'bias' in name], 'weight_decay': 0.0},
    {'params': [param for name, param in model.named_parameters() if 'bias' not in name], 'weight_decay': 0.01}
]
# åˆå§‹åŒ–ä¼˜åŒ–å™¨
optimizer = optim.Adam(param_groups, lr=0.001)
# å‰©ä½™è®­ç»ƒè¿‡ç¨‹ä¸ä¸Šè¿°ç›¸åŒ
```

## äºŒã€å¤šå±‚æ„ŸçŸ¥æœº
### (1) å¤šå±‚æ„ŸçŸ¥æœºæ¦‚å¿µ
å¤šå±‚æ„ŸçŸ¥æœºå®é™…ä¸Šæ˜¯åˆ†ç±»å™¨, ç±»ä¼¼äº[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/è¡¥å……çŸ¥è¯†/4. KNNç®—æ³•å’ŒKMeansèšç±»ç›¸å…³ç®—æ³•|KNNç®—æ³•å’ŒKMeansç®—æ³•]]éƒ¨åˆ†. 
å¤šå±‚æ„ŸçŸ¥æœºæ˜¯è‡³å°‘å«æœ‰ä¸€ä¸ªéšè—å±‚çš„ç”±å…¨è¿æ¥å±‚ç»„æˆçš„ç¥ç»ç½‘ç»œ, æ¯ä¸ªéšè—å±‚çš„è¾“å‡ºé€šè¿‡æ¿€æ´»å‡½æ•°è¿›è¡Œå˜æ¢ã€‚å…¶åŸºæœ¬ç»“æ„æ˜¯ <mark style="background: transparent; color: red">è¾“å…¥-> éšè—å±‚ -> è¾“å‡º</mark>, å…¶ä¸­åŒ…å«éšè—å•å…ƒ, ä¸ºä¸€ä¸ª2å±‚çš„ç¥ç»ç½‘ç»œ; è®°éšè—å±‚çš„è¾“å‡ºä¸ºH, è€Œä¸¤å±‚çš„æƒé‡å‘é‡ä¸º $W_h$ å’Œ $W_o$, åˆ™: 
$$H =\phi(XW_{h} + b_{h})   \qquad   O = HW_o + b_o$$
ç»è¿‡è”ç«‹ï¼Œå¯å¾—åˆ°:
$$O =\phi (XW_h + b_h)W_o + b_{o}$$
å…¶ä¸­å­¦ä¹ å‚æ•°ä¸º $\theta = (W_{o}, b_{o},  W_{h}, b_{h})$
éœ€è¦è¯´æ˜çš„æ˜¯, å¦‚æœä¸å¢åŠ æ¿€æ´»å‡½æ•°, åˆ™æœ‰:
$$O =   XW_{h} W_{o}  + (b_{h} W_{o} + b_{o})$$
<mark style="background: transparent; color: red">å³ä½¿å†æ·»åŠ æ›´å¤šçš„éšè—å±‚ï¼Œä¸åŠ æ¿€æ´»å‡½æ•°çš„è®¾è®¡ä»ç„¶åªèƒ½ä¸ä»…å«è¾“å‡ºå±‚çš„å•å±‚ç¥ç»ç½‘ç»œç­‰ä»·</mark>(å…¶ä¸­ï¼Œè¾“å‡ºå±‚æƒé‡å‚æ•°ä¸º$W_hW_o$,åå·®å‚æ•°ä¸º$b_hW_o+b_o$)

å…¶ä¸­, æ¿€æ´»å‡½æ•° $\phi$ å¯ä»¥å‚è€ƒ[å¸¸è§çš„æ¿€æ´»å‡½æ•°éƒ¨åˆ†](https://blog.csdn.net/caip12999203000/article/details/127067360), åŒæ—¶ä¸€èˆ¬é€‰ç”¨ ReLU æˆ–è€… tanh  å‡½æ•°, è¾“å‡ºå±‚å¦‚æœæ˜¯åˆ†ç±»é—®é¢˜, ä¸€èˆ¬é‡‡ç”¨ [[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/4. æœ€ä¼˜åŒ–æ–¹æ³•, æ¢¯åº¦å¯»ä¼˜æ³•åŠLogistic å›å½’|Logistic å‡½æ•°]](Sigmoidå‡½æ•°) å°†è·å¾—çš„$(-\infty, +\infty)$ èŒƒå›´çš„ç»“æœæŠ•å½±åˆ° (0, 1)ä¹‹é—´ã€‚

```python
import torch.nn as nn   
from torch.nn import functional as F

self.Linear  = nn.Linear(input_dim,  output_dim) # å»ºç«‹å…¨è¿æ¥å±‚
self.Logistic = nn.Sigmoid()    # ä¸º   Logistic æ¿€æ´»å‡½æ•°
F.softplus() # softplus    
m = nn.ReLU6()
m = nn.GeLU()  
nn.SiLU()
nn.SELU()  # ELU, 
m = nn.Hardswish()  
```

### (2) ç»éªŒé£é™©å‡½æ•°
æœ€ä¼˜åŒ–é—®é¢˜:  ç»™å®šæ•°æ®é›†$T = \{(x_1,y_1),....(x_n,y_n)\}$
åˆ™é—®é¢˜è½¬åŒ–ä¸ºæ±‚è§£
$$\min _{w,b}L(w,b)$$
é‡‡ç”¨éšæœºæ¢¯åº¦ä¸‹é™ç®—æ³•ï¼ˆéšæœºé€‰å…¶ä¸­çš„æ ·æœ¬ï¼Œå¯»æ‰¾è¯¯åˆ†ç±»ç‚¹å¹¶é€šè¿‡æ¢¯åº¦æ›´æ–°),[[å¤šå±‚æ„ŸçŸ¥æœºè®²è§£ 2022-11-26 15.27.23.excalidraw|åå‘ä¼ æ’­ç®—æ³•æ¢¯åº¦æ±‚è§£æ¨å¯¼è¿‡ç¨‹]]


## ä¸‰ã€æ¦‚ç‡å›¾æ¨¡å‹
### (1) æ¦‚ç‡å›¾æ¨¡å‹çš„æ¦‚å¿µ
é©¬å°”ç§‘å¤«é“¾éƒ¨åˆ†å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/è¡¥å……çŸ¥è¯†/6. é©¬å°”ç§‘å¤«MCSæŠ½æ ·(MCMC)|é©¬å°”ç§‘å¤«MCSæŠ½æ ·(MCMC)]] 
æ¦‚ç‡æ¨¡å‹æä¾›äº†ä¸€ç§æè¿°æ¡†æ¶, å°†æè¿°ä»»åŠ¡å½’ç»“ä¸ºè®¡ç®—æ¡ä»¶æ¦‚ç‡çš„åˆ†å¸ƒã€‚
é¦–å…ˆ, æˆ‘ä»¬è®¾å˜é‡æ•°æ®ä¸º $X$, å¹¶ä¸”ç”± $N$ ä¸ª $p$ ç»´å‘é‡æ„æˆ, ä¸”å‚æ•°ä¸º $\theta$ï¼Œ åˆ™æˆ‘ä»¬è®¡æ¦‚ç‡æ¨¡å‹ä¸º: 
$$X \sim  P (x | \theta)$$
å…¶ä¸­$X$ ä¸ºéšæœºå˜é‡, ä¸€èˆ¬åœ°æœ‰é¢‘ç‡æ´¾å’Œè´å¶æ–¯æ´¾ä¸¤ç§è§‚ç‚¹, å…¶ä¸­, é¢‘ç‡æ´¾è®¤ä¸º $\theta$ æ˜¯æœªçŸ¥å¸¸é‡,å¹¶å¯ä»¥é‡‡ç”¨[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/è¡¥å……çŸ¥è¯†/1. ML estimation æœ€å¤§ä¼¼ç„¶ä¼°è®¡|æœ€å¤§ä¼¼ç„¶ä¼°è®¡]] (MLE)è¿›è¡Œè·å–ã€‚è€Œè´å¶æ–¯æ´¾è®¤ä¸º $\theta$ æ˜¯æœä»æŸæ¦‚ç‡åˆ†å¸ƒçš„å˜é‡(è®°ä¸º $\theta \sim P( \theta)$,ç§°ä¸º<b><mark style="background: transparent; color:red">å…ˆéªŒæ¦‚ç‡åˆ†å¸ƒ</mark></b>); ä»¥è´å¶æ–¯æ³•åˆ™ä¸ºæŒ‡å¯¼, ä¸»è¦åŒ…å«<b><mark style="background: transparent; color: orange">è´å¶æ–¯ä¼°è®¡æ³•</mark></b>å’Œ [[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/è¡¥å……çŸ¥è¯†/2. MAP estimation(æœ€å¤§å•åéªŒå¯èƒ½æ€§ä¼°è®¡)|æœ€å¤§åéªŒæ¦‚ç‡ä¼°è®¡æ³•(MAP)]] ä¸¤ç§

**æ¦‚ç‡å›¾æ¨¡å‹**ä¸»è¦åˆ†ä¸ºä¸‰å¤§ç†è®ºä½“ç³»: åŒ…å«<mark style="background: transparent; color: red">è¡¨ç¤ºç†è®º,  æ¨ç†ç†è®ºå’Œå­¦ä¹ ç†è®º</mark>, å…¶æ¨¡å‹æ˜¯ç”±èŠ‚ç‚¹å’Œå¼§æ„æˆçš„å›¾, å…¶ä¸­<b><mark style="background: transparent; color: blue">æ— å‘å›¾ç§°ä¸ºé©¬å°”ç§‘å¤«ç½‘, è€Œæœ‰å‘å›¾è¢«ç§°ä¸ºè´å¶æ–¯ç½‘</mark></b>, **å…¶ä¸­éšé©¬å°”ç§‘å¤«æ¨¡å‹æ˜¯é©¬å°”ç§‘å¤«ç½‘çš„ä¸€ç§å½¢å¼**ã€‚

![[Excalidraw/9. å¤šå±‚æ„ŸçŸ¥å™¨, æ­£åˆ™åŒ–æ–¹æ³•å’Œæ¦‚ç‡å›¾æ¨¡å‹ 2024-12-09 20.43.48|450]]

å…¶ä¸­, æ¨æ–­åˆ†ä¸º ç²¾ç¡®æ¨æ–­å’Œè¿‘ä¼¼æ¨æ–­ä¸¤æ–¹é¢, å…¶ä¸­: 
ç²¾ç¡®æ¨æ–­æ¶‰åŠåˆ°çš„ç®—æ³•ä¸º
1. å˜é‡æ¶ˆé™¤æ³• 
2. ä¿¡å¿µä¼ æ’­æ³• (belief propagation| sum-product algorithm)
3. è”åˆæ ‘ç®—æ³• (Junction Tree Algorithm)

è¿‘ä¼¼æ¨æ–­æ¶‰åŠåˆ°çš„ç®—æ³•ä¸º:
1. å¾ªç¯ä¿¡å¿µä¼ æ’­æ³•: loop-belief propagation (å¤„ç†æ¦‚ç‡å›¾æœ‰ç¯ç»“æ„çš„æƒ…å½¢)
2. è’™ç‰¹å¡æ´›æ¨æ–­(è¿‘ä¼¼æ¨æ–­), åŒ…å«é‡è¦æ€§é‡‡æ ·å’Œ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æœºå™¨å­¦ä¹ ç®—æ³•(sklearn)/è¡¥å……çŸ¥è¯†/6. é©¬å°”ç§‘å¤«MCSæŠ½æ ·(MCMC)|é©¬å°”ç§‘å¤«MCSæŠ½æ ·(MCMC)]]
3. å˜åˆ†æ¨æ–­(Variational Interference)

### (2) æ¡ä»¶ç‹¬ç«‹æ€§ 
ä¸€èˆ¬åœ°, åœ¨è®¡ç®—æ¡ä»¶æ¦‚ç‡åˆ†å¸ƒæ—¶, å¤æ‚åº¦å¾€å¾€æé«˜,  è€Œ $n$ ä¸ªäºŒå€¼å˜é‡çš„è”åˆæ¦‚ç‡åˆ†å¸ƒå…±åŒ…å« $2^{n}- 1$ä¸ªç‹¬ç«‹å‚æ•°; æ­¤æ—¶**è”åˆæ¦‚ç‡çš„è·å–å’Œå­˜å‚¨ç­‰éƒ½ä¼šå³ä¸ºå›°éš¾**ã€‚

é¦–å…ˆ, å¦‚æœ $P(X|Y) = P(X)$,  æˆ–è€… $P(Y) = 0$, åˆ™ç§° $X$ å’Œ  $Y$ åœ¨ $P$ ä¸­ç›¸äº’ç‹¬ç«‹. å¹¶è®°ä¸º:
$$P |=  (X| Y)$$
è€Œ $P(X, Y)= P(X)P(Y)$ æ—¶, ç§° $X,Y$ ç‹¬ç«‹, è®°ä¸º:
$$(X \perp  Y)$$
<b><mark style="background: transparent; color: orange">æ¡ä»¶ç‹¬ç«‹æ€§çš„å®šä¹‰</mark></b>: æˆ‘ä»¬å‡è®¾ $P(X|Y, Z) = P(X|Z)$ æˆ–è€… $P(Y,Z) = 0$ æ­¤æ—¶, æˆ‘ä»¬ç§°äº‹ä»¶ $X$ ==**åœ¨ç»™å®šäº‹ä»¶ $Z$ ä¸Šæ¡ä»¶ç‹¬ç«‹äº $Y$ï¼Œ å¹¶é‡‡ç”¨å¦‚ä¸‹æ–¹æ³•è®°:**== 
$$ P |= (X \perp Y | Z)$$
å¦‚æœæœ‰ä¸Šå¼æˆç«‹, åˆ™æœ‰å…³ç³»:
$$P  (X, Y | Z) =  P(X|Z) P(Y|Z) $$
æ¦‚ç‡å›¾æ¨¡å‹çš„é‡ç‚¹æ˜¯**åˆ©ç”¨éšæœºå˜é‡ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§**, <mark style="background: transparent; color: red">å°†è”åˆåˆ†å¸ƒåˆ†è§£ä¸ºå¤šä¸ªå¤æ‚åº¦è¾ƒä½çš„æ¦‚ç‡åˆ†å¸ƒ</mark>ã€‚ ä»è€Œé™ä½æ¨¡å‹çš„å¤æ‚åº¦, æé«˜æ¨ç†æ•ˆç‡ã€‚

æˆ‘ä»¬ç»™å®š==å¦‚ä¸‹çš„ä¾‹å­==:
$$P(B, E, S, A, M) = P(B) P(E, B) P (A| B,E) P(S| A, B, E)  P(M| S, A, B, E)$$
æ˜¾ç„¶ä¸Šè¿°æœ‰ 31 ä¸ªå˜é‡, è€Œè‹¥æœ‰ $P(S\perp B, E | A)$ åˆ™ä¸Šè¿°ç®€åŒ–ä¸º: $P(S| A, B, E) = P(S|A)$ è‹¥æœ‰ $M \perp S,B,E$ (å³ M åœ¨ $A$ æ¡ä»¶ä¸‹ä¸å…¶ä»–æ— å…³), åˆ™ $P(M| S, A, B, E) = P(M| A)$; åŒæ—¶å¦‚æœ $B, E$ ç‹¬ç«‹, æœ‰ $P(E|B)= P(E)$ ä¸Šå¼ç®€åŒ–ä¸º:
$$\boxed{P(B, E, S, A, M) = P (B) P(E) P(A| B , E) P (M|A) P(S|B)}\tag{9.2}$$
åˆ™å˜é‡ä¸º 1 +  1 + 4 + 2 + 2 = 10 ä¸ª, æ˜¾è‘—ç®€åŒ–äº†è®¡ç®—è¿‡ç¨‹ã€‚

å¦å¤–, å¯¹äºä¸€èˆ¬æ¦‚ç‡åˆ†å¸ƒ $P(X_1, X_2, \dots X_n)$, æ ¹æ®é“¾å¼æ³•åˆ™, æœ‰: 
$$P(X_{1}, \dots X_{n} ) = \prod^{n}_{i=1}  P(X_{i} |  X_{1}, \dots X_{i-1})$$
å¯¹äºä»»æ„çš„ $X$, è‹¥å­˜åœ¨ $\pi (X_{i}) \subseteq \{ X_{1}, \dots X_{i-1} \}$, ä½¿å¾—å¯¹äºç»™å®šçš„ $\pi(X_i)$, æœ‰ $X_i$ <mark style="background: transparent; color: red">ä¸å…¶ä»–å˜é‡å‡ç‹¬ç«‹ï¼Œ åˆ™æœ‰å…³ç³»</mark>: 
$$\boxed{\Large P(X_{i} | X_{1},  \dots  X_{i-1}) = P(X_{i} | \pi(X_{i}))}$$

### (3) è´å¶æ–¯ç½‘ç»œå’Œé©¬å°”ç§‘å¤«å‡è®¾
#### 1. è´å¶æ–¯å…¬å¼å’Œé©¬å°”ç§‘å¤«å‡è®¾ 
é¦–å…ˆ, æˆ‘ä»¬ç»™å‡ºè´å¶æ–¯å…¬å¼(å‚è€ƒ[[ğŸ“˜ClassNotes/ğŸ“Mathmatics/ğŸ£Probability Theory/ç¬¬ä¸€ç«  éšæœºäº‹ä»¶åŠå…¶æ¦‚ç‡#å…­ã€æ¡ä»¶æ¦‚ç‡, å…¨æ¦‚ç‡å…¬å¼ä¸è´å¶æ–¯å…¬å¼|å…¨æ¦‚ç‡å…¬å¼ä¸è´å¶æ–¯å…¬å¼]]):
$$P(B_{i}| A) = \frac{P(A|B_{i}) P(B_{i})}{\sum^{n}_{j=1} P(A|B_{j}) P(B_{j})}$$
å…¶ä¸­, $B_{1}, B_{2}, \dots$ æ˜¯å…¨ç©ºé—´çš„ä¸€ä¸ªåˆ’åˆ†, æ¨å¹¿åˆ°ç§¯åˆ†éƒ¨åˆ†, åˆ™æœ‰:
$$\boxed{\Large P(x_{2} | x_{1} )= \frac{P(x_{1}, x_{2})}{P(x_{1})} = \frac{P(x_{1}, x_{2})}{ \int P(x_{1}, x_{2}dx_{2}} =\frac{P(x_{2}) \cdot  P(x_{1}| x_{2})}{\int P (x_{2}) \cdot  P (x_{1} | x_{2 }) dx_{2}}}$$
é¦–å…ˆ, <mark style="background: transparent; color: red">æœ´ç´ è´å¶æ–¯æ–¹æ³•</mark>å‡è®¾å„ä¸ªå˜é‡ç›¸äº’ç‹¬ç«‹, å¿½ç•¥ä¾èµ–å…³ç³»ã€‚æ˜¾ç„¶è¿™ä¸ªå‡è®¾æ˜¯è¿‡å¼ºçš„; å› æ­¤æˆ‘ä»¬å¼•å…¥ä»¥ä¸‹çš„ <b><mark style="background: transparent; color: orange">é©¬å°”ç§‘å¤«å‡è®¾</mark></b>: 

æˆ‘ä»¬å‡è®¾å½“å‰å˜é‡ä»…å’Œå‰$n$ä¸ªå˜é‡æ˜¯ç›¸å…³çš„, **è€Œå…¶ä½™çš„ç›¸äº’ç‹¬ç«‹**. å…¶ä¸­, æˆ‘ä»¬ä¸€èˆ¬é‡‡ç”¨<mark style="background: transparent; color: red">ä¸€é˜¶å’ŒäºŒé˜¶é©¬å°”ç§‘å¤«å‡è®¾</mark> 
1. **ä¸€é˜¶é©¬å°”ç§‘å¤«å‡è®¾**ï¼Œæœ‰:
$$x_{j} \perp  x_{i+1}  | x_{i}\qquad  j < i$$
å³<b><mark style="background: transparent; color: orange">å½“å‰åˆ†å¸ƒä»…å–å†³äºå‰ä¸€æ—¶åˆ»çš„çŠ¶æ€, è€Œä¸æ›´æ—©çš„çŠ¶æ€æ— å…³</mark></b>ã€‚è¿™ä¸ªå¯ä»¥ç®€åŒ–è®¡ç®—, ä½†æ˜¯è®°å¿†æ€§è¾ƒå·®, å³å…·æœ‰"çŸ­è®°å¿†æ€§"; ä½†æ˜¯è¯¥å‡è®¾ä»ç„¶éš¾ä»¥æ³›åŒ–ã€‚
2. å› æ­¤å®é™…ä¸Šæ›´å¤šé‡‡ç”¨**äºŒé˜¶é©¬å°”ç§‘å¤«å‡è®¾**:
$$\boxed{\large (x_{A} \perp  x_{B}  |  x_{C}) }$$
å…¶ä¸­, $x_A, x_B, x_C$ æ˜¯<mark style="background: transparent; color: red">ä¸‰ä¸ªäº’ä¸ç›¸äº¤çš„é›†åˆ</mark>, è¯¥å‡è®¾å¯ä»¥å¤§å¤§é™ä½è®¡ç®—å¤æ‚åº¦ã€‚

#### 2. è´å¶æ–¯ç½‘ç»œçš„æ¦‚å¿µ
å¯¹äºè´å¶æ–¯ç½‘ç»œ, æ˜¯ä¸€ä¸ªæœ‰å‘æ— ç¯å›¾, <b><mark style="background: transparent; color: orange">ç”¨äºè¡¨ç¤ºå˜é‡ä¹‹é—´çš„æ¡ä»¶ç‹¬ç«‹æ€§</mark></b>, ä¸€èˆ¬éœ€è¦é‡‡ç”¨[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸŒ³Data Structure & Algorithms/ã€½ï¸ Data Structure/ç¬¬ä¸ƒç«  å›¾|æ‹“æ‰‘æ’åº]]æ–¹æ³•, <mark style="background: transparent; color: red">ä¾æ®æ¡ä»¶æ¦‚ç‡ç¡®å®šå˜é‡ä¹‹é—´çš„ä¾èµ–å…³ç³»</mark>ã€‚

æ ¹æ®ä¸Šè¿°å‡è®¾,  æˆ‘ä»¬å°†æ•°æ®åˆ†ä¸º A, B, C éƒ¨åˆ†, å› æ­¤ä¸€èˆ¬æœ‰å¦‚ä¸‹ä¸‰ç§åŸºæœ¬å½¢å¼:
![[Excalidraw/9. å¤šå±‚æ„ŸçŸ¥å™¨, æ­£åˆ™åŒ–æ–¹æ³•å’Œæ¦‚ç‡å›¾æ¨¡å‹ 2024-12-09 23.40.39|600]]

ä¾‹å¦‚ B,E ç‹¬ç«‹, è€Œ A ä¾èµ–äº B,E; è€Œ A ä¾èµ–äº B,E; A å¯èƒ½è§¦å‘ F,G åˆ™æ„å»ºè´å¶æ–¯ç½‘å¦‚ä¸‹æ‰€ç¤º:
![[Excalidraw/9. å¤šå±‚æ„ŸçŸ¥å™¨, æ­£åˆ™åŒ–æ–¹æ³•å’Œæ¦‚ç‡å›¾æ¨¡å‹ 2024-12-09 23.52.51|250]]
æ­¤æ—¶å¯ä»¥ç›´æ¥å°†äº”ä¸ªå˜é‡çš„æ¦‚ç‡ç›¸ä¹˜å¾—åˆ°æœ€ç»ˆæ¦‚ç‡:
$$P(A, B, E, S,G) = P(B) P(E) P(A | B, E) P(F|A) P(G|A)$$
ä¸å¼ (9.2)ç›¸åŒ,è€Œä¸Šè¿°æ¯ä¸ªå˜é‡éƒ½æœ‰æ˜ç¡®çš„æ¦‚ç‡åˆ†å¸ƒ, å³<mark style="background: transparent; color: red">æ˜¾è‘—ç®€åŒ–äº†æ¦‚ç‡è®¡ç®—è¿‡ç¨‹</mark>ã€‚

å¯¹äºè´å¶æ–¯ç½‘ç»œ, ä¸»è¦å…³æ³¨çš„æ˜¯**æœ€å¤§åéªŒæ¦‚ç‡å‡è®¾**é—®é¢˜, ä»¥åŠæœ€å¤§å¯èƒ½è§£é‡Šé—®é¢˜

### (4) éšé©¬å°”ç§‘å¤«æ¨¡å‹(HMM)
#### 1. é©¬å°”ç§‘å¤«éšæœºåœº
åœ¨é©¬å°”ç§‘å¤«éšæœºåœºä¸­, è¦æ±‚æ»¡è¶³ä¸‰ä¸ªæ€§è´¨:
1. å…¨å±€é©¬å°”ç§‘å¤«æ€§: å›¢ $A$ å¿…é¡»ç»è¿‡å›¢ $B$ æ‰èƒ½åˆ°è¾¾å›¢ $C$, åˆ™ç§°å›¢ A, C <mark style="background: transparent; color: red">æ¡ä»¶ç‹¬ç«‹</mark>
2. å±€éƒ¨é©¬å°”ç§‘å¤«æ€§: **æŸä¸ªå˜é‡åœ¨ç»™å®šå…¶å…¨éƒ¨ç›¸é‚»èŠ‚ç‚¹çš„æƒ…å†µä¸‹, ä¸éé‚»èŠ‚ç‚¹æ¡ä»¶ç‹¬ç«‹**
3. æˆå¯¹é©¬å°”ç§‘å¤«æ€§: å¯¹äº $AB$ ä¹‹é—´æ²¡æœ‰è¾¹è¿æ¥, æ­¤æ—¶ç»™å®šé™¤äº† $A, B$ æ‰€æœ‰èŠ‚ç‚¹çš„æ¡ä»¶ä¸‹, $A, B$ æ¡ä»¶ç‹¬ç«‹

åœ¨é©¬å°”ç§‘å¤«éšæœºåœºä¸­ ï¼Œ æœ‰å¯¹äºè´å¶æ–¯ç½‘ç»œä¸‰ç§æ¨¡å‹, æœ‰:
![[Excalidraw/9. å¤šå±‚æ„ŸçŸ¥å™¨, æ­£åˆ™åŒ–æ–¹æ³•å’Œæ¦‚ç‡å›¾æ¨¡å‹ 2024-12-09 23.40.39|600]]
å¯¹åº”é©¬å°”ç§‘å¤«é“¾æ¦‚ç‡è¡¨è¾¾:
1. tail-tail
$$P(A, B, C) \propto  \phi(A, B) \phi(A,C)  = P (A) P(B|A) P(C|A)$$
2. tail-head
$$P(A, B, C) \propto \phi(A, B) \phi(B, C)$$
3. head-head 
$$P(A, B, C) \propto \phi (B,  A) \phi(B, C) \phi(A, C) $$
æ³¨æ„: ç”±äºç¢°æ’ç‚¹ $A$ çš„å­˜åœ¨, å¼•å…¥äº† $B,C$ ä¹‹é—´çš„ä¾èµ–æ€§;

#### 2. éšé©¬å°”ç§‘å¤«æ¨¡å‹
éšé©¬å°”ç§‘å¤«æ¨¡å‹(Hidden Markov Model, HMM)ä¸€èˆ¬å°†çŠ¶æ€åˆ†ä¸ºæ˜¾çŠ¶æ€å’ŒéšçŠ¶æ€. å…¶ä¸­æ˜¾çŠ¶æ€ä¸ºå¯è§‚æµ‹çŠ¶æ€èŒƒå›´, è€Œå®é™…éœ€è¦é¢„æµ‹çš„æ˜¯éšçŠ¶æ€; å¯å‚è€ƒ [çŸ¥ä¹æ–‡ç« éƒ¨åˆ†](https://zhuanlan.zhihu.com/p/85454896) 
![[attachments/IMG_20241210_002446_edit_497445432396903.jpg|400]]
æˆ‘ä»¬å– $\pi$ å‘é‡ä¸ºä¸€ä¸ªè§‚å¯ŸçŠ¶æ€åˆ°æ¯ä¸ªéšçŠ¶æ€çš„å‘é‡, ä¹Ÿç§°ä¸º<b><mark style="background: transparent; color: orange">åˆå§‹æ¦‚ç‡</mark></b>, è¡¨ç¤º<mark style="background: transparent; color: red">åˆå§‹æ—¶åˆ»è§‚å¯ŸçŸ©é˜µè½¬æ¢åˆ°éšçŠ¶æ€çš„æ¦‚ç‡</mark> 

å®šä¹‰ä¸€ä¸ªé©¬å°”ç§‘å¤«æ¨¡å‹æ˜¯ä¸€ä¸ªäº”å…ƒç»„$(S,O, \Pi , A, B$):
1. S ä¸ºä¸€ä¸ªç³»ç»Ÿåœ¨ $t$ æ—¶åˆ»çš„çŠ¶æ€ç©ºé—´é›†åˆ, 
2. O ä¸ºè¾“å‡ºçŠ¶æ€ç©ºé—´é›†åˆ $(S_1, \dots S_n)$ 
3. $\Pi = (\pi_{i})$ åˆå§‹åŒ–æ¦‚ç‡å‘é‡çŸ©é˜µ, å³**åˆå§‹åŒ–çš„éšçŠ¶æ€å–å¾—çš„æ¦‚ç‡å‘é‡**
4. $A=a_{ij}$ <mark style="background: transparent; color: red">çŠ¶æ€è½¬ç§»çŸ©é˜µ</mark> (å®é™…ä¸Šæ˜¯<b><mark style="background: transparent; color: orange">éšçŠ¶æ€ä¹‹é—´çš„è½¬ç§»æ¦‚ç‡</mark></b>)
5. $B = b_{ij}$ <mark style="background: transparent; color: red">æ··æ·†çŸ©é˜µ</mark> (ä¹Ÿç§°ä¸ºå‘å°„æ¦‚ç‡, åŒ…å«æ¯ä¸ª**ç»™å®šæ¯ä¸ªéšè—çŠ¶æ€è½¬æ¢åˆ°è§‚å¯ŸçŠ¶æ€çš„æ¦‚ç‡**)

æ­¤æ—¶, ä»¥**éšçŠ¶æ€ä¸ºçºµè½´ï¼Œ æ˜¾çŠ¶æ€ä¸ºæ¨ªè½´**, ç»™å‡ºæ¯ä¸ªéšçŠ¶æ€ä¸‹ï¼Œå–å¾—æ˜¾çŠ¶æ€çš„æ¦‚ç‡ï¼Œç§°ä¸º<b><mark style="background: transparent; color: orange">å‘å°„çŸ©é˜µ B</mark></b>, æ˜¾çŠ¶æ€çš„æ¦‚ç‡ç”±**å‘å°„æ¦‚ç‡çŸ©é˜µ**(Emission Matrix)å®šä¹‰ï¼Œ<mark style="background: transparent; color: red">æ˜¯å…³äºéšçŠ¶æ€äº§ç”Ÿæ˜¾çŠ¶æ€çš„æ¦‚ç‡</mark>;

HMM åŸºæœ¬é—®é¢˜ä¸»è¦æœ‰ 
1. æ¦‚ç‡è®¡ç®— : ç»™å®š $\lambda = (\pi, A, B)$ å’Œè§‚æµ‹åºåˆ— $X = (x_1, x_2, \dots x_r)$ è®¡ç®—è§‚æµ‹åºåˆ—æ¡ä»¶æ¦‚ç‡ $P(X|\lambda)$ 
2. å‚æ•°å­¦ä¹  : ç»™å®š $X$ è§‚æµ‹åºåˆ—, æ¨å¯¼ $\pi, A, B$
3. è§£ç é—®é¢˜(æœ€å¤§åéªŒå‡è®¾é—®é¢˜) : å–å®é™…çš„åºåˆ—ä¸º $z_{1}, z_2,\dots z_r$, æ±‚è§£å¯èƒ½æ€§æœ€å¤§çš„ $Z = (z_{1}, \dots  z_{r})$

æœ‰å¦‚ä¸‹çš„å‡ ä¸ªå‡è®¾:
1. é½æ¬¡é©¬å°”ç§‘å¤«å‡è®¾: ä»»ä¸€æ—¶åˆ»çš„çŠ¶æ€ä»…ä¾èµ–äºå‰ä¸€æ—¶åˆ»çš„çŠ¶æ€ã€‚
$$P (z_{i}| z_{i-1}, \dots z_{1}, x_{t},...) = z(z_{t} | z_{t-1})$$
2. è¾“å‡ºç‹¬ç«‹æ€§å‡è®¾: **è§‚æµ‹çŠ¶æ€ä»…ä¾èµ–äºè¯¥æ—¶åˆ»çš„éšçŠ¶æ€**ï¼Œè€Œä¸å…¶ä»–æ— å…³:
$$P(x_{t} | x_{t-1}, \dots  x_{1} , z_{t}, \dots ) = P(x_{t}| z_{t})$$
3. ä¸åŠ¨æ€§å‡è®¾: è¾“å‡ºçš„éšçŠ¶æ€çš„è½¬ç§»çŸ©é˜µæ˜¯å¸¸æ•°, å› æ­¤ä¸æ—¶åˆ»æ— å…³:
$$P(z_{i + 1} | z_{i}) = P(z_{j+  1}| z_{j} )$$

