常见的深度学习算法包含: 
1. 多层感知器 
2. 卷积神经网络 (LeNet) 
3. 递归神经网络 (RNN) 
4. LSTM 网络 
5. 稀疏编码器 
6. 堆叠自动编码器 
7. 深度置信网络 
8. 混合 MonteCarlo 抽样 
9. 压缩自动编码器   
10. RNN-RBM 网络 

一般地, 正则化方法是神经网络中的常用方法。训练模型时，如果 MSGD 算法不考虑正则化方法, 则有可能导致过拟合。而在实际神经网络中, 最常用的正则化方法包括两类, Early Stop 和 L1/L2 正则化, 是在有监督的深度学习中常用到的防止过拟合的办法。

#### 1. Early Stop 正则化
该方法的思路部分, 实际上是<b><mark style="background: transparent; color: orange">通过检测新的验证集中的指标来防止过拟合</mark></b>, 一般会设置一个验证频率(级数增长), 多次训练之后验证一次。如果模型的性能在验证集上不发生显著提高(损失下降 < best_loss * threshold), 甚至下降时, 则触发提前终止条件。

#### 2. L1/L2 正则化方法
L1/L2 正则化方法是使用于 MLP(Multilayer perception，多层感知器网络)的<mark style="background: transparent; color: red">权重泛化问题</mark>的正则化方法。
如果损失函数为:
$$NLL(\theta, D) = - \sum_{i = 0}^{|D|} \log P  (Y= y^{(i)}|  x^{(i)} , \theta)$$
则有正则化的损失: 
$$E (\theta, D) = NLL(\theta, D) + \lambda R(\theta)$$
其中取惩罚参数(降低非线性) $R(\theta)$ 可取为 $\theta$ 的[[📘ClassNotes/📐Mathmatics/✖️Matrix Theory/2. 范数理论及其应用|p范数]]:
$$R(\theta) = ||\theta||_{p}^{p} = \left(\sum_{j = 0}^{n} |\theta_{j}|^{p}  \right)^{\frac{1}{p}}$$
其中, $\lambda$ 控制正则化参数的重要性, 并且**按照 p = 1, 2 分别称为 L1, L2 正则化方法**。但是这种泛化方法一般在小规模数据集上有一定的帮助。

例如下面给出一个采用 torch 进行 L1 正则化的简单示例, 其中采用 model.parameters 访问了所有的 param，并且<mark style="background: transparent; color: red">计算平方和附加到 loss 中</mark>, 即对实际上的参数部分施加了正则化方法:
```python
lambda_l1 = 0.01 # L1 正则化强度 
lambda_l2 = 0.01 # L2 正则化强度
# 初始化模型、损失函数和优化器
model = LogisticRegressionModel(input_dim, output_dim)
criterion = nn.BCELoss()  # 二分类交叉熵损失
optimizer = optim.SGD(model.parameters(), lr=learning_rate)
# 训练模型
for epoch in range(epochs):
    # 前向传播
    y_pred = model(X)
    loss = criterion(y_pred, y)
    # 添加 L1 和 L2 正则化
    l1_penalty = torch.tensor(0.0)
    l2_penalty = torch.tensor(0.0)
    for param in model.parameters():
        l1_penalty += torch.sum(torch.abs(param))  # L1 正则化项
        l2_penalty += torch.sum(param ** 2)  # L2 正则化项
    loss += lambda_l1 * l1_penalty + lambda_l2 * l2_penalty # 更新 loss 参数 
    # 反向传播和优化
    optimizer.zero_grad()
    loss.backward()
    optimizer.step()
    # 打印训练进度
    if (epoch + 1) % 100 == 0:
        print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')

# 模型测试
with torch.no_grad():
    test_input = torch.tensor([[0.5, -0.5], [-1.0, 1.0], [1.0, 1.0]])
    test_output = model(test_input)
    print("\nTest Input:", test_input)
    print("Predicted Output:", test_output)
```

需要说明的是, 一般采用的 L2 正则化方法也称为权重衰减方法(weight decay), 如下: 

`````ad-note
title: Weight decay
collapse: open

Weight decay, also known as **L2 regularization**, is a technique used in deep learning to prevent overfitting by penalizing large weights in the model. Here’s a detailed introduction to weight decay:

### What is Weight Decay?

Weight decay is a regularization technique that adds a penalty term to the loss function, which is proportional to the sum of the squared weights of the model. [This penalty term discourages the model from assigning too much importance to any single feature, thereby promoting simpler models that generalize better to unseen data](https://d2l.ai/chapter_linear-regression/weight-decay.html)[1](https://d2l.ai/chapter_linear-regression/weight-decay.html)[2](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/).

### How Does Weight Decay Work?

The primary loss function (L_{\text{original}}(w)) is modified to include the weight decay term, resulting in a new loss function (L_{\text{new}}(w)):

$$L_{\text{new}}(w) = L_{\text{original}}(w) + \lambda \sum_{i} w_i^2$$

Here, (w) represents the weights of the model, and (\lambda) is a hyperparameter that controls the strength of the regularization. [The larger the value of (\lambda), the more the weights are penalized](https://d2l.ai/chapter_linear-regression/weight-decay.html)[3](https://paperswithcode.com/method/weight-decay).

### Why Use Weight Decay?

Weight decay helps in:

1. [**Reducing Overfitting**: By penalizing large weights, weight decay prevents the model from fitting the noise in the training data, leading to better generalization on new data](https://d2l.ai/chapter_linear-regression/weight-decay.html)[2](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/).
2. [**Improving Model Stability**: Smaller weights lead to a more stable model that is less sensitive to small changes in the input data](https://d2l.ai/chapter_linear-regression/weight-decay.html)[1](https://d2l.ai/chapter_linear-regression/weight-decay.html).

### Implementing Weight Decay

Weight decay can be implemented in various deep learning frameworks. For example, in Keras, you can add weight regularization to a layer using the `kernel_regularizer` argument:

```python
from keras.layers import Dense
from keras.regularizers import l2

model.add(Dense(32, kernel_regularizer=l2(0.01)))
```

[This code snippet adds an L2 regularizer with a penalty factor of 0.01 to a dense layer](https://d2l.ai/chapter_linear-regression/weight-decay.html)[2](https://machinelearningmastery.com/how-to-reduce-overfitting-in-deep-learning-with-weight-regularization/).

### Conclusion 
Weight decay is a powerful and widely-used regularization technique in deep learning. By adding a penalty term to the loss function, it helps in reducing overfitting and improving the generalization of the model. Understanding and effectively using weight decay can significantly enhance the performance of your deep learning models.
`````

需要说明的是, 绝大多数 Pytorch 中的模型都支持采用 weight-decay 参数, 例如:
```python
# 创建优化器，并设置 weight_decay 参数 
optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.01) # L2 权重衰减
```

需要说明的是, 如果希望偏置层或者归一化层等的部分不受权重衰减影响,则可以进行权重分组:
```python
# 手动将参数分组
param_groups = [
    {'params': [param for name, param in model.named_parameters() if 'bias' in name], 'weight_decay': 0.0},
    {'params': [param for name, param in model.named_parameters() if 'bias' not in name], 'weight_decay': 0.01}
]
# 初始化优化器
optimizer = optim.Adam(param_groups, lr=0.001)
# 剩余训练过程与上述相同
```

## 二、多层感知机
### (1) 多层感知机概念
多层感知机实际上是分类器, 类似于[[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓机器学习算法(sklearn)/补充知识/4. KNN算法和KMeans聚类相关算法|KNN算法和KMeans算法]]部分. 
多层感知机是至少含有一个隐藏层的由全连接层组成的神经网络, 每个隐藏层的输出通过激活函数进行变换。其基本结构是 <mark style="background: transparent; color: red">输入-> 隐藏层 -> 输出</mark>, 其中包含隐藏单元, 为一个2层的神经网络; 记隐藏层的输出为H, 而两层的权重向量为 $W_h$ 和 $W_o$, 则: 
$$H =\phi(XW_{h} + b_{h})   \qquad   O = HW_o + b_o$$
经过联立，可得到:
$$O =\phi (XW_h + b_h)W_o + b_{o}$$
其中学习参数为 $\theta = (W_{o}, b_{o},  W_{h}, b_{h})$
需要说明的是, 如果不增加激活函数, 则有:
$$O =   XW_{h} W_{o}  + (b_{h} W_{o} + b_{o})$$
<mark style="background: transparent; color: red">即使再添加更多的隐藏层，不加激活函数的设计仍然只能与仅含输出层的单层神经网络等价</mark>(其中，输出层权重参数为$W_hW_o$,偏差参数为$b_hW_o+b_o$)

其中, 激活函数 $\phi$ 可以参考[常见的激活函数部分](https://blog.csdn.net/caip12999203000/article/details/127067360), 同时一般选用 ReLU 或者 tanh  函数, 输出层如果是分类问题, 一般采用 [[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓机器学习算法(sklearn)/4. 最优化方法, 梯度寻优法及Logistic 回归|Logistic 函数]](Sigmoid函数) 将获得的$(-\infty, +\infty)$ 范围的结果投影到 (0, 1)之间。

```python
import torch.nn as nn   
from torch.nn import functional as F

self.Linear  = nn.Linear(input_dim,  output_dim) # 建立全连接层
self.Logistic = nn.Sigmoid()    # 为   Logistic 激活函数
F.softplus() # softplus    
m = nn.ReLU6()
m = nn.GeLU()  
nn.SiLU()
nn.SELU()  # ELU, 
m = nn.Hardswish()  
```

### (2) 经验风险函数
最优化问题:  给定数据集$T = \{(x_1,y_1),....(x_n,y_n)\}$
则问题转化为求解
$$\min _{w,b}L(w,b)$$
采用随机梯度下降算法（随机选其中的样本，寻找误分类点并通过梯度更新),[[多层感知机讲解 2022-11-26 15.27.23.excalidraw|反向传播算法梯度求解推导过程]]


## 三、概率图模型
### (1) 概率图模型的概念
马尔科夫链部分参考[[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓机器学习算法(sklearn)/补充知识/6. 马尔科夫MCS抽样(MCMC)|马尔科夫MCS抽样(MCMC)]] 
概率模型提供了一种描述框架, 将描述任务归结为计算条件概率的分布。
首先, 我们设变量数据为 $X$, 并且由 $N$ 个 $p$ 维向量构成, 且参数为 $\theta$， 则我们计概率模型为: 
$$X \sim  P (x | \theta)$$
其中$X$ 为随机变量, 一般地有频率派和贝叶斯派两种观点, 其中, 频率派认为 $\theta$ 是未知常量,并可以采用[[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓机器学习算法(sklearn)/补充知识/1. ML estimation 最大似然估计|最大似然估计]] (MLE)进行获取。而贝叶斯派认为 $\theta$ 是服从某概率分布的变量(记为 $\theta \sim P( \theta)$,称为<b><mark style="background: transparent; color:red">先验概率分布</mark></b>); 以贝叶斯法则为指导, 主要包含<b><mark style="background: transparent; color: orange">贝叶斯估计法</mark></b>和 [[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓机器学习算法(sklearn)/补充知识/2. MAP estimation(最大单后验可能性估计)|最大后验概率估计法(MAP)]] 两种

**概率图模型**主要分为三大理论体系: 包含<mark style="background: transparent; color: red">表示理论,  推理理论和学习理论</mark>, 其模型是由节点和弧构成的图, 其中<b><mark style="background: transparent; color: blue">无向图称为马尔科夫网, 而有向图被称为贝叶斯网</mark></b>, **其中隐马尔科夫模型是马尔科夫网的一种形式**。

![[Excalidraw/9. 多层感知器, 正则化方法和概率图模型 2024-12-09 20.43.48|450]]

其中, 推断分为 精确推断和近似推断两方面, 其中: 
精确推断涉及到的算法为
1. 变量消除法 
2. 信念传播法 (belief propagation| sum-product algorithm)
3. 联合树算法 (Junction Tree Algorithm)

近似推断涉及到的算法为:
1. 循环信念传播法: loop-belief propagation (处理概率图有环结构的情形)
2. 蒙特卡洛推断(近似推断), 包含重要性采样和[[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓机器学习算法(sklearn)/补充知识/6. 马尔科夫MCS抽样(MCMC)|马尔科夫MCS抽样(MCMC)]]
3. 变分推断(Variational Interference)

### (2) 条件独立性 
一般地, 在计算条件概率分布时, 复杂度往往极高,  而 $n$ 个二值变量的联合概率分布共包含 $2^{n}- 1$个独立参数; 此时**联合概率的获取和存储等都会即为困难**。

首先, 如果 $P(X|Y) = P(X)$,  或者 $P(Y) = 0$, 则称 $X$ 和  $Y$ 在 $P$ 中相互独立. 并记为:
$$P |=  (X| Y)$$
而 $P(X, Y)= P(X)P(Y)$ 时, 称 $X,Y$ 独立, 记为:
$$(X \perp  Y)$$
<b><mark style="background: transparent; color: orange">条件独立性的定义</mark></b>: 我们假设 $P(X|Y, Z) = P(X|Z)$ 或者 $P(Y,Z) = 0$ 此时, 我们称事件 $X$ ==**在给定事件 $Z$ 上条件独立于 $Y$， 并采用如下方法记:**== 
$$ P |= (X \perp Y | Z)$$
如果有上式成立, 则有关系:
$$P  (X, Y | Z) =  P(X|Z) P(Y|Z) $$
概率图模型的重点是**利用随机变量之间的条件独立性**, <mark style="background: transparent; color: red">将联合分布分解为多个复杂度较低的概率分布</mark>。 从而降低模型的复杂度, 提高推理效率。

我们给定==如下的例子==:
$$P(B, E, S, A, M) = P(B) P(E, B) P (A| B,E) P(S| A, B, E)  P(M| S, A, B, E)$$
显然上述有 31 个变量, 而若有 $P(S\perp B, E | A)$ 则上述简化为: $P(S| A, B, E) = P(S|A)$ 若有 $M \perp S,B,E$ (即 M 在 $A$ 条件下与其他无关), 则 $P(M| S, A, B, E) = P(M| A)$; 同时如果 $B, E$ 独立, 有 $P(E|B)= P(E)$ 上式简化为:
$$\boxed{P(B, E, S, A, M) = P (B) P(E) P(A| B , E) P (M|A) P(S|B)}\tag{9.2}$$
则变量为 1 +  1 + 4 + 2 + 2 = 10 个, 显著简化了计算过程。

另外, 对于一般概率分布 $P(X_1, X_2, \dots X_n)$, 根据链式法则, 有: 
$$P(X_{1}, \dots X_{n} ) = \prod^{n}_{i=1}  P(X_{i} |  X_{1}, \dots X_{i-1})$$
对于任意的 $X$, 若存在 $\pi (X_{i}) \subseteq \{ X_{1}, \dots X_{i-1} \}$, 使得对于给定的 $\pi(X_i)$, 有 $X_i$ <mark style="background: transparent; color: red">与其他变量均独立， 则有关系</mark>: 
$$\boxed{\Large P(X_{i} | X_{1},  \dots  X_{i-1}) = P(X_{i} | \pi(X_{i}))}$$

### (3) 贝叶斯网络和马尔科夫假设
#### 1. 贝叶斯公式和马尔科夫假设 
首先, 我们给出贝叶斯公式(参考[[📘ClassNotes/📐Mathmatics/🎣Probability Theory/第一章 随机事件及其概率#六、条件概率, 全概率公式与贝叶斯公式|全概率公式与贝叶斯公式]]):
$$P(B_{i}| A) = \frac{P(A|B_{i}) P(B_{i})}{\sum^{n}_{j=1} P(A|B_{j}) P(B_{j})}$$
其中, $B_{1}, B_{2}, \dots$ 是全空间的一个划分, 推广到积分部分, 则有:
$$\boxed{\Large P(x_{2} | x_{1} )= \frac{P(x_{1}, x_{2})}{P(x_{1})} = \frac{P(x_{1}, x_{2})}{ \int P(x_{1}, x_{2}dx_{2}} =\frac{P(x_{2}) \cdot  P(x_{1}| x_{2})}{\int P (x_{2}) \cdot  P (x_{1} | x_{2 }) dx_{2}}}$$
首先, <mark style="background: transparent; color: red">朴素贝叶斯方法</mark>假设各个变量相互独立, 忽略依赖关系。显然这个假设是过强的; 因此我们引入以下的 <b><mark style="background: transparent; color: orange">马尔科夫假设</mark></b>: 

我们假设当前变量仅和前$n$个变量是相关的, **而其余的相互独立**. 其中, 我们一般采用<mark style="background: transparent; color: red">一阶和二阶马尔科夫假设</mark> 
1. **一阶马尔科夫假设**，有:
$$x_{j} \perp  x_{i+1}  | x_{i}\qquad  j < i$$
即<b><mark style="background: transparent; color: orange">当前分布仅取决于前一时刻的状态, 而与更早的状态无关</mark></b>。这个可以简化计算, 但是记忆性较差, 即具有"短记忆性"; 但是该假设仍然难以泛化。
2. 因此实际上更多采用**二阶马尔科夫假设**:
$$\boxed{\large (x_{A} \perp  x_{B}  |  x_{C}) }$$
其中, $x_A, x_B, x_C$ 是<mark style="background: transparent; color: red">三个互不相交的集合</mark>, 该假设可以大大降低计算复杂度。

#### 2. 贝叶斯网络的概念
对于贝叶斯网络, 是一个有向无环图, <b><mark style="background: transparent; color: orange">用于表示变量之间的条件独立性</mark></b>, 一般需要采用[[📘ClassNotes/⌨️Programming/🌳Data Structure & Algorithms/〽️ Data Structure/第七章 图|拓扑排序]]方法, <mark style="background: transparent; color: red">依据条件概率确定变量之间的依赖关系</mark>。

根据上述假设,  我们将数据分为 A, B, C 部分, 因此一般有如下三种基本形式:
![[Excalidraw/9. 多层感知器, 正则化方法和概率图模型 2024-12-09 23.40.39|600]]

例如 B,E 独立, 而 A 依赖于 B,E; 而 A 依赖于 B,E; A 可能触发 F,G 则构建贝叶斯网如下所示:
![[Excalidraw/9. 多层感知器, 正则化方法和概率图模型 2024-12-09 23.52.51|250]]
此时可以直接将五个变量的概率相乘得到最终概率:
$$P(A, B, E, S,G) = P(B) P(E) P(A | B, E) P(F|A) P(G|A)$$
与式 (9.2)相同,而上述每个变量都有明确的概率分布, 即<mark style="background: transparent; color: red">显著简化了概率计算过程</mark>。

对于贝叶斯网络, 主要关注的是**最大后验概率假设**问题, 以及最大可能解释问题

### (4) 隐马尔科夫模型(HMM)
#### 1. 马尔科夫随机场
在马尔科夫随机场中, 要求满足三个性质:
1. 全局马尔科夫性: 团 $A$ 必须经过团 $B$ 才能到达团 $C$, 则称团 A, C <mark style="background: transparent; color: red">条件独立</mark>
2. 局部马尔科夫性: **某个变量在给定其全部相邻节点的情况下, 与非邻节点条件独立**
3. 成对马尔科夫性: 对于 $AB$ 之间没有边连接, 此时给定除了 $A, B$ 所有节点的条件下, $A, B$ 条件独立

在马尔科夫随机场中 ， 有对于贝叶斯网络三种模型, 有:
![[Excalidraw/9. 多层感知器, 正则化方法和概率图模型 2024-12-09 23.40.39|600]]
对应马尔科夫链概率表达:
1. tail-tail
$$P(A, B, C) \propto  \phi(A, B) \phi(A,C)  = P (A) P(B|A) P(C|A)$$
2. tail-head
$$P(A, B, C) \propto \phi(A, B) \phi(B, C)$$
3. head-head 
$$P(A, B, C) \propto \phi (B,  A) \phi(B, C) \phi(A, C) $$
注意: 由于碰撞点 $A$ 的存在, 引入了 $B,C$ 之间的依赖性;

#### 2. 隐马尔科夫模型
隐马尔科夫模型(Hidden Markov Model, HMM)一般将状态分为显状态和隐状态. 其中显状态为可观测状态范围, 而实际需要预测的是隐状态; 可参考 [知乎文章部分](https://zhuanlan.zhihu.com/p/85454896) 
![[attachments/IMG_20241210_002446_edit_497445432396903.jpg|400]]
我们取 $\pi$ 向量为一个观察状态到每个隐状态的向量, 也称为<b><mark style="background: transparent; color: orange">初始概率</mark></b>, 表示<mark style="background: transparent; color: red">初始时刻观察矩阵转换到隐状态的概率</mark> 

定义一个马尔科夫模型是一个五元组$(S,O, \Pi , A, B$):
1. S 为一个系统在 $t$ 时刻的状态空间集合, 
2. O 为输出状态空间集合 $(S_1, \dots S_n)$ 
3. $\Pi = (\pi_{i})$ 初始化概率向量矩阵, 即**初始化的隐状态取得的概率向量**
4. $A=a_{ij}$ <mark style="background: transparent; color: red">状态转移矩阵</mark> (实际上是<b><mark style="background: transparent; color: orange">隐状态之间的转移概率</mark></b>)
5. $B = b_{ij}$ <mark style="background: transparent; color: red">混淆矩阵</mark> (也称为发射概率, 包含每个**给定每个隐藏状态转换到观察状态的概率**)

此时, 以**隐状态为纵轴， 显状态为横轴**, 给出每个隐状态下，取得显状态的概率，称为<b><mark style="background: transparent; color: orange">发射矩阵 B</mark></b>, 显状态的概率由**发射概率矩阵**(Emission Matrix)定义，<mark style="background: transparent; color: red">是关于隐状态产生显状态的概率</mark>;

HMM 基本问题主要有 
1. 概率计算 : 给定 $\lambda = (\pi, A, B)$ 和观测序列 $X = (x_1, x_2, \dots x_r)$ 计算观测序列条件概率 $P(X|\lambda)$ 
2. 参数学习 : 给定 $X$ 观测序列, 推导 $\pi, A, B$
3. 解码问题(最大后验假设问题) : 取实际的序列为 $z_{1}, z_2,\dots z_r$, 求解可能性最大的 $Z = (z_{1}, \dots  z_{r})$

有如下的几个假设:
1. 齐次马尔科夫假设: 任一时刻的状态仅依赖于前一时刻的状态。
$$P (z_{i}| z_{i-1}, \dots z_{1}, x_{t},...) = z(z_{t} | z_{t-1})$$
2. 输出独立性假设: **观测状态仅依赖于该时刻的隐状态**，而与其他无关:
$$P(x_{t} | x_{t-1}, \dots  x_{1} , z_{t}, \dots ) = P(x_{t}| z_{t})$$
3. 不动性假设: 输出的隐状态的转移矩阵是常数, 因此与时刻无关:
$$P(z_{i + 1} | z_{i}) = P(z_{j+  1}| z_{j} )$$

