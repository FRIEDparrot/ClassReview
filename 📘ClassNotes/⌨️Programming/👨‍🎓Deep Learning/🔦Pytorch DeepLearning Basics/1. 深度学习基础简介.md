DeepLearning 主要的层次包含 <mark style="background: transparent; color: red">感知, 推理, 知识, 规划</mark> 四个方面。 最常使用的部分包含自然语言处理, 计算机视觉(图片分类和检测部分)等等。

一般对于超大数据集部分, 采用 Top5 准确率部分. High Level -> 目标检测; Low Level 的目标 分割方式。样式迁移等等。
![[Pasted image 20221121201818.png|500]]

## 一、线性代数基础知识

$$||a \cdot  b || = \left| a\right| \cdot  || b||$$
$$c = a B $$
$$y =  Ax$$
实际上是**空间的变形**, 实际上是向量的数量积作为基本单元进行理解

用的较多的是 矩阵的[[📘ClassNotes/📐Mathmatics/✖️Matrix Theory/2. 范数理论及其应用#(1) 矩阵的 M1, M2 和 F 范数|F 范数]], 常用于构造 Loss 函数
$$\Large \boxed{||A||_{F} = \left( \sum_{i = 1}^{m} \sum_{j = 1}^{n}  \left|a_{ij}^{2} \right|\right)^{\frac{1}{2}} =  \text{tr} (A^{H} A )^{\frac{1}{2}}}$$

正定矩阵:
$$ x^{T }x \geq  0 \overset{推广}{\longrightarrow}  x^{T } A  x \geq 0$$
时为正定二次型

正交矩阵定义基于正交的列向量:
$$A^{T} A = 1$$
置换矩阵:[[📘ClassNotes/📐Mathmatics/✖️Matrix Theory/4. 矩阵分解#(2) Hermite 标准型方法|置换矩阵部分]]
特征值等等 

对于图片(B, C,H, W); 一组的  RGB 视频部分, 一般采用 $batch\_size \times  time \times  R * G * B$

一般地, 对于尖点不可导点, 我们一般取其导数为<b><mark style="background: transparent; color: orange">亚导数</mark></b>, 例如任取 $a$ 在$[-1, 1]$之间:
$$\frac{\partial |x|}{\partial x} = \begin{cases}
1   \\
-1  \\
a \qquad   x = 0, a \in [-1,1]
\end{cases}$$

首先, 求导扩充包含:
$$\frac{\partial y}{\partial \boldsymbol{x}}\qquad  \frac{\partial \boldsymbol{y}}{\partial \boldsymbol{x}}$$
具体参考[[📘ClassNotes/📐Mathmatics/✖️Matrix Theory/3. 矩阵序列，矩阵级数与矩阵函数#(1) 矩阵的微分|矩阵的微分]]部分
规定标量对于列向量求导是行向量(即将向量拉到行上)例如
$$x = \left[\begin{matrix}
x_{1} \\  x_{2}  \\  \dots  \\ x_{n}
\end{matrix}\right] \qquad  \frac{\partial y}{\partial \boldsymbol{x}} = \left[  \frac{\partial y}{\partial x_{1}}, \dots \frac{\partial y}{\partial x_{n}}\right]$$
实际上的对向量求导的意义是**增大最快的方向** 

常见规则:
$$\frac{\partial \sum x}{\partial  x} = 1^{T}\qquad  \frac{\partial ||x||^{2}}{\partial x} = 2 x^{T } $$
对于加和和乘积部分, 仍然满足基本运算律:
$$\frac{\partial  <u,v>}{\partial x} = <\frac{\partial u}{\partial x},  v>+ <\frac{\partial v}{\partial x}, u>$$
向量对向量求导(类似), 符合几乎所有的运算规则;而**链式法则始终成立**

实际上求导的形状 为 $n_{1 } +n_{2}$ (标量取0)如 $\frac{\partial X}{\partial Y}$ 部分是4维的结果。


## 二、基本反向传播算法原理
### (1) 正向传播和反向传播
例如: 取 w, b 为参数, $y \in  R$, $z = (<w,x> + b - y)$ $l =  \frac{1}{n}z^{2}$ , 则参考[[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/⚓Deep Learning Basic Concepts/Chapter3 Linear Neural  Networks for regression(back Propagation)|regression]] 部分, 则有:
$$\hat{y}= \omega^Tx+b$$
取损失的平均值
$$\boxed {L = \frac{1}{n} \sum^{n}_{i=1} l^{(i)}(w, b) = \frac{1}{n} \sum^{n}_{i=1} \frac{1}{2} \left( w^{T} x^{(i)} + b - y^{(i)}\right)^{2}}$$
首先我们取<mark style="background: transparent; color: red">正向传播</mark>为:
$$\frac{\partial l}{\partial w} = \frac{\partial l}{\partial z_{n} } \left(\frac{\partial z_{n}}{\partial z_{n-1}} \left(\frac{\partial z_{2}}{\partial z_{1}} \frac{\partial z_{1}}{\partial x}\right) \right)$$
而反向传播基本公式: 
$$\frac{\partial l}{\partial w} =\left(\left(\left(\frac{\partial l}{\partial z_{n} } \frac{\partial z_{n}}{\partial z_{n-1}} \right)\dots \frac{\partial z_{2}}{\partial z_{1}}\right) \frac{\partial z_{1}}{\partial x}\right)$$
其中往往对于 $\frac{\partial z_1}{\partial w}$, 可以直接采用 $x$ 直接读取代替, 因此采用反向传播可以减少变量, 同时
> [!NOTE] 正向传播和反向传播区别
> 正向传播和反向传播代价类似, 而反向传播虽然增大了内存, 但是减少了变量等等

取如下的反向梯度参数
$$(w, b) \overset{}{\longrightarrow}  (w,b) - \frac{|\eta|}{|B|} \sum_{i \in B_{t}} \partial_{w,b}  l^{(i)}   (w, b)$$
其中 $\partial(w, b)$ 部分的导数为:
$$\frac{\partial L}{\partial w} = \frac{\partial L}{\partial z} \frac{\partial z}{\partial w} = \frac{2}{n}(w^{T}x^{(i)}  + b - y_{i})x^{(i)}$$
$$\frac{\partial L}{\partial b} = \frac{\partial L}{\partial z}\frac{\partial z}{\partial b}  = \frac{2}{n}(w^{T}x^{(i)} + b - y^{(i)})$$
![[Excalidraw/深度学习基础简介 2024-12-11 15.58.22|200]]

需要说明的时, 一般取
$$l^{(i)}(w,b) = \frac{1}{2}(\hat{y}^{(i)} -y^{(i)})^2$$
需要说明的是, 损失函数必须是严格的[[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓机器学习算法(sklearn)/4. 最优化方法, 梯度寻优法及Logistic 回归#(3) 凸函数及其性质|凸函数]]; 而往往可能<mark style="background: transparent; color: red">深度学习能够找到的是局部最优解, 而非全局最优解</mark> 

### (2) 批量
一般迭代公式为($\eta$ 是**重要的学习率参数**):
$$w_{t} =w_{t-1} - \eta \frac{\partial l }{\partial w_{t - 1}}$$
对于小批量下降, 参考[[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/⚓Deep Learning Basic Concepts/Chapter3 Linear Neural  Networks for regression(back Propagation)#2. Minibatch Stochastic gradient descent(SGD)|SGD 算法]], 可以采用:
$$(w, b) \overset{}{\longrightarrow}  (w,b) - \frac{|\eta|}{|B|} \sum_{i \in B_{t}} \partial_{w,b}  l^{(i)}   (w, b)$$
其中 $B$ 为学习的批量大小; (batch 理论上越大越好, 但是**受到显存的限制**, 并根据显存调节)

1. $\eta$ 一般采用自适应方法(前期 $\eta$ 较大, 后期 $\eta$ 较小)

### 模型选择，欠拟合，过拟合
1. 训练误差和泛化误差
2. 最小化训练误差并不一定能够最小化泛化误差
3. 机器学习应当注重降低泛化误差

- 欠拟合(underfitting)：模型无法得到较低的训练误差
- 过拟合(overfitting): 模型的训练误差远小于测试数据集上的误差


## Pretrained Networks 
The main works are as follows : 
1. the introduction of tensor, and how the  model expect the tensor to be shaped. 
2. gradient descent method.  
3. fully connected  model for image classification  
4. end -to -end strategy  
5. metrics to  for identify the  weaknesses in training as 
6. deploy the python into c++ web program service 

- Popular Deeplearning FreameWork relationships : 
1. Theano and TensorFlow are low-level libs (which defines the computation graph)
2. Lasagne and Kreas are high-level wrappers  
3. Caffe2 as Pytorch's backend 
4. Also support for ONNX 
JAX -> autograd and JIT capable 

the **torch original lib are based on C++ librarys**. and this can be compiled to run with parallelism on GPUS. 

criterion (loss function) -> 

torch.nn.parallel and torch.distributed model can be employed. 

ONNX is a standard  format for neural network, and <mark style="background: transparent; color: red">Pytorch provides a  way to compile the  models through <b>Torch Script</b></mark>. 

most used modules are as follows : 
```python
import torch
from torch import nn
import torch.optim as optim 
import torch.nn.functional as F

class MyModule(torch.nn.Module):  
    """  
    Transform for converting video frames as a list of tensors.    
    """    
    def __init__(self):  
        super().__init__()
```

## 1. Using Pre-Trained Models 
Go to https://pytorch.org/hub/ to see more repos. 
We firstly use the video classification model for the 
If we want to load the model, just use : 
```python
import warnings
import torch  
import torchvision  
from typing import Dict  
import json  
import urllib  
from torchvision.transforms import Compose, Lambda  
from torchvision.transforms._transforms_video import CenterCropVideo, NormalizeVideo  
from pytorchvideo.data.encoded_video import EncodedVideo  
from pytorchvideo.transforms import  ApplyTransformToKey, ShortSideScale, UniformTemporalSubsample, UniformCropVideo  
  
model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)  
device = "cpu"  
model = model.eval().to(device)  
  
model = torch.nn.DataParallel(model)  
  
json_url = "https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json"  
json_filename = "kinetics_classnames.json"  
  
try:  
    urllib.URLopener().retrieve(json_url, json_filename)  
except:  
    warnings.warn("request failed, trying with urllib2 instead")  
    urllib.request.urlretrieve(json_url, json_filename)  
  
with open(json_filename, "r") as f:  
    kinetics_classnames = json.load(f)  
  
# Create an id to label name mapping  
kinetics_id_to_classname = {}  
for k, v in kinetics_classnames.items():  
    kinetics_id_to_classname[v] = str(k).replace('"', "")  
  
side_size = 256  
mean = [0.45, 0.45, 0.45]  
std = [0.225, 0.225, 0.225]  
crop_size = 256  
num_frames = 32  
sampling_rate = 2  
frames_per_second = 30  
slowfast_alpha = 4  
num_clips = 10  
num_crops = 3  
  s
class PackPathway(torch.nn.Module):  
    """  
    Transform for converting video frames as a list of tensors.    
    """    
    def __init__(self):  
        super().__init__()  
  
    def forward(self, frames: torch.Tensor):  
        fast_pathway = frames  
        # Perform temporal sampling from the fast pathway.  
        slow_pathway = torch.index_select(  
            frames,  
            1,  
            torch.linspace(  
                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha  
            ).long(),  
        )  
        frame_list = [slow_pathway, fast_pathway]  
        return frame_list  
  
transform = ApplyTransformToKey(  
    key="video",  
    transform=Compose(  
        [  
            UniformTemporalSubsample(num_frames),  
            Lambda(lambda x: x / 255.0),  
            NormalizeVideo(mean, std),  
            ShortSideScale(  
                size=side_size  
            ),  
            CenterCropVideo(crop_size),  
            PackPathway()  
        ]  
    ),  
)  
  
"""  
Load the video and transform it to the input format required by the model.  
"""  
# The duration of the input clip is also specific to the model.  
clip_duration = (num_frames * sampling_rate) / frames_per_second  
  
# download example video  
url_link = "https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4"  
video_path = 'archery.mp4'  
try:  
    urllib.URLopener().retrieve(url_link, video_path)  
except:  
    urllib.request.urlretrieve(url_link, video_path)  
  
# Select the duration of the clip to load by specifying the start and end duration  
# The start_sec should correspond to where the action occurs in the video  
start_sec = 0  
end_sec = start_sec + clip_duration  
  
# Initialize an EncodedVideo helper class and load the video  
video = EncodedVideo.from_path(video_path)  
  
# Load the desired clip  
video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)  
  
# Apply a transform to normalize the video input  
video_data = transform(video_data)  
  
# Move the inputs to the desired device  
inputs = video_data["video"]  
inputs = [i.to(device)[None, ...] for i in inputs]  
  
""" Get Predictions """  
# Pass the input clip through the model  
preds = model(inputs)  
  
# Get the predicted classes  
post_act = torch.nn.Softmax(dim=1)  
preds = post_act(preds)  
pred_classes = preds.topk(k=5).indices[0]  
  
# Map the predicted classes to the label names  
pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes]  
print("Top 5 predicted labels: %s" % ", ".join(pred_class_names))
```

For the issue of `No module named 'torchvision.transforms.functional_tensor'`, referring to [this GitHub link](https://github.com/AUTOMATIC1111/stable-diffusion-webui/issues/13985), modifying the source code from `import torchvision.transforms.functional_tensor as F_t` to `import torchvision.transforms.functional as F_t` allows the compilation to succeed.

another example is the Image recognition model **ImageNet Large Scale Recognition**, which is downloaded at https://image-net.org/ 

```
model = torch.hub.load('pytorch/vision', 'resnet18', pretrained=True)
```

dataset is downloaded at https://www.kaggle.com/c/imagenet-object-localization-challenge, refer to [[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/🔦Pytorch DeepLearning Basics/implements/Download Dataset by API from kaggle|Download Dataset]] which can download by:
![[attachments/Pasted image 20241009101028.png]]
and run the code in pycharm Termial

