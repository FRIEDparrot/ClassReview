1.线性回归模型的基本要素:
首先，线型回归假设输入与各个输出之间是线型关系: 
$$y = w_{1}x_{1}+w_{2}x_{2} + b $$
接着，通过数据来寻找特定的模型参数值，使模型在数据上的误差尽可能小 --> 即模型训练过程

1. 训练数据:  
收集一系列的真实数据，形成训练数据集（train-dataset）  
收集的每一个样本，其预测内容为标签，对应地，用来预测标签的两个因素叫特征  
3. 损失函数：  
使用一个非负数作为误差，数值越小误差越小,我们往往定义平方损失函数为:
$$l = \frac{1}{2}(y^{(i)} - \hat{y}^{(i)})^{2}$$

通常使用所有样本误差的平均值来衡量模型预测的质量  
我们希望找到一组模型参数，记为w1,w2,b,使训练样本的平均损失最小  
w1,w2,b = argmin l

小批量梯度随机下降的优化算法: 
广义地说， 数据样本数为n，特征数为d时，线型回归的矢量计算表达式为 y = Xw + b其中，批量数据样本特征$X ∈ R(nxd)$权重 $w ∈ R (dx1)$, 偏差 $b ∈ R$, 设模型参数为 $theta = [w1, w2, b]^T$ 此时，我们重写损失函数为
$$l(\theta) = \frac{1}{2n} * (\hat{y}-y)^T(\hat{y}-y)$$
进行最小二乘回归预测
theta <- theta - zeta/beta sigma(i)     公式件p29