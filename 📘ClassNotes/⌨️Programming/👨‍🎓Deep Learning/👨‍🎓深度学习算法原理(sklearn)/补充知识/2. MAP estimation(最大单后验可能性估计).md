## 一、最大单后验估计法
`````ad-note
title: 先验概率和后验概率
collapse: open
### 先验概率 (Prior Probability)

先验概率是指在获得新数据之前，根据已有的知识、经验或历史数据对某个事件发生的概率的估计。例如，如果我们知道某个地区过去的降雨概率是30%，那么这个30%就是先验概率。

### 后验概率 (Posterior Probability)

后验概率是在获得新数据之后，对某个事件发生的概率的重新评估。它结合了先验概率和新数据，通过贝叶斯定理进行更新。
例如， 假设我们有三个碗，A、B、C，其中一个碗下面有一个鸡蛋。最初，我们不知道鸡蛋在哪个碗下面，所以每个碗有鸡蛋的概率都是1/3，这就是先验概率。
现在，我们揭开了C碗，发现下面没有鸡蛋。此时，我们可以更新A碗和B碗有鸡蛋的概率。因为C碗没有鸡蛋，所以鸡蛋在A碗或B碗下面的概率变成了1/2，这就是后验概率。 
`````

参考 https://en.wikipedia.org/wiki/Maximum_a_posteriori_estimation 
MAP (Maximum a posteriori probablity) estimation 是一种量化估计不确定性的方法, 可用于对最大可能性的点估计。可以认为是正则化的最大可能性估计。

参考[[📘ClassNotes/📐Mathmatics/🎣Probability Theory/第三章 多维随机变量及其分布|第三章 多维随机变量及其分布]], 有 $f_{X,Y}(x,y) = f(x|y) f_{Y}(y)$, 首先, 考虑一个不可观测的总体参数$\theta$. 设 $f$ 为 $x$ 的采样分布, 此时计 $f(x| \theta)$ 为总体参数为$\theta$时对应的条件概率.
$$\theta   \rightarrow  f(x | \theta)$$
体现了 x 在$\theta$下的概率密度函数, 其中最大的点为最大可能性估计(MLE)点, 即有:
$$\hat{\theta}_{MLE}(x) = \text{argmax}_{\theta} f (x| \theta)$$
设参数 $\theta$ 存在一个先验分布为 g, 即 $\theta$ 概率密度函数为 $g(\theta)$ (先验概率), 则 $\theta$ 的先验概率密度函数为:
$$\boxed{\theta \rightarrow  f (\theta |x ) = \frac{f(x| \theta ) g(\theta)}{P (x)} =  \frac{f(x| \theta ) g(\theta)}{ \int_{\Theta} f (x |\delta ) g( \delta  ))  d\delta}} \tag{1.1}$$
其中 $\Theta$ 为 g 的所有取值域。

我们**希望得到某个x取值情况下的最大化后验估计概率**，即:
$$\Large\boxed{\hat{\theta}_{MAP} (x) = \text{argmax}\space  f (\theta | x ) }$$
根据贝叶斯公式(1.1), 显然, $\int_{\Theta} f (x |\delta ) g( \delta  ))  d\delta$ 为常数, 则显然有:
$$f (\theta |x) \propto f (x | \theta) g(\theta)$$
则我们只需寻找 $f(\theta|x)$ 最大的点即可。得到:
$$\Large\boxed{\hat{\theta}_{MAP}(x) = \text{arg max}f(\theta|x)  = \text{arg max} f(x | \theta) g (\theta)}$$
该式即为<b><mark style="background: transparent; color: blue">最大后验可能性估计</mark></b>公式。

另外, 当 $g(\theta)$ 是均匀分布时, 则参数 $\theta$ 的 MAP 估计直接变为 $\text{argmax}(f(x|\theta))$， 这与最大似然估计(max likelihood, ML)结果相同。(最大似然估计参考[wiki相关定义](https://en.wikipedia.org/wiki/Maximum_likelihood_estimation) 和 [[📘ClassNotes/⌨️Programming/👨‍🎓Deep Learning/👨‍🎓深度学习算法原理(sklearn)/补充知识/1. ML estimation 最大似然估计|最大似然估计]]) 

当损失函数形式为:
$$L (\theta, a ) = \begin{cases}
0 , \qquad  |a - \theta| < c,  \\
1,  \qquad  \text{otherwise}
\end{cases}$$
当 c-> 0 时, MAP 估计 趋近于 [贝叶斯估计](https://en.wikipedia.org/wiki/Bayes_estimator), 说明 $\theta$ 的分布实际上是准凹函数. 但是必须注意 MAP 是连续估计, Bayes 是离散估计。

