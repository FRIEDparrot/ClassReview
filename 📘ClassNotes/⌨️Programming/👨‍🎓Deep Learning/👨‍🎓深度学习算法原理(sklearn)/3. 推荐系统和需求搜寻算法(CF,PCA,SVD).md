## ä¸€ã€éœ€æ±‚æœå¯»ç®—æ³•ç®€ä»‹ 
æ¨èç³»ç»Ÿçš„éƒ¨åˆ†éœ€è¦å¯¹äºéœ€æ±‚çš„æ·±å…¥ç†è§£ï¼Œå¦‚æœä»…åŸºäºä¼ ç»Ÿçš„æœç´¢å¼•æ“ç®—æ³•ï¼Œå…³é”®èµ“ç»­å“Ÿå•Šçš„å­—æŸ¥è¯¢ä¿¡æ¯éš¾ä»¥å®šä½éœ€æ±‚ã€‚è€Œå®é™…ä¸Šç”¨æˆ·ä¸€èˆ¬æ›´éœ€è¦çš„æ˜¯ç¬¦åˆä¸ªäººåå¥½çš„ç»“æœã€‚

ä¸€èˆ¬çš„æ¨èç³»ç»Ÿçš„ä¸»è¦åŠŸèƒ½åŒ…æ‹¬ : 
1. **æ‰“åŒ…é”€å”®(Cross Selling)**:å³åœ¨æ¨èæŸäº›äº§å“æ—¶, ä¹Ÿä¼šåŒæ—¶æ¨èä¸€åŒè´­ä¹°çš„äº§å“
2. **ååŒè¿‡æ»¤**: ä¸»è¦æ˜¯å®šä½ç”¨æˆ·çš„è´­ä¹°éœ€æ±‚ã€‚åŸºäºæ¨¡ç³Šå…³é”®å­—ä»åˆ—è¡¨ä¸­æ˜ç¡®éœ€æ±‚ã€‚æ­¤å¤–ä¹ŸåŒ…æ‹¬çœ‹è¿‡æ­¤å•†å“ä¹‹åè´­ä¹°çš„å…¶å®ƒå•†å“ã€‚åæ˜ äº†éšå¼éœ€æ±‚(æ›¾ç»æµè§ˆè¿‡æŸé¡µé¢çš„ç”¨æˆ·æ‰€è´­ä¹°çš„äº§å“)ã€‚
3. ç”¨æˆ·å•†å“è¯„è®ºåˆ—è¡¨çš„æŠ½å’Œæ±‡æ€»åˆ†æ, ç”¨äºè¯„ä¼°äº§å“è´¨é‡çš„åˆ†å¸ƒæ°´å¹³ã€‚

æ¨èç³»ç»Ÿçš„ä¸»è¦ç®—æ³•åŒ…å« : 
1. åŸºäºäººå£ç»Ÿè®¡å­¦çš„æ¨èæœºåˆ¶ : æ ¹æ®ç”¨æˆ·çš„åŸºæœ¬ä¿¡æ¯è·å–ç›¸å…³ç¨‹åº¦, å¹¶æ ¹æ®ç›¸ä¼¼ç”¨æˆ·å–œå¥½çš„çš„å…¶ä»–ç‰©å“æ¨èç»™å½“å‰ç”¨æˆ·ã€‚
2. åŸºäºååŒè¿‡æ»¤çš„æ¨èæœºåˆ¶ : ä¸»è¦åˆ†ä¸º<b><mark style="background: transparent; color: blue">åŸºäºç”¨æˆ·çš„æ¨èå’ŒåŸºäºé¡¹ç›®çš„æ¨è</mark></b>ã€‚
3. åŸºäºéšè¯­ä¹‰çš„æ¨èæ¨¡å‹ : å…¶ä¸­, **ç›®å‰ç²¾åº¦æœ€é«˜çš„ç®—æ³•æ˜¯ SVD éšè¯­ä¹‰æ¨¡å‹**ã€‚

ä¸€èˆ¬åœ¨è®­ç»ƒé˜¶æ®µ, å±äº CPU å¯†é›†å‹ä»»åŠ¡, è€Œåœ¨åˆ†ç±»æˆ–è€…é¢„æµ‹é˜¶æ®µå±äº IO å¯†é›†å‹ä»»åŠ¡ã€‚ ä¸€èˆ¬ä¸ä½¿ç”¨è„šæœ¬è¯­è¨€è¿›è¡Œè®¾è®¡ã€‚

ååŒè¿‡æ»¤çš„æ¨¡ä»¥åŠç®—æ³•åŒ…å«: 
1. æ•°æ®å¤„ç†ä¸ UI çŸ©é˜µ 
2. UserCF å’Œ ItemCF æ¨èæ¨¡å‹
3. KMeans ç›¸ä¼¼æ€§è®¡ç®— 
4. SVD ç›¸ä¼¼æ€§è®¡ç®—  

### (1) ç‰©å“æ•°æ®çš„ KMeans èšç±»
KMeans èšç±»å‚è€ƒ [[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æ·±åº¦å­¦ä¹ ç®—æ³•åŸç†(sklearn)/è¡¥å……çŸ¥è¯†/4.KNNç®—æ³•å’ŒKMeansç®—æ³•#äºŒã€K-Meansç®—æ³•(Kå‡å€¼ç®—æ³•)|KMeansç®—æ³•]] , å¹¶ç»™å‡ºä¸€ä¸ªç®€å•çš„ iris æ•°æ®é›† KMeans èšç±»ä»£ç :
```python
import sklearn  
from sklearn.datasets import load_iris  
from sklearn.cluster import KMeans  
from sklearn.preprocessing import StandardScaler  
from sklearn.model_selection import train_test_split  
import matplotlib.pyplot as plt  
  
iris = load_iris()  
  
iris_data = iris.data  
iris_target = iris.target  
  
X_train, X_test, y_train, y_test =  train_test_split(iris_data, iris_target, test_size=0.2, random_state=None)  
  
kms = KMeans(n_clusters=3)  
kms.fit(X_train, y_train)  
  
y_pred = kms.predict(iris_data)  
  
fig, axes = plt.subplots(2,1, figsize=(5,10))  
axes[0].scatter(iris_data[:,0], iris_data[:,1], c=iris_target)  
axes[0].set_title("real results")  
axes[1].scatter(iris_data[:,0], iris_data[:,1], c=y_pred)  
axes[1].set_title("KMeans results")  
plt.show()
```

KMeans èšç±»ç»“æœå¦‚ä¸‹:
![[attachments/Pasted image 20240914173557.png]]

```python
# è·å–èšç±»ä¸­å¿ƒç‚¹
centers = kms.cluster_centers_
print("Cluster centers:\n", centers)
```

äºŒåˆ† KMeans ä»ç„¶å‚è€ƒ [[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æ·±åº¦å­¦ä¹ ç®—æ³•åŸç†(sklearn)/è¡¥å……çŸ¥è¯†/4.KNNç®—æ³•å’ŒKMeansç®—æ³•|4.KNNç®—æ³•å’ŒKMeansç®—æ³•]]


### (2) ååŒè¿‡æ»¤ User CF å’Œ Item CF åŸç†
ååŒè¿‡æ»¤(Collabrate Filtering, CF) åˆ†ä¸º User CF å’Œ Item CF éƒ¨åˆ†;
é¦–å…ˆéœ€è¦å»ºç«‹ç”¨æˆ·åå¥½çŸ©é˜µ, æ ¹æ® KNN ç®—æ³•ï¼Œä»¥è·ç¦»æˆ–è€…å¤¹è§’ä½™å¼¦ä¸ºè·ç¦», åˆ†åˆ«è®¡ç®—å…¶åˆ°æ¯ä¸€ç±»ç”¨æˆ·çš„è·ç¦»;
![[Excalidraw/3. æ¨èç³»ç»Ÿå’Œéœ€æ±‚æœå¯»ç®—æ³• 2024-09-14 18.03.57|550]]
User CF å³é‡‡ç”¨KNNç­‰å°†ç”¨æˆ·(USER C)é€šè¿‡usr_vector å½’ç±»åˆ°æŸä¸€ç±»ç”¨æˆ·(Aæˆ–B)ä¸­ã€‚å¹¶å°†è¯¥ç±»ç”¨æˆ·æ²¡æœ‰ä¹°è¿‡çš„ç‰©å“è¿›è¡Œæ¨è
Item CF å³é€‰å–æ–°ç”¨æˆ·(USER C)æ¯”è¾ƒåå¥½çš„ç‰©å“ (item E), å¹¶é€šè¿‡åˆ†ç±»è·å–ä¸ item E ç›¸ä¼¼çš„ç‰©å“ (é€šè¿‡item_vecå¯ä»¥æ‰¾å‡ºå¦‚item Aç›¸ä¼¼,åˆ™å°†item A ä¹Ÿæ¨èç»™ item Eçš„ç”¨æˆ·)

### (3) ä¸€èˆ¬çŸ©é˜µçš„ SVD åˆ†è§£åŠå…¶è¯æ˜ 
å¯¹äºåŸºäºæ¨¡å‹çš„ CF æ–¹æ³•ä¸­, æœ€å¸¸ç”¨çš„æ˜¯éšè¯­ä¹‰æ¨¡å‹, é‡‡ç”¨çš„æ˜¯ SVD åˆ†è§£, å³çŸ©é˜µçš„å¥‡å¼‚å€¼åˆ†è§£ã€‚å‚è€ƒ[[ğŸ“˜ClassNotes/ğŸ“Mathmatics/ğŸ“linear algebra/ç¬¬äº”ç«  çŸ©é˜µçš„ç›¸ä¼¼å˜æ¢#(3) çŸ©é˜µçš„ç›¸ä¼¼å¯¹è§’åŒ–|ç¬¬äº”ç«  çŸ©é˜µçš„ç›¸ä¼¼å˜æ¢]]. 

å¯¹äº n é˜¶æ–¹é˜µ $A^{n\times n}$, æœ‰ç›¸ä¼¼çŸ©é˜µ:
$$A = Q \Sigma Q ^{-1}$$
å…¶ä¸­ $\Sigma$ ä¸ºç‰¹å¾å€¼æ„æˆçš„å¯¹è§’é˜µ, $Q$ ä¸ºç‰¹å¾å‘é‡æ’æˆçš„åˆ—é˜µã€‚ä½†æ˜¯,æ­¤æ–¹æ³•ä»…ä»…æ˜¯å¯¹æ–¹é˜µè€Œè¨€çš„ã€‚å®é™…**å¤šæ•°æƒ…å†µä¸‹æ ·æœ¬ä¸æ˜¯æ–¹é˜µ**ï¼Œæ­¤æ—¶å¯ä»¥<mark style="background: transparent; color: red">ä»¥å¥‡å¼‚å€¼åˆ†è§£æè¿°æ™®é€šçŸ©é˜µçš„é‡è¦ç‰¹å¾</mark>

<b><mark style="background: transparent; color: blue">å®šä¹‰(çŸ©é˜µçš„SVDåˆ†è§£)</mark></b>:è®¾ A æ˜¯ä»»æ„çš„ $M \times N$ çŸ©é˜µ, åˆ™æœ‰çŸ©é˜µçš„ SVD åˆ†è§£ä¸º:
$$\Large\boxed{A =  U \Sigma V^{T}}$$
å…¶ä¸­ $U$ æ˜¯ $M \times M$ æ–¹é˜µ, $\Sigma$ æ˜¯ä¸€ä¸ª $M \times N$ çŸ©é˜µ, ä»…æœ‰å¯¹è§’çº¿ä¸Šæœ‰å…ƒç´ , ä¸”<mark style="background: transparent; color: red">å¯¹è§’çº¿ä¸Šçš„å…ƒç´ ç§°ä¸ºå¥‡å¼‚å€¼</mark>, å…¶å®ƒå…ƒç´ å‡ä¸º0. è€Œ $V^T$ æ˜¯ä¸€ä¸ª $N \times N$ æ–¹é˜µã€‚å³:
$$\Large\boxed{A_{m \times  n} = U _{m\times m} \Sigma_{m \times  n} V^{T}_{n \times n}}$$
å…¶ä¸­ U çš„å…ƒç´ ç§°ä¸º<mark style="background: transparent; color: red">å·¦å¥‡å¼‚å‘é‡</mark>, V ä¸­çš„å…ƒç´ ç§°ä¸º<mark style="background: transparent; color: red">å³å¥‡å¼‚å‘é‡</mark>, å¹¶æœ‰å…³ç³» $U^{T} U = V^{T}V= I$

å‚è€ƒ [Singular_value_decomposition](https://en.wikipedia.org/wiki/Singular_value_decomposition) è¡¥å…… [polar_decomposition](https://en.wikipedia.org/wiki/Polar_decomposition#Matrix_polar_decomposition)  æ¨å¯¼å¯ä»¥å‚è€ƒ [[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æ·±åº¦å­¦ä¹ ç®—æ³•åŸç†(sklearn)/è¡¥å……çŸ¥è¯†/SVD decomposition.pdf|SVD decomposition.pdf]]  å’Œ [SVDåˆ†è§£çš„è¯æ˜](https://zhuanlan.zhihu.com/p/399547902)

**ç»™å‡ºæ¨å¯¼**: é¦–å…ˆ, è®¾Açš„ç§©ä¸ºr, å³æœ‰ $r = \min \left\{ m,n\right\}$, æ­¤æ—¶ $A^T$ ç§©æ˜¾ç„¶ä¹Ÿä¸º $r$, ç»è¿‡[ä¸€æ–‡å…³äºçŸ©é˜µç§©å…¬å¼r(AA^T)=r(A^T A)=r(A)çš„è¯æ˜](https://zhuanlan.zhihu.com/p/447703725) å¾—åˆ°:
$$rank (A^{T}A ) =  rank (A A^{T} )$$
åˆ™ $\text{rank}(A^T A) = r$, æ­¤æ—¶æ ¹æ®$A^TA$ä¸ºåŠæ­£å®šçŸ©é˜µ(æ˜¾ç„¶$x^TA^TAx \geq 0$), å› æ­¤å…¶ç‰¹å¾å€¼ä¸ºéè´Ÿå®æ•°ã€‚å…¶ä¸­**ç§©çš„ä¸ªæ•°å³ä¸ºéé›¶ç‰¹å¾å€¼çš„ä¸ªæ•°**ï¼Œå–å…¶ç‰¹å¾å€¼å¾—åˆ°:
$$\boxed{\Large  (A^{T}A) v_{i}= \lambda_{i} v_{i}}$$
å…¶ä¸­ $A$ ä¸º $m \times n$ çŸ©é˜µ, **åŒæ—¶,ç”±äº$AA^T$ä¸ºå®å¯¹ç§°é˜µ, ç›¸ä¼¼å¯¹è§’åŒ–å $v_i, v_j$ æ˜¯æ­£äº¤å‘é‡, åˆ™**:
$$<Av_{i} ,Av_{j}> = v_{j}^{T} A^{T} A v_{i}  = \lambda v_{j}^{T}  v_{i} = \begin{cases}
\lambda_{i} \qquad  1 \leq  i = j \leq  r  \\
0 \qquad  i \neq j  \text{ or } i = j > r
\end{cases}$$
æ˜¾ç„¶ $<Av_i, Av_j>$ ä¸ºæ­£äº¤å‘é‡ç»„, æ­¤æ—¶å– i = j å³å¾—å¦‚ä¸‹å¼å­:
$$\boxed{\Large ||Av_{i}|| = \sqrt{\lambda_{i}}\qquad i = 1, 2, \dots  r}$$
$$\Large\boxed{||Av_{i}|| = 0 \qquad  i = r + 1, \dots n}$$
å…¶ä¸­$v_{i}$å°±æ˜¯ä¸Šé¢çš„<mark style="background: transparent; color: red">å³å¥‡å¼‚å‘é‡</mark>, æˆ‘ä»¬å– $\sigma_i  = \sqrt{\lambda_i}$ å³ä¸º<b><mark style="background: transparent; color: blue">å¥‡å¼‚å€¼</mark></b>ï¼Œè€Œä»¤ 
$$\Large \boxed{u_{i}  = \frac{Av_{i}}{||Av_{i}||} =  \frac{1}{\sqrt{\lambda_{i}}} Av_{i} \qquad  i= 1, \dots  n} $$
**å…¶ä¸­ç”±äº A ä¸º $m*n$ æ•… $\boldsymbol{u}$ ä¸º $m \times 1$ çš„å‘é‡, å®é™…ä¸Šå°±æ˜¯å‘é‡u**<b><mark style="background: transparent; color: blue">(å·¦å¥‡å¼‚å‘é‡)</mark></b>ã€‚ç„¶åç»è¿‡å¦‚ä¸‹è¯æ˜è¿‡ç¨‹:
![[attachments/Pasted image 20240919170741.png]]
å¾—åˆ° SVD åˆ†è§£:
$$\Large\boxed {A_{m \times  n} = U_{m \times  m }\Sigma_{m \times  n} V_{n \times n}^{T}}$$
### (4) çŸ©é˜µçš„éƒ¨åˆ†å¥‡å¼‚å€¼(SVD)åˆ†è§£
å¥‡å¼‚å€¼$\sigma$å’Œç‰¹å¾å€¼ç±»ä¼¼, æ˜¾ç„¶**åœ¨ $\Sigma$ ä¸­, $\sigma$ å€¼ä¹Ÿæ˜¯ä»å¤§åˆ°å°æ’åˆ—çš„**ã€‚æ­¤æ—¶**å¯èƒ½çŸ©é˜µå‰ 10% ç”šè‡³ 1% çš„ç‰¹å¾å€¼çš„å’Œå°±å æ®äº†å…¨éƒ¨å¥‡å¼‚å€¼ä¹‹å’Œçš„99%ä»¥ä¸Š**ã€‚æˆ‘ä»¬å–å‰ $r$ ä¸ªå¥‡å¼‚å€¼, å…¶ä½™çš„ r+1é˜¶ä»¥åçš„å¥‡å¼‚å€¼éå¸¸æ¥è¿‘0,åˆ™å®šä¹‰<b><mark style="background: transparent; color: blue">çŸ©é˜µçš„éƒ¨åˆ†SVDåˆ†è§£</mark></b>ä¸º:
$$\boxed{\Large A_{m \times  r} \approx U_{m \times r} \Sigma_{r \times r} V^{T}_{r\times  n}}$$
åœ¨numpy.linalg ä¸­æä¾›äº†SVDåˆ†è§£å‡½æ•°:
```python 
import numpy.linalg import svd
U, S, VT  = svd(A)
print(U, S, VT)
```


## äºŒã€PCA ä¸»æˆåˆ†åˆ†æå’Œ SVD åˆ†è§£çš„åº”ç”¨
éœ€è¦è¯´æ˜, PCA å’Œ SVD éƒ½æ˜¯ sklearn.decomposition ä¸­çš„å†…å®¹ã€‚ 
### (1) PCA ä¸»æˆåˆ†åˆ†æåŸç†
[sklearnå®æˆ˜ä¹‹é™ç»´ç®—æ³•PCAä¸SVD_ä½¿ç”¨svdè¿›è¡Œä¸»æˆåˆ†åˆ†æé¸¢å°¾èŠ±åˆ†ç±»-CSDNåšå®¢](https://blog.csdn.net/qq_48314528/article/details/119845670)
PCA çš„åŸºæœ¬åŸç†æ˜¯ï¼šå¦‚æœä¸€ä¸ª==é«˜ç»´æ•°æ®é›†å¦‚æœèƒ½å¤Ÿè¢«ç›¸å…³å˜é‡è¡¨ç¤º, é‚£ä¹ˆä»…æœ‰ä¸€äº›ç»´æœ‰æ„ä¹‰ã€‚æ ¹æ®æ­¤åŸç†, å¯ä»¥æå–å‡ºé«˜ç»´å˜é‡ä¸­æŸäº›ç‰¹å¾æˆ–è€…ç›¸å…³å˜é‡, å³å¯é‡‡ç”¨ä½ç»´æ•°æ®è¡¨ç¤ºè¯¥å˜é‡==, è€Œ<mark style="background: transparent; color: red">ä¸é‡è¦çš„ç»´å¯ä»¥åœ¨è®¡ç®—ä¸­å¿½ç•¥</mark>ã€‚æ­¤æ—¶<b><mark style="background: transparent; color: blue">å¦‚æœå¯»æ‰¾åˆ°æ•°æ®ä¸­æ–¹å·®æœ€å¤§çš„æ–¹å‘, åˆ™è¢«ç§°ä¸ºå‘é‡çš„ä¸»æˆåˆ†</mark></b> 

åœ¨é«˜ç»´æ•°æ®ä¸­, å¾€å¾€å™ªå£°ä¸å¸¦æœ‰æœ‰æ•ˆä¿¡æ¯, ä¸”éƒ¨åˆ†ç‰¹å¾æ˜¯ç›¸å…³çš„, å› æ­¤éœ€è¦åœ¨å‡å°‘ç‰¹å¾æ•°é‡åŒæ—¶ä¿æŒä¿ç•™æœ‰æ•ˆä¿¡æ¯ã€‚<mark style="background: transparent; color: red">æ ¹æ®æ ·æœ¬æ–¹å·®, æ–¹å·®è¶Šå¤§, ç‰¹å¾æ‰€å«æœ‰ä¿¡æ¯è¶Šå¤šã€‚ ä¸€èˆ¬åœ°, æ–¹å·®å°çš„æ•°æ®, å…¶ä½“ç°ä¿¡æ¯æ¯”è¾ƒå°‘, å› æ­¤å¯ä»¥èˆå»</mark>: 

ä¸€èˆ¬åœ°, æ ·æœ¬æ–¹å·®è®¡ç®—ä¸º(é‡‡ç”¨ n-1 æ˜¯æ ·æœ¬çš„æ— åä¼°è®¡): 
$$\text{Var} = \frac{1}{n -1} \sum^{n}_{i=1} (x_{i} - \overline{x})^{2}$$
PCA çš„ä¸€èˆ¬æ­¥éª¤å¦‚ä¸‹: é¦–å…ˆ, è®¡ç®—æ ·æœ¬çš„å‡å€¼å‘é‡å’Œåæ–¹å·®çŸ©é˜µ$S$:
$$\mu =\frac{1}{n} \sum^{n}_{i=1} x_{i} \qquad  S = \frac{1}{n}\sum^{n}_{i=1}(x_{i}- \mu) (x_{i} - \mu)^{T}$$
ç„¶åè®¡ç®— S çš„ç‰¹å¾å€¼ $\lambda_{i}$ å’Œå¯¹åº”çš„ç‰¹å¾å‘é‡ $v_i$ 
$$Sv_{i}  = \lambda_{i} v_{i}  \qquad  i = 1,2,\dots n$$
ç„¶å<mark style="background: transparent; color: red">å¯¹ç‰¹å¾å€¼å’Œç‰¹å¾å‘é‡è¿›è¡Œé€’å‡æ’åº, å¦‚æœå®šä¹‰ä¸€ä¸ªå‘é‡æœ‰ k ä¸ªä¸»æˆåˆ†, åˆ™å¯¹åº”çš„ k ä¸ªä¸»æˆåˆ†å³ä¸º k ä¸ªæœ€å¤§çš„ç‰¹å¾å€¼åŠæ‰€å¯¹åº”çš„ç‰¹å¾å‘é‡</mark>ã€‚æ³¨æ„: è¿™ä¸ªé€šè¿‡ PCA`(n_components = x)` è¿›è¡ŒæŒ‡å®š(å¦‚æœä»…ä»…å¯è§†åŒ–,å¯ä»¥é™ç»´åˆ°äºŒç»´)
$$y = W^{T}  (x -u)   \qquad  W = (v_{1}, v_{2}, \dots  v_{n})$$
è€Œ <b><mark style="background: transparent; color: blue">PCA åŸºçš„å˜æ¢</mark></b>ä¸º
$$\boxed{\Large x = W y + u \qquad  W =  (v_{1}, v_{2}, \dots  v_{k})}$$
ä¸‹é¢é‡‡ç”¨ PCA é™ç»´ä¹‹åé¢„æµ‹ Iris æ•°æ®é›†å¹¶ç»˜åˆ¶å›¾åƒ
```python
from sklearn.datasets import load_iris  
from sklearn.decomposition import PCA  
from sklearn.preprocessing import StandardScaler  
from sklearn.model_selection import train_test_split, cross_val_score  
from sklearn.naive_bayes import GaussianNB  
from sklearn.metrics import accuracy_score  
import matplotlib.pyplot as plt  
  
X,y = load_iris(return_X_y=True)  
x_train, x_test,y_train, y_test = train_test_split(X,y,test_size=0.35,random_state=42)  
  
pca = PCA(n_components=2).fit(x_train) # 2 components  
print(pca.components_)     # ä¸»æˆåˆ†çš„ç‰¹å¾å‘é‡(æ¯ä¸€è¡Œå¯¹åº”ä¸€ä¸ªä¸»æˆåˆ†ï¼Œ å³å¯¹åº”çš„ V çŸ©é˜µ)
print("variance:" ,pca.explained_variance_)         # æŸ¥çœ‹é™ç»´åæ¯ä¸ªæ–°ç‰¹å¾å‘é‡ä¸Šæ‰€å¸¦çš„ä¿¡æ¯é‡å¤§å°ï¼ˆå¯è§£é‡Šæ€§æ–¹å·®çš„å¤§å°ï¼‰  
print("variance_ratio:", pca.explained_variance_ratio_)   # æŸ¥çœ‹é™ç»´åæ¯ä¸ªæ–°ç‰¹å¾å‘é‡ä¸Šæ‰€å¸¦çš„ä¿¡æ¯é‡å æ€»ä¿¡æ¯é‡çš„æ¯”ä¾‹ï¼ˆå¯è§£é‡Šæ€§æ–¹å·®çš„ç™¾åˆ†æ¯”ï¼‰  
  
x_train_new = pca.transform(x_train)
x_test_new = pca.transform(x_test)  
  
gnb = GaussianNB()  
gnb.fit(x_train_new,y_train)  
y_pred = gnb.predict(x_test_new)  
  
fig, axes = plt.subplots(1,2, figsize=(12,5), subplot_kw = {"xticks":[],"yticks":[]})  # subplot_kw æŒ‡å®šç»˜åˆ¶é¡ºåº
axes[0].scatter(x_test_new[:,0],x_test_new[:,1],c=y_test)  
axes[1].scatter(x_test_new[:,0],x_test_new[:,1],c=y_pred)  
plt.show()  
  
print("predict accuracy:", accuracy_score(y_test,y_pred, normalize=True))
```

> [!caution] PCA çš„ n_components å‚æ•°
> 1. ä¸ºæ•´æ•°æ—¶, åˆ™ä¿ç•™ç›¸åº”çš„ç»´æ•°ã€‚
> 2. å¦‚æœä¸å†™ä»»ä½•å€¼, åˆ™è¿”å› min(X.shape) (ç”±äºæ ·æœ¬é‡ä¸€èˆ¬å¤§äºç‰¹å¾ä¸ªæ•°, ç›¸å½“äºæ²¡æœ‰è½¬æ¢ç‰¹å¾, å› æ­¤é™¤äº†ç»˜åˆ¶ç´¯è®¡å¯è§£é‡Šæ–¹å·®è´¡çŒ®ç‡æ›²çº¿ `np.cumsum(pca_line.explained_variance_ratio_)` ä»¥å¤–, ä¸€èˆ¬ä¸é‡‡ç”¨è¯¥æ–¹å¼)
> 3. å¯ä»¥é‡‡ç”¨ PCA ç”¨æœ€å¤§ä¼¼ç„¶ä¼°è®¡è¿›è¡Œè‡ªé€‰è¶…å‚æ•° `n_components` , åªéœ€æŒ‡å®š
> `pca = PCA(n_components = "mle")` å³å¯ 
> 4. è¾“å…¥ [0,1] é—´çš„æµ®ç‚¹æ•°å¹¶å– `svd_solver = full` æ—¶, æœ‰ `pca_f = PCA(n_components=0.97,svd_solver="full")` åˆ™é™ç»´åˆ°ä¿è¯é™ç»´å**æ€»è§£é‡Šæ€§æ–¹å·®è´¡çŒ®ç‡å¤§äºn_componentsæŒ‡å®šç™¾åˆ†æ¯”çš„ä¿¡æ¯é‡**çš„ç»´æ•°ã€‚

å¦å¤–ç»˜åˆ¶ä¸‰ç»´å›¾åƒä¹Ÿéå¸¸ç®€å•(ä¸è¿›è¡Œé¢„æµ‹):
```python
from sklearn.decomposition import PCA  
# unused but required import for doing 3d projections with matplotlib < 3.2  
import mpl_toolkits.mplot3d

fig = plt.figure(1, figsize=(8, 6))  
ax = fig.add_subplot(111, projection="3d", elev=-150, azim=110)  
  
X_reduced = PCA(n_components=3).fit_transform(iris.data)  
ax.scatter(  
    X_reduced[:, 0],  
    X_reduced[:, 1],  
    X_reduced[:, 2],  
    c=iris.target,  
    s=40, # marker size )
plt.show()
```
### (2) PCA ä¸­çš„ SVD 
SVD å®é™…ä¸Šæ˜¯<b><mark style="background: transparent; color: blue">ä¸è®¡ç®—åæ–¹å·®çŸ©é˜µ, ç›´æ¥æ‰¾å‡ºä¸€ä¸ªæ–°ç‰¹å¾å‘é‡ç»„æˆçš„ n ç»´ç©ºé—´</mark></b>, å³ç›´æ¥è·å–å³åˆ†è§£å‘é‡çŸ©é˜µ $V^T$, è€Œ $U$ å’Œ $\Sigma$ åœ¨ fit å®Œæˆä¹‹å, å³è¢«èˆå¼ƒã€‚
è€Œ `print(pca.components_)` å¯ä»¥ç›´æ¥è·å– PCA ä¸­ SVD åˆ†è§£å™¨çš„$V$å‚æ•°ã€‚

å®é™…ä¸ŠPCA çš„ SVD æ±‚è§£å™¨æ˜¯é€šè¿‡ PCA (svd_solver) æ§åˆ¶çš„, å‚æ•°åŒ…å«:
**â€œautoâ€ï¼Œâ€œfullâ€ï¼Œâ€œarapckâ€ï¼Œâ€œrandomizedâ€ï¼Œé»˜è®¤"auto"**ï¼Œå…·ä½“è§£é‡Šå¦‚ä¸‹:
![[attachments/Pasted image 20240922105941.png]]

éœ€è¦è¯´æ˜ PCAå’Œç‰¹å¾é€‰æ‹©çš„åŒºåˆ«: **ç‰¹å¾é€‰æ‹©åçš„ç‰¹å¾çŸ©é˜µæ˜¯å¯è§£è¯»çš„ï¼Œè€ŒPCAé™ç»´åçš„ç‰¹å¾çŸ©é˜µæ˜¯ä¸å¯è§£è¯»çš„, å³å°†å·²ç»å­˜åœ¨çš„ç‰¹å¾è¿›è¡Œå‹ç¼©, ä¸”é™ç»´å®Œæ¯•åç‰¹å¾ä¸æ˜¯åŸçŸ©é˜µçš„ä»»ä½•ç‰¹å¾, è€Œæ˜¯é€šè¿‡æŸäº›æ–¹å¼è¿›è¡Œç»„åˆèµ·æ¥çš„ï¼Œæ–°çš„ç‰¹å¾**.
**é‡è¦çš„æ˜¯ï¼š å¦‚æœåŸç‰¹å¾çŸ©é˜µæ˜¯å›¾åƒï¼ŒV(k,n)è¿™ ä¸ªç©ºé—´çŸ©é˜µä¹Ÿå¯ä»¥è¢«å¯è§†åŒ–çš„è¯ï¼Œæˆ‘ä»¬å°±å¯ä»¥é€šè¿‡ä¸¤å¼ å›¾æ¥æ¯”è¾ƒï¼Œå°±å¯ä»¥çœ‹å‡ºæ–°ç‰¹å¾ç©ºé—´ç©¶ç«Ÿä»åŸå§‹æ•°æ®é‡Œæå–äº† ä»€ä¹ˆé‡è¦çš„ä¿¡æ¯**ã€‚ä¾‹å¦‚äººè„¸è¯†åˆ«ä¸­æœ‰è¾ƒä¸ºå¥½çš„åº”ç”¨ã€‚

ä½†æ˜¯åœ¨çŸ©é˜µåˆ†è§£æ—¶, PCAä¸€èˆ¬åœ¨åŸæœ‰ç‰¹å¾åŸºç¡€ä¸Š, æ‰¾å‡ºèƒ½å¤Ÿè®©ä¿¡æ¯å°½é‡èšé›†çš„æ–°çš„ç‰¹å¾å‘é‡ã€‚

> [!NOTE] è¡¥å……: PCA çš„ inverse_transform éƒ¨åˆ†
> PCA å¯ä»¥é€šè¿‡ X **å³ä¹˜æ‰€æå–çš„ç‰¹å¾çŸ©é˜µ V** ç”Ÿæˆæ–°çŸ©é˜µ $X_{dr}$ åˆ™è®© X_dr å³ä¹˜ $V(k,n)$ é€†çŸ©é˜µ $V^{-1}_{(k,n)}$ å³å¯å°† X_dr è¿˜åŸä¸º $X$, ä½†èˆå¼ƒäº†é™ç»´åçš„éƒ¨åˆ†çš„ä¿¡æ¯ã€‚

### (3) 

ä» Kaggle ä¸Šè·å–æ¨èç³»ç»Ÿæ•°æ®é›† [retailrocket](https://www.kaggle.com/datasets/retailrocket/ecommerce-dataset) è¿›è¡Œåˆ†æ;


#### Task 1
**When a customer comes to an e-commerce site, he looks for a product with particular properties: price range, vendor, product type and etc. These properties are implicit**, so it's hard to determine them through clicks log.

Try to **create an algorithm which predicts properties of items in "addtocart" event by using data from "view" events for any visitor in the published log**.

#### Task 2
Description:
Process of analyzing ecommerce data include very important part of data cleaning. Researchers noticed that in some cases browsing data include up to 40% of abnormal traffic.

Firstly, abnormal users add a lot of noise into data and make recommendation system less effective. In order to increase efficiency of recommendation system, abnormal users should be removed from the raw data.

Secondly, abnormal users add bias to results of split tests, so this type of users should be removed also from split test data.

Goals:
- The main goal is to find abnormal users of e-shop.

Subgoals:
- Generate features
- Build a model
- Create a metric that helps to evaluate quality of the model