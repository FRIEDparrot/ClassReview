## ä¸€ã€çº¿æ€§ç³»ç»ŸåŠå…¶é¢„æµ‹
é¢„æµ‹ä¸­çš„æ ¸å¿ƒæ¦‚å¿µæ˜¯<mark style="background: transparent; color: red">å›å½’é—®é¢˜</mark>(Regression), å›å½’åæ˜ äº†ç³»ç»Ÿçš„éšæœºè¿åŠ¨æ€»æ˜¯è¶‹å‘äºå…¶æ•´ä½“è¿åŠ¨è§„å¾‹çš„è¶‹åŠ¿ã€‚
å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸŒŸæœºå™¨å­¦ä¹ ä¼˜åŒ–ç®—æ³•åˆé›†/9. å¾„å‘åŸºå‡½æ•°æ–¹æ³•(RBF)|å¾„å‘åŸºå‡½æ•°æ–¹æ³•(RBF)]]ï¼Œ 
### (1) æœ€å°äºŒä¹˜å›å½’
#### 1. åŸºæœ¬æ¨¡å‹
é¦–å…ˆ, æˆ‘ä»¬çš„åŸºæœ¬æ¨¡å‹æ˜¯
$$Y= a X + b$$
å…¶ä¸­ a,b ä¸ºå¸¸æ•°; å–æ®‹å·®
$$\xi_{i} = y_{i}- ax_{i} - b$$
åˆ™é‡‡ç”¨æ®‹å·®çš„å¹³æ–¹å’Œ:
$$Q = \sum_{i = 1}^{n} \xi_{i} ^{2} \overset{\min}{\longrightarrow} \frac{\partial Q}{\partial a} = \frac{\partial Q}{\partial b} = 0 $$
å¾—åˆ°:
$$\begin{cases}
\sum_{i = 1}^{n}  ( x_{i}y_{i} - ax_{i}^{2} - bx_{i}) = 0  \\
\sum_{i = 1}^{n}  (y_{i} - a x_{i} - b ) = 0  
\end{cases}$$
æ­¤æ—¶, å°† $bx_i$ ç§»åŠ¨åˆ°å³ä¾§è§£å‡º $a$, æœ‰: 
$$\sum_{i = 1}^{n} (x_{i}y_{i} - ax_{i} ^{2} ) =  n * b \overline{x} =  \sum_{i = 1}^{n} \overline{x} (y_{i} - a x_{i})$$
å¾—åˆ°<b><mark style="background: transparent; color: blue">æœ€å°äºŒä¹˜å…¬å¼</mark></b>:
$$\boxed{a = \frac{\sum_{i = 1}^{n} x_{i} y_{i} - n\overline{x} \overline{y}}{\sum_{i = 1}^{n}x_{i}^{2} - n \overline{x}^{2}}\qquad b = \overline{y} - a \overline{x} }$$
#### 2. æ­£è§„æ–¹ç¨‹ç»„
ä¸€èˆ¬çš„æ–¹æ³•å‚è€ƒ [MATLABæœ€å°äºŒä¹˜å¤šé¡¹å¼æ‹Ÿåˆ](https://mp.weixin.qq.com/s?__biz=Mzg2MDY5MTY4NA==&mid=2247484025&idx=1&sn=0b580f3a94bf79d0c148e0d783ecc30d&chksm=ce23cff2f95446e428a8b6c4289d6167d5f199235b628242efc78ca82a47ffdf8111a0ab8582&token=777628491#rd), å¯¹äºå®é™…çš„æ ·æœ¬ç‚¹, æˆ‘ä»¬æœ‰: 
$$X = \left[\begin{matrix}
x_{11} & \dots   & x_{1n} \\  
x_{21} & \dots & x_{2n}  \\ 
\vdots   \\ && x_{mn}
\end{matrix}\right]$$
è€Œæœ‰: $y_1 = a_{1} x_{11} + a_2 x_{12} + \dots +  a_n x_{1n} + b_{i}$, åˆ™å– $a = (a_{1}, \dots  a_{n})^T$, å¾—åˆ° $Y = Xa + b$, æ­¤æ—¶æˆ‘ä»¬å°† $b$ åˆå¹¶åˆ° $X$ ç¬¬ä¸€åˆ—å¾—åˆ°:
$$Y =   X\boldsymbol{a} \quad  \rightarrow \quad   X^{T} Y = X^{T } X \boldsymbol{a}$$
æ˜¾ç„¶ä¸ºäº†æ–¹ç¨‹ç»„æœ‰è§£, **å¯¹ç§°çŸ©é˜µ $X^{T} X$ å¿…é¡»éå¥‡å¼‚**; å¹¶æœ‰
$$A = (X^{T}  X)^{-1}  (X^{T}Y)$$
ä¸º<mark style="background: transparent; color: red">æ–¹ç¨‹ç»„çš„æœ€å°äºŒä¹˜è§£</mark>. åŒæ—¶, ä¸€èˆ¬é‡‡ç”¨[[ğŸ“˜ClassNotes/ğŸ“Mathmatics/ğŸ£Probability Theory/ç¬¬å››ç«  éšæœºå˜é‡çš„æ•°å­—ç‰¹å¾#ä¸‰ã€åæ–¹å·®åŠå…¶ç›¸å…³ç³»æ•°|ç›¸å…³ç³»æ•°]]æ–¹æ³•è¿›è¡Œè¯„ä¼°, è¡¡é‡çº¿æ€§ç¨‹åº¦.

### (2) å¾„å‘åŸºå‡½æ•°ç½‘ç»œ
RBF (Radius Basis Function)ç½‘ç»œå¯ä»¥<b><mark style="background: transparent; color: orange">ä»¥ä»»æ„ç²¾åº¦é€¼è¿‘ä»»æ„è¿ç»­æˆ–è€…ç¦»æ•£å‡½æ•°  å¹¶ä¸”ç‰¹åˆ«é€‚åˆè¿›è¡Œéçº¿æ€§é¢„æµ‹å’Œåˆ†ç±»ç­‰ç­‰é—®é¢˜</mark></b>ã€‚åŸºæœ¬æ¶æ„å¦‚ä¸‹:
![[Excalidraw/6. é¢„æµ‹å›å½’åˆæ­¥å’Œ RBF ç½‘ç»œ 2024-11-25 11.24.01|450]]
å…¶ä¸­<mark style="background: transparent; color: red">æ¿€æ´»å‡½æ•°ä¸º</mark>é«˜æ–¯æ ¸å‡½æ•°(æ­£æ€åˆ†å¸ƒå‡½æ•°), å‚è€ƒ[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æ·±åº¦å­¦ä¹ ç®—æ³•åŸç†(sklearn)/è¡¥å……çŸ¥è¯†/5.SVMæ”¯æŒå‘é‡æœº#3. å¾„å‘åŸºå‡½æ•°æ ¸å‡½æ•°(é«˜æ–¯æ ¸)|5.SVMæ”¯æŒå‘é‡æœº]]:
$$ W(i,j) =  \exp \left(- \frac{1}{2\sigma^{2} }||x  - y||^{2}\right)\quad (j = 1,2, \dots   n)$$
å¯¹äºå¾„å‘åŸºå‡½æ•°è€Œè¨€ï¼Œå¸¸è§æ–¹æ³•æœ‰ç²¾ç¡®æ±‚è§£ï¼ŒOLSæ±‚è§£å’ŒKMeansèšç±»æ–¹æ³•ï¼Œ å…¶Matlabä¸­çš„å»ºç«‹æä¸ºå®¹æ˜“:
```Matlab  
newrbeÂ Â Â Â %ç²¾ç¡®æ±‚è§£  
neerbÂ Â Â Â Â Â %OLSæ–¹æ³•  
``` 
éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œå¯¹äºç²¾ç¡®æ±‚è§£æ–¹æ³•ï¼Œæœ‰nä¸ªæ ·æœ¬ç‚¹å°±æœ‰nä¸ªå¾„å‘åŸºå‡½æ•°ï¼Œä¼šå¯¼è‡´æå¤§å¤æ‚æ€§å¢åŠ ã€‚åœ¨matlabä¸­ï¼Œå¯ä»¥ä½¿ç”¨å®šä¹‰è¯¯å·®çš„æ–¹æ³•ï¼Œè€Œç½‘ç»œè¯¯å·®æ˜¯éšç€å¾„å‘åŸºå¢åŠ è€Œä¸‹é™çš„è¿‡ç¨‹ã€‚

å…¶ä¸€èˆ¬åŸç†æ˜¯å…ˆè®¡ç®—æ¬§å¼è·ç¦»å† RBF æ‹Ÿåˆçš„æ–¹æ³•; æƒå€¼è°ƒæ•´æ˜¯é€šè¿‡æ¿€æ´»å‡½æ•°å®ç°çš„, è€Œä¸é‡‡ç”¨åå‘ä¼ æ’­æˆ–è€…[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸ‘¨â€ğŸ“Deep Learning/ğŸ‘¨â€ğŸ“æ·±åº¦å­¦ä¹ ç®—æ³•åŸç†(sklearn)/5. BP ç¥ç»ç½‘ç»œ, SOM ç¥ç»ç½‘ç»œå’Œ Boltzmannæœº|5. BP ç¥ç»ç½‘ç»œ, SOM ç¥ç»ç½‘ç»œå’Œ Boltzmannæœº|BP ç¥ç»ç½‘ç»œ]]ç±»ä¼¼çš„è¯¯å·®åé¦ˆæƒå€¼æ›´æ–°ã€‚

#### 1. è®­ç»ƒè¿‡ç¨‹
é¦–å…ˆ, å¾„å‘åŸºå‡½æ•°ä»ç„¶æ˜¯ä»¥ [[#2. æ­£è§„æ–¹ç¨‹ç»„]] æ€è·¯, å»ºç«‹æ–¹ç¨‹
$$Y  = X\boldsymbol{a}  \quad  \overset{}{\longrightarrow}  X^{T} X \boldsymbol{a}  = X^{T} Y\overset{}{\longrightarrow} a = (X^{T} X)^{-1 } X^{T} Y $$
æˆ‘ä»¬å°†ç³»æ•°å‘é‡ $a$ ç”¨ $w$ è¡¨ç¤º, æˆä¸º
$$w = (X^{T} X^{-1})X^{T}  Y$$
<mark style="background: transparent; color: red">æ ¸æ–¹æ³•å°†ä½ç»´ç©ºé—´ä¸­çš„æ•°æ®çŸ©é˜µ  X æ˜ å°„åˆ° æ–°çš„è®¾è®¡çŸ©é˜µ K, è€Œæ–°çš„è®¾è®¡çŸ©é˜µ K å®é™…ä¸Šæ˜¯é€šè¿‡é‡‡ç”¨ M ä¸ªåŸºå‡½æ•°æ„é€ çš„</mark> 
$$K_{ij} = \phi\left(\frac{||x_{i} - m_{j}||}{\sigma}\right) \qquad \overset{K æ›¿ä»£X, w æ›¿ä»£a}{\longrightarrow}  \qquad K w = y$$

é¦–å…ˆ, è®¾æ ·æœ¬çŸ©é˜µ i, j è¡Œåˆ†åˆ«ä¸º  $x_i, x_j$ åˆ™<b><mark style="background: transparent; color: orange">å¾„å‘åŸºå‡½æ•°æ’å€¼åŠæ³•ä¼šè®¡ç®—ä¸¤è€…è·ç¦»</mark></b>, å¹¶**å½¢æˆä¸€ä¸ª $m \times m$ çš„è·ç¦»çŸ©é˜µ K**:
$$d_{ij} = x_{i} -  x_{j}$$
æˆ‘ä»¬**å–æ’å€¼çŸ©é˜µ K $(m \times m çŸ©é˜µ)$ ä¸ºé«˜æ–¯æ ¸å‡½æ•°**:
$$K_{i,j}  = \exp \left( -  \frac{d_{i,j}  \times  d_{i,j}^{T}}{2 \sigma^{2}} \right) = \exp \left(- \frac{||x_{i} -  x_{j}||^{2}}{2 \sigma^{2}}\right)$$
æ­¤æ—¶ K å·²ç»æ±‚å‡º, å…¶ä¸­ $K$ è¡¨ç¤ºæŸä¸ªè¾“å…¥ç‚¹ $x_i$ åˆ° $x_j$ çš„ç›¸ä¼¼æ€§, $w$ æ˜¯ä¸€ä¸ª $m \times 1$ çš„å‘é‡, è¡¨ç¤ºæƒé‡ã€‚æœ‰
$$y= K w \qquad \overset{åˆ†é‡}{\longrightarrow}\qquad   y_{i} = \sum_{j = 1}^{m} K_{i,j} w_{j} $$
å³å¯è§£å‡ºå¯¹åº”çš„å‘é‡ $w$ 

#### 2. é¢„æµ‹è¿‡ç¨‹
åˆ™**æœ€ç»ˆçš„é¢„æµ‹æ–¹æ³•, é¦–å…ˆéœ€è¦ <b><mark style="background: transparent; color: orange">è®¡ç®—ä¸æ‰€æœ‰è®­ç»ƒç‚¹çš„æ ¸å‡½æ•°</mark></b>**,  è®¾æ–°çš„å‘é‡ä¸º $x$, åˆ™å…ˆè®¡ç®—å’Œæ¯ä¸ªè®­ç»ƒç‚¹çš„è·ç¦», ä»ç„¶å– $y = K w$ ç„¶åå°†è·ç¦» $K$ ä¹˜ $w$ å¾—åˆ°:
$$\boxed{\Large   y = \sum_{i = 1}^{m}  \exp \left( -   \frac{||x - p_{i} ||^{2}}{2 \sigma^{2}}\right)  \times w}$$
å…¶ä¸­ $p_i$ ä¸ºä¸Šè¿°æ‰€æœ‰çš„è®­ç»ƒç‚¹ã€‚

### (3) RBF ç¥ç»ç½‘ç»œä»£ç å®ç°
ä¸‹é¢çš„ä»£ç é‡‡ç”¨ RBF çš„æ’å€¼æ–¹å¼, å®ç°äº†ç»å…¸ matlab å‡½æ•° peaks çš„éšæœº 50 ç‚¹ æ’å€¼ç»˜åˆ¶:

**éœ€è¦æ³¨æ„çš„æ˜¯, å…¶ä¸­ rbf_fun éƒ¨åˆ†, é‡‡ç”¨çŸ©é˜µæ–¹æ³•** `np.exp(- 1 / (2 * sigma ** 2) * np.linalg.norm(d, axis=-1) ** 2) ` é€‚é…äº†å¤šä¸ªè·ç¦»å‘é‡æƒ…å†µä¸‹çš„è·ç¦»è®¡ç®—ã€‚å®ç°äº†**åœ¨é¢„æµ‹æ—¶èƒ½å¤Ÿå¿«é€Ÿè®¡ç®—ä¸å…¶ä»–å„ä¸ªè®­ç»ƒç‚¹çš„è·ç¦»å‘é‡**

```python fold title:RBFå¾„å‘åŸºå‡½æ•°æ’å€¼çš„pythonå®ç°
import numpy as np  
import sys  
import os  
import matplotlib.pyplot as plt  
from  mpl_toolkits.mplot3d import Axes3D  
from scipy.interpolate import griddata  
  
os.chdir(os.path.dirname(os.path.abspath(__file__)))  
  
mu = 0.02  
k  = 0.03  
  
def activate_fun(x,W,c):  
    y = np.sum(np.exp(-1/(2 * sigma **2) * np.linalg.norm(x-c)**2))  
  
class RBF_test():  
    def __init__(self, x,y):  
        self.x = x  
        self.y = y  
        if np.ndim(x) == 2:  
            self.m, self.n = x.shape  
        else:  
            raise ValueError("x must be 2D array")  
  
    def train(self):  
        K = np.zeros((self.m, self.m))  
        for i in range(self.m):  
            for j in range(self.m):  
                d  = self.x[i,:] - self.x[j,:]   # è®¡ç®—ä¸¤ç‚¹ä¹‹é—´çš„è·ç¦»å‘é‡  
                K[i,j] = self.rbf_fun(d)      # æƒé‡çŸ©é˜µçš„æ¯ä¸€é¡¹æŒ‰ç…§é«˜æ–¯å‡½æ•°è®¡ç®—;  
        self.w = np.linalg.solve(K, self.y)  
  
    def predict(self, x):  
        d = (self.x - x)  # è®¡ç®—è¾“å…¥å‘é‡ä¸æ‰€æœ‰è®­ç»ƒé›†å‘é‡ä¹‹é—´çš„è·ç¦»å‘é‡  
        y = np.sum(self.rbf_fun(d) @ self.w)        # è®¡ç®—é¢„æµ‹å€¼  
        return y  
  
    def rbf_fun(self, d, sigma = 1.0):  
        # å¯¹äº d ä¸ºçŸ©é˜µæ—¶, å®é™…ä¸Šä¸æ˜¯ d @  d.T, è€Œæ˜¯é‡‡ç”¨ np.linalg.norm        return np.exp(- 1 / (2 * sigma ** 2) * np.linalg.norm(d, axis=-1) ** 2)  # é‡‡ç”¨ axis = -1 è¡¨ç¤ºå¯¹æœ€åä¸€ä¸ªç»´åº¦è¿›è¡Œè®¡ç®—  
  
  
def peaks(x, y):  
    term1 = 3 * (1 - x) ** 2 * np.exp(-x ** 2 - (y + 1) ** 2)  
    term2 = -10 * (x / 5 - x ** 3 - y ** 5) * np.exp(-x ** 2 - y ** 2)  
    term3 = -1 / 3 * np.exp(-(x + 1) ** 2 - y ** 2)  
    return term1 + term2 + term3  
  
  
if __name__ == '__main__':  
    # sample 50 points  
    x1 = np.random.rand(50) * 6 - 3  
    x2 = np.random.rand(50) * 6 - 3  
    X  = np.array([x1, x2]).T  
    Y = peaks(x1, x2)    #  np.sin(np.sqrt(x1 ** 2 + x2 ** 2)) *  np.sqrt(x1 ** 2 + x2 ** 2)  
    rt = RBF_test(X, Y)  
    rt.train()  
  
    # ç”Ÿæˆç½‘æ ¼ç‚¹  
    x_grid = np.linspace(-3, 3, 100)  
    y_grid = np.linspace(-3, 3, 100)  
    x_mesh, y_mesh = np.meshgrid(x_grid, y_grid)  
    z_mesh = np.zeros_like(x_mesh)  
  
    X_input = np.array([np.hstack(x_mesh), np.hstack(y_mesh)]).T  # å°†ç½‘æ ¼ç‚¹è½¬æ¢ä¸ºè¾“å…¥ X çŸ©é˜µ  
  
    for i in range (x_mesh.shape[0]):  
        for j in range(x_mesh.shape[1]):  
            z_mesh[i,j] = rt.predict([x_mesh[i,j], y_mesh[i,j]])  
    fig = plt.figure(figsize=(10, 7))  
    ax = fig.add_subplot(1, 2, 1, projection='3d')  
    ax.plot_surface(x_mesh, y_mesh, z_mesh, cmap='viridis')  
  
    # ç»˜åˆ¶åŸå§‹å‡½æ•°çš„æ’å€¼æ˜¾ç¤º  
    ax2 = fig.add_subplot(1, 2, 2, projection='3d')  
    z_mesh = griddata(X, Y, (x_mesh, y_mesh), method='linear') # æ’å€¼ï¼ˆçº¿æ€§ï¼‰  
    ax2.plot_surface(x_mesh, y_mesh, z_mesh, cmap='viridis')  
    plt.show()
```

è·å¾—å¦‚ä¸‹çš„æ’å€¼å›¾åƒ (ç¬¬ä¸€å¼ æ˜¯æ’å€¼ç»“æœ)
![[attachments/Pasted image 20241125171319.png|450]]

## äºŒã€å²­å›å½’å’Œ Lasso å›å½’
### (1) å¤šé‡å…±çº¿æ€§çš„æ¦‚å¿µä¸éªŒè¯
åœ¨æœ€å°äºŒä¹˜æ³•å’Œ RBF é«˜æ–¯æ ¸å‡½æ•°é¢„æµ‹çš„, **æœ‰ä¸€ä¸ªé™åˆ¶è¦æ±‚**, å³æ ·æœ¬çŸ©é˜µçš„è¡Œåˆ—å¼ä¸èƒ½ä¸º0, æˆ–è€…<b><mark style="background: transparent; color: blue">æ ·æœ¬çš„å„ä¸ªç‰¹å¾ä¹‹é—´ä¸è¡¨ç°ä¸ºå¼ºçƒˆçš„çº¿æ€§ç›¸å…³æ€§</mark></b>, **å¹¶å°†æ­¤ç§°ä¸ºå¤šé‡å…±çº¿æ€§**. è¿™ç§ä¼šå¯¼è‡´æ¨¡å‹ä¼°è®¡å¤±çœŸ, è€Œå¯¹äºå¤§å¤šæ•°æ•°æ®, æœ‰å¯èƒ½æœ‰è¿‘ä¼¼å…±çº¿æ€§å‡ºç°ã€‚

å²­å›å½’(Ridge Regression)æ˜¯ä¸€ç§æœ€å°äºŒä¹˜çš„æ”¹è¿›ç­–ç•¥,  æ˜¯å¯¹äºçº¿æ€§ç³»ç»Ÿå¸¸ç”¨çš„ä¼°è®¡æ–¹å¼ã€‚
é¦–å…ˆ, æˆ‘ä»¬å¯ä»¥é€šè¿‡è®¡ç®—ç›¸å…³ç³»æ•°çŸ©é˜µå¾—åˆ°æ¯ä¸€åˆ—çš„ç›¸å…³æ€§ã€‚è¿™ä¸ªå¯ä»¥é€šè¿‡ np.corrcoef å¾—åˆ° Pearson ç›¸å…³ç³»æ•° 
```python
import numpy as np
data = np.random.rand(10, 2) # éšæœºç”Ÿæˆ 10x2 æ•°æ®
correlation_matrix = np.corrcoef(data, rowvar=True)
# å¾—åˆ°æ¯ä¸€è¡Œçš„å‘é‡
np.linalg.det(x.T @ x)  # è®¡ç®—å…±çº¿æ€§ç¨‹åº¦
```

é¦–å…ˆ, çŸ©é˜µçš„éšæœºå˜é‡ä¹‹é—´å­˜åœ¨å¤šé‡å…±çº¿æ€§, å³æœ‰:
$$\left| X^{T}  X\right| \approx 0 $$
æˆ‘ä»¬åŠ ä¸Šä¸€ä¸ªå‚æ•°çŸ©é˜µ $kI$, æ­¤æ—¶ $X^{T}  X+ KI$ çš„å¥‡å¼‚ç¨‹åº¦æ˜¾ç„¶ä¼šæ˜¾è‘—å‡å°, åˆ™æ ‡å‡†åŒ–åä»ç„¶é‡‡ç”¨ $X$ è¡¨ç¤º, å¹¶å®šä¹‰å¯¹äºåŸå§‹æ–¹ç¨‹
$$Y = X \alpha $$
å– $\alpha$ çš„è¿‘ä¼¼:
$$\Large\boxed{\alpha(k) = (X^{T} X +  \lambda I)^{-1}  X^{T }Y}$$
ç§°ä¸º $\alpha(k)$ çš„å²­å›å½’ä¼°è®¡; å¹¶ç§°**å…¶ä¸­ $\lambda$ ä¸ºå²­å‚æ•°**;

`````ad-note
title: è¡¥å……: å²­å›å½’å’Œå¤å…¸å›å½’çš„è¡¨è¾¾ä»¥åŠç›¸å…³æ¨å¯¼
collapse: open
ç›¸è¾ƒäºå¤å…¸å›å½’çš„æŸå¤±å‡½æ•°, æœ‰ $Y= X \theta$, è®¤ä¸ºæŸå¤±å‡½æ•°ä¸º:
$$\hat{\theta} = \arg\min_{\theta} \left\| Y - X\theta \right\|_2^2$$
å…¶ä¸­, $\theta$ ä¸ºè¡¨ç¤ºæƒé‡çš„å‚å˜é‡

ç›¸æ¯”äºå¤å…¸å›å½’, <b><mark style="background: transparent; color: orange">å²­å›å½’</mark></b>é€šè¿‡åœ¨**æ™®é€šæœ€å°äºŒä¹˜æ³•çš„ç›®æ ‡å‡½æ•°ä¸­åŠ å…¥ä¸€ä¸ªæ­£åˆ™åŒ–é¡¹æ¥çº¦æŸå›å½’ç³»æ•°**ã€‚æ­£åˆ™åŒ–é¡¹é€šå¸¸æ˜¯ 1 èŒƒæ•°æˆ–è€… 2 èŒƒæ•° (æ­¤å¤„å–ä¸º2èŒƒæ•°å¹³æ–¹)ï¼Œæ—¨åœ¨**ç¼©å°å›å½’ç³»æ•°çš„ç»å¯¹å€¼ï¼Œä»è€Œæé«˜æ¨¡å‹çš„ç¨³å®šæ€§**ï¼Œç‰¹åˆ«æ˜¯åœ¨å­˜åœ¨å¤šé‡å…±çº¿æ€§çš„æƒ…å†µä¸‹ã€‚

å²­å›å½’å¯¹åº”çš„ç›®æ ‡å‡½æ•°å¦‚ä¸‹:
$$\hat{\theta} = \arg\min_{\theta} \left( \left\| Y - X\theta \right\|_2^2 + \lambda \left\| \theta\right\|_2^2 \right)$$

å±•å¼€åˆå¹¶, åˆ™ $J(\theta)= \hat{\theta}$ ä¸ºæˆ‘ä»¬çš„ç›®æ ‡å‡½æ•° :
$$\hat{\theta} = \text{arg}\min_{\theta} (Y - X\theta)^{T} (Y - X\theta) = Y^{T} Y - 2 \theta^{T} X^{T} Y + \theta^{T} X^{T} X \theta + \lambda \theta^{T}  \theta = J(\theta)$$
æ­¤æ—¶, å¯¹ç›®æ ‡å‡½æ•°æ±‚æ¢¯åº¦,  å˜ä¸º 
$$\nabla_{\theta} J(\theta) = -2 v^{T}\cdot X^{T}Y  + 2 v^{T} X^{T} X \theta +  2 \lambda v^{T} \theta$$
å– $\nabla_{\theta} = 0$ å…¶ä¸­ $v = (1,1,1,\dots 1)^T$, åˆ™æœ€å°åŒ–æ—¶, å°† $v^{T}$ æå‡º,  æœ‰:
$$X^{T } Y =  X^{T} X \theta  + \lambda I \theta$$
å®¹æ˜“å¾—åˆ°æœ€å°äºŒä¹˜çš„è§’åº¦æ¥çœ‹çš„æœ€å°å€¼å¯¹åº”$\theta$å…¬å¼: 
$$\theta =  (X^{T} X +  \lambda I)^{-1} X ^{T} Y$$
å› æ­¤ä¸Šé¢çš„ä¸¤ç§è¡¨è¾¾å½¢å¼æ˜¯ç­‰ä»·çš„ã€‚
`````

### (2) å²­è¿¹åˆ†æ
é¦–å…ˆ, å‡è®¾ X å·²ç»æ ‡å‡†åŒ–, åˆ™ $X^T X$ ä¸ºè‡ªå˜é‡æ ·æœ¬ç›¸å…³é˜µ, <b><mark style="background: transparent; color: orange">å¦‚æœ Y ä¹Ÿæ ‡å‡†åŒ–è¿‡, åˆ™è®¡ç®—ç»“æœæ˜¯æ ‡å‡†åŒ–åçš„å²­å›å½’ä¼°è®¡</mark></b>ã€‚

æ˜¾ç„¶ï¼Œ$A(\lambda)$ æ˜¯ $\lambda$ çš„å‡½æ•°, è€Œ $A(\lambda)$ éš  çš„è½¨è¿¹ç§°ä¸ºå²­è¿¹, éœ€è¦è¯´æ˜, $A (\lambda)$ æ˜¯å›å½’å‚æ•° A çš„æœ‰åä¼°è®¡ 
![[Excalidraw/6. é¢„æµ‹å›å½’åˆæ­¥å’Œ RBF ç½‘ç»œ 2024-11-25 18.44.39|450]]

å®é™…ä¸Š $A(\lambda)$ ä½œä¸º A çš„æœ‰åä¼°è®¡æ¯”æœ€å°äºŒä¹˜ä¼°è®¡æ›´åŠ ç¨³å®šã€‚

å¯¹äº**å›¾1  æ‰€ç¤ºçš„å²­è¿¹**, å½“å²­è¿¹æœ‰æ˜¾è‘—çš„ä¸Šå‡æˆ–è€…ä¸‹é™æ—¶, åˆ™ $X^{T} X$ å¯¹ $Y$ çš„å½±å“æ˜¯æ¯”è¾ƒå¤§çš„, åªè¦åœ¨å…¶ä¸Šé™„åŠ ä¸€å®šéƒ¨åˆ†, å°±ä¼šäº§ç”Ÿæ˜¾è‘—å½±å“(ä¸»è¦æŒ‡æ­£è´Ÿæ”¹å˜)ã€‚

ä¾‹å¦‚å›¾4ä¸­, $A_1(\lambda)$ å’Œ $A_{2}(\lambda)$, è™½ç„¶ $A_2(\lambda)$ ä¸ç¨³å®š, è€Œæ€»ä½“ä¸Šæ˜¯ç¨³å®šçš„, <b><mark style="background: transparent; color: orange">è¿™ç§æƒ…å†µå¾€å¾€å‡ºç°äºç›¸å…³æ€§å¾ˆå¤§çš„åœºåˆ, æ­¤æ—¶ä»å˜é‡é€‰æ‹©è§’åº¦è€Œè¨€, A, B ä¿ç•™ä¸€ä¸ªå°±å¤Ÿäº†</mark></b>ã€‚(å¾€å¾€æ˜¯ç¬¦å·ä¸åˆç†é€ æˆçš„)

å¦‚æœå°†æŸä¸€å…·ä½“å®ä¾‹ä¸­, åˆ¤æ–­æœ€å°äºŒä¹˜æ˜¯å¦é€‚ç”¨,  æˆ‘ä»¬å¯ä»¥å°†æ‰€æœ‰çš„å›å½’ç³»æ•°å²­è¿¹ç”»å‡º, é’ˆå¯¹äºå›¾ 5 ä¸­, åˆ™å¯èƒ½æœ€å°äºŒä¹˜æ˜¯ä¸é€‚ç”¨çš„; è€Œé’ˆå¯¹å›¾ 6, æœ€å°äºŒä¹˜ä¸€èˆ¬æ˜¯é€‚ç”¨çš„ã€‚

ä¸€èˆ¬çš„ $\lambda$ å€¼é€‰å–åŸåˆ™: 
1. æ‰€æœ‰å›å½’ç³»æ•°çš„å²­ä¼°è®¡éƒ½æ˜¯è¶‹å‘äºç¨³å®šçš„;
2. æœ€å°äºŒä¹˜ä¼°è®¡ä¸­ï¼Œ ç¬¦å·ä¸åˆç†çš„å›å½’ç³»æ•°, åœ¨å²­å›å½’ä¸­å˜ä¸ºåˆç†
3. æ®‹å·®å¹³æ–¹å’Œå¢å¤§ä¸å¤ªå¤š 
4. å¯å‰”é™¤è¾ƒå°æˆ–è€…è¶‹äºé›¶çš„ä¸åˆç† $\lambda$ å€¼

æœ€å¸¸ç”¨çš„åŒ…æ‹¬ **==Horel-Kennard å…¬å¼, å²­è¿¹æ³•å’Œäº¤å‰éªŒè¯æ³•==** 

### (3) Lasso å›å½’æ¨¡å‹
å¯¹äºçº¿æ€§æ¨¡å‹, ä¸Šé¢æˆ‘ä»¬å·²ç»æ¨å¯¼å‡º:
$$\alpha = (X^{T} X )^{-1 } X^{T} y$$
è€ŒæŸå¤±å‡½æ•°ä¸º $J(\alpha) = (y - \alpha X)^{T}(y - \alpha X)$

Lasso å›å½’æ˜¯é‡‡ç”¨ 1 èŒƒæ•°ä»£æ›¿å²­å›å½’ä¸­æ·»åŠ çš„ 2 èŒƒæ•°:
$$\hat{\theta} = \text{arg}\min_{\theta} || y - X \theta ||^{2} + \lambda ||\theta||_{1}$$
å¯¹äºå‘é‡, æœ‰ $||\theta||_{1} = \sum_{i = 1}^{n}  |\theta_{i}|$ 

Lass æ–¹æ³•çš„ä¼˜ç‚¹æ˜¯å¯ä»¥è§£å†³é«˜ç»´æ•°æ®çš„ç¨€ç–æ€§ï¼Œé‡‡ç”¨ Lasso æ–¹æ³•å¯ä»¥å°†ä¸é‡è¦çš„å˜é‡ç³»æ•°å‹ç¼©ä¸º 0, ä»è€Œå®ç°äº†**å˜é‡é™ç»´**å’Œå‚æ•°ä¼°è®¡ã€‚

éœ€è¦è¯´æ˜,  Lasso æœ€ä¼˜è§£ç”±äºçº¦æŸæ¡ä»¶ä¸å¯å¯¼ï¼Œæ— æ³•ç›´æ¥æ±‚è§£æ¢¯åº¦; å› æ­¤å¸¸ç”¨
1. åæ ‡è½´ä¸‹é™æ³•
2. æœ€å°è§’å›å½’æ³•
(å…·ä½“å‚è€ƒ[çŸ¥ä¹æ–‡ç« ](https://www.zhihu.com/collection/971827377))


### (4) æ³¢å£«é¡¿æˆ¿ä»·å²­å›å½’é¢„æµ‹å®æˆ˜
è¦æ±‚: **å¯¹äº Boston æˆ¿ä»·éƒ¨åˆ†, å»ºç«‹å²­å›å½’å’Œ Lasso å›å½’æ¨¡å‹, åŒæ—¶ç»˜åˆ¶å²­è¿¹å›¾, æ ¹æ®  RMSE (root mean squared error) å’Œ R2 åˆ†æ•°, æµ‹è¯•æ¨¡å‹çš„æ€§èƒ½**, å¹¶ä¸”<mark style="background: transparent; color: red">åˆ©ç”¨äº¤å‰éªŒè¯å’Œæ­£åˆ™å‚æ•°è°ƒä¼˜</mark>æ¥è·å–æœ€ä¼˜çš„å²­å›å½’æ­£åˆ™åŒ–å‚æ•° $\lambda$. 

å¯ä»¥ç›´æ¥è°ƒç”¨ `from sklearn.linear_model import Ridge` å»ºç«‹å²­å›å½’æ¨¡å‹, è€Œä¹Ÿå¯ä»¥é‡‡ç”¨, å¹¶é‡‡ç”¨
`coef_ : ndarray of shape (n_features,) or (n_targets, n_features): Weight vector(s).`
å‚æ•°ç›´æ¥è·å– $A(\lambda)$, å³ $\alpha$ï¼Œæƒé‡å‘é‡. 

å¯¹äº 8 å˜é‡çš„éƒ¨åˆ†, å¾—åˆ°çš„ coef_ å‚æ•°æ˜¯ä¸€ä¸ª 8 å¤§å°çš„æ•°ç»„;

å– k çš„èŒƒå›´ä¸º 0-5000, ç»˜åˆ¶å‡ºå²­è¿¹å›¾å¦‚ä¸‹æ‰€ç¤º, è¯´æ˜å¯¹äºè¯¥é—®é¢˜å²­è¿¹å›¾æœ‰è¾ƒå¥½çš„ç°è±¡, å¯ä»¥é‡‡ç”¨æœ€å°äºŒä¹˜æ–¹æ³•ç±»ä¼¼çš„è¿›è¡Œå›å½’åˆ†æã€‚
![[attachments/Pasted image 20241126011042.png|450]]




2. **å²­å›å½’åˆ†æ**ï¼šé€šè¿‡ä¸åŒçš„ Î»\lambda å€¼ï¼Œè¿›è¡Œå²­å›å½’å¹¶ç»˜åˆ¶å²­è¿¹å›¾ã€‚
3. **æœ€ä¼˜ Î»\lambda é€‰æ‹©**ï¼šä½¿ç”¨äº¤å‰éªŒè¯æ¥é€‰æ‹©æœ€ä¼˜çš„æ­£åˆ™åŒ–å‚æ•°ã€‚

### ä»£ç ç¤ºä¾‹ï¼š

```python
import numpy as np
import matplotlib.pyplot as plt
from sklearn.datasets import load_boston
from sklearn.model_selection import train_test_split
from sklearn.linear_model import Ridge
from sklearn.model_selection import cross_val_score

# 1. åŠ è½½æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†
boston = load_boston()
X = boston.data
y = boston.target

# 2. æ‹†åˆ†æ•°æ®é›†
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)

# 3. å®šä¹‰ä¸åŒçš„æ­£åˆ™åŒ–å‚æ•° alpha å€¼
alphas = np.logspace(-6, 6, 200)

# 4. å²­å›å½’å¹¶è®¡ç®—ç³»æ•°
coefficients = []
for alpha in alphas:
    ridge = Ridge(alpha=alpha)
    ridge.fit(X_train, y_train)
    coefficients.append(ridge.coef_)

# 5. ç»˜åˆ¶å²­è¿¹å›¾
coefficients = np.array(coefficients)
plt.figure(figsize=(10, 6))
plt.plot(alphas, coefficients)
plt.xscale('log')
plt.xlabel('æ­£åˆ™åŒ–å‚æ•° alpha (log scale)')
plt.ylabel('å›å½’ç³»æ•°')
plt.title('å²­è¿¹å›¾ (Ridge Trace)')
plt.axis('tight')
plt.show()

# 6. ä½¿ç”¨äº¤å‰éªŒè¯æ¥é€‰æ‹©æœ€ä¼˜çš„ alpha å€¼
ridge = Ridge()
scores = []
for alpha in alphas:
    ridge.alpha = alpha
    score = cross_val_score(ridge, X_train, y_train, cv=5, scoring='neg_mean_squared_error')
    scores.append(np.mean(score))

# 7. æ‰¾åˆ°æœ€ä¼˜çš„ alpha
best_alpha = alphas[np.argmax(scores)]
print(f"æœ€ä¼˜çš„ alpha å‚æ•°å€¼æ˜¯: {best_alpha}")

# 8. æœ€ä¼˜æ¨¡å‹è¯„ä¼°
ridge = Ridge(alpha=best_alpha)
ridge.fit(X_train, y_train)
test_score = ridge.score(X_test, y_test)
print(f"åœ¨æµ‹è¯•é›†ä¸Šçš„ R^2 å¾—åˆ†ä¸º: {test_score}")
```

### è§£é‡Šï¼š

1. **æ•°æ®é›†**ï¼šæˆ‘ä»¬ä½¿ç”¨ `load_boston()` å‡½æ•°åŠ è½½æ³¢å£«é¡¿æˆ¿ä»·æ•°æ®é›†ï¼Œå¹¶å°†å…¶åˆ†ä¸ºè®­ç»ƒé›†å’Œæµ‹è¯•é›†ã€‚
2. **å²­å›å½’ç³»æ•°**ï¼šæˆ‘ä»¬é€šè¿‡ `Ridge` ç±»å¯¹ä¸åŒçš„ Î±\alpha å€¼ï¼ˆæ­£åˆ™åŒ–å¼ºåº¦ï¼‰è¿›è¡Œå²­å›å½’ï¼Œå¹¶ç»˜åˆ¶æ¯ä¸ª Î±\alpha å¯¹åº”çš„å›å½’ç³»æ•°ã€‚
3. **å²­è¿¹å›¾**ï¼šé€šè¿‡ `matplotlib` ç»˜åˆ¶ä¸åŒ Î±\alpha å€¼ä¸‹çš„å›å½’ç³»æ•°ï¼Œè§‚å¯Ÿæ­£åˆ™åŒ–å¼ºåº¦å¦‚ä½•å½±å“ç³»æ•°å¤§å°ã€‚
4. **æœ€ä¼˜ Î±\alpha é€‰æ‹©**ï¼šæˆ‘ä»¬é€šè¿‡äº¤å‰éªŒè¯è®¡ç®—æ¯ä¸ª Î±\alpha çš„æ¨¡å‹è¯„åˆ†ï¼ˆä½¿ç”¨è´Ÿå‡æ–¹è¯¯å·®ï¼‰ï¼Œç„¶åé€‰æ‹©ä½¿å¾—è¯„åˆ†æœ€å¥½çš„ Î±\alpha ä½œä¸ºæœ€ä¼˜å‚æ•°ã€‚
5. **æ¨¡å‹è¯„ä¼°**ï¼šåœ¨é€‰æ‹©æœ€ä¼˜çš„ Î±\alpha åï¼Œæˆ‘ä»¬åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹çš„æ€§èƒ½ï¼Œè¾“å‡º RÂ² å¾—åˆ†ã€‚

### å²­è¿¹å›¾åˆ†æï¼š

- å²­è¿¹å›¾æ˜¾ç¤ºäº†éšç€ Î±\alpha å¢åŠ ï¼Œå›å½’ç³»æ•°çš„å˜åŒ–è¶‹åŠ¿ã€‚è¾ƒå°çš„ Î±\alpha å€¼ï¼ˆæ¥è¿‘0ï¼‰å¯¹åº”çš„ç³»æ•°è¾ƒå¤§ï¼Œéšç€ Î±\alpha çš„å¢å¤§ï¼Œå›å½’ç³»æ•°ä¼šè¢«å‹ç¼©ï¼Œè¶‹å‘äºé›¶ã€‚
- æˆ‘ä»¬å¯ä»¥é€šè¿‡è§‚å¯Ÿå²­è¿¹å›¾ï¼Œç†è§£ä¸åŒç‰¹å¾å¯¹ç›®æ ‡å˜é‡çš„å½±å“ï¼ŒåŒæ—¶ä¹Ÿèƒ½çœ‹åˆ°æ­£åˆ™åŒ–å¦‚ä½•å½±å“æ¨¡å‹å¤æ‚åº¦ã€‚

### æœ€ä¼˜ Î±\alpha å‚æ•°ï¼š

- é€šè¿‡äº¤å‰éªŒè¯ï¼Œé€‰æ‹©æœ€ä¼˜çš„ Î±\alpha å‚æ•°æ¥å¹³è¡¡æ¨¡å‹çš„åå·®ä¸æ–¹å·®ï¼Œç¡®ä¿æ¨¡å‹çš„æ³›åŒ–èƒ½åŠ›ã€‚

### è¾“å‡ºç¤ºä¾‹ï¼š

```plaintext
æœ€ä¼˜çš„ alpha å‚æ•°å€¼æ˜¯: 0.18556109619943295
åœ¨æµ‹è¯•é›†ä¸Šçš„ R^2 å¾—åˆ†ä¸º: 0.8397402877122464
```

è¿™æ®µä»£ç æä¾›äº†ä¸€ä¸ªå®Œæ•´çš„å²­å›å½’ç¤ºä¾‹ï¼ŒåŒ…æ‹¬äº†å²­è¿¹å›¾çš„ç»˜åˆ¶å’Œæœ€ä¼˜æ­£åˆ™åŒ–å‚æ•°çš„é€‰æ‹©è¿‡ç¨‹ï¼Œé€‚ç”¨äºä½ éœ€è¦äº†è§£å¦‚ä½•é€šè¿‡æ­£åˆ™åŒ–ä¼˜åŒ–å›å½’æ¨¡å‹çš„æƒ…å†µã€‚



