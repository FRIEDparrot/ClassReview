参考文章 : https://blog.csdn.net/weixin_51545953/article/details/127160151   
##  一、GNN 基本概念
### (1) 邻接矩阵定义 
例如， 除了一般图的[[📘ClassNotes/⌨️Programming/🌳Data Structure & Algorithms/〽️ Data Structure/第七章 图#(1) 邻接矩阵表示方法|邻接矩阵]],  也可以将邻接矩阵推广到文本数据, 例如用于分析关联性 : 
![[Excalidraw/2. 图神经网络 (GNN) 简介 2025-06-13 10.22.17|300]]

同时, GNN 可用于解不同城市道路和节点数量均不固定的问题。 

### (2) 常见的任务类型 
图神经网络主要任务包括 : 
1. 针对节点整合特征向量， 进行分类或者回归  
2. 为每条边整合特征向量， 根据其边做分类或者回归 
3. 为图整合特征向量， 根据此对图做分类或者回归 

此外， 除了邻接矩阵以外， 邻接表和十字链表均可以用于减少内存。   

例如 : 
-  预测分子结构图， 判断是哪一类 (图分类问题)
-  预测某个点是哪一类  
-  预测边是哪一类 

### (3) 输入和输出特性
在 GNN 图神经网络中， 其输入是特征， 输出也是特征。 而 GNN 本质就是**更新图各个部分的特征**。而整个过程中， 邻接矩阵是不变的；

例如， 可以采用**输入两个图，输出一个关联图**的任务框架， 这种情况可以使用 Encoder-Decoder GNN 架构做图生成架构。
$encoder1 \rightarrow  h1 \qquad  encoder2 \rightarrow  h2 \rightarrow  z =f(h_{1}, h_{2})$ 

也可以使用 **Graph Transformer** 或 **Graph Diffusion Models** 解码器做结构生成 (可参考[GraphGPT](https://arxiv.org/abs/2301.08210))

常用的库是 `torch_geometric` 部分. 只需采用如下部分 : 
```python fold title:安装
pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu126.html
pip install torch-geometric 
```

通常输入 : 
1. 各个节点的输入特征 
2. 网络结构图
## 2. 图卷积网络 (GCN) 
### (1)  基本思想 
对于 GCN, 属于<b><mark style="background: transparent; color: orange">半监督式学习</mark></b> (semi-supervised learning),   
1. 首先， 至少需要一个节点具有标签， 
2.  **计算 Loss 时， 仅考虑有标签的节点**
3. 不需要所有节点都有标签  
4. 一般 GCN 层数不会太多， 在 2-3 层左右;  

对于具有标签的节点，<b><mark style="background: transparent; color: orange">平均其邻居特征之后， 传入神经网络</mark></b>。

对于图神经网络，每个节点均有一个特征
![[Excalidraw/2. 图神经网络 (GNN) 简介 2025-06-13 11.16.10|400]]
<b><mark style="background: transparent; color: orange">特征的计算是邻接矩阵和特征矩阵进行乘法操作来聚合相邻节点信息</mark></b> : 
$$X' = A  \cdot  X \qquad   (n \times  n)  \times  (n\times m)$$
### (2) 邻接矩阵的变换 
首先， 我们可以考虑在邻接矩阵中， 加上对角矩阵保证自身项 :  
$$\tilde{A} = A +  \lambda I_{N}$$
此时， 对角线元素部分在相乘之后， 得到的是行上部分所有的总加和 
$$X_{i}' =  \sum_{j = 1}^{n} A_{ij} X_{j}$$
同时， 引入<b><mark style="background: transparent; color: orange">带有自环的度矩阵</mark></b> $\tilde{D}$  : 
$$\tilde{D}_{ii} =\sum_{j}  \tilde{A}_{jj}  = D + I$$
显然，当一个节点的度越大，得到的乘法结果度也累加更多， 因此， 我们可以采用 $\tilde{D}^{-1}$ 进行平均变换后的矩阵 A 的结果 : 
$$\tilde{D}^{-1} (\tilde{A} X)$$
但是由于左乘仅对行做了归一化， 为了保证能够对列也有归一化特性， 上述可以修改为: 
$$\boxed{\Large \hat{A} =  \tilde{D}^{-\frac{1}{2}} \tilde{A}  \tilde{D}^{-\frac{1}{2}} X}$$
而<b><mark style="background: transparent; color: orange"> softmax 是 GNN 中最常用的归一化函数 </mark></b> 
$$Z = f(X, A) =  \text{softmax}(\hat{A}\space   \text{ReLU}(\hat{A} X W^{(0)}) W^{(1)} )$$
其中, 设 X 的长度为 $C$ ,  $AX$  为 $N \times C$ 向量矩阵, 隐藏层为 $H$, 输出层 F,  则首先第一层输入维度为 $N\times C$, 则:
$$N \times  H$$
第二层为 $F \times H$ 

> [!summary] 总结
> 图神经网络相对于 CNN 部分，  卷积是卷积核的计算和平移， 而图神经网络也是利用邻接点的特征， 但是不增加任何通道数。 

### (3) 利用 torch.geometric 构建网络数据集 
首先， 点的定义是 $n \times 2$ 的 torch 向量  
边是 $2 * m$ 的  torch 向量，其中每个是相应点的下标
利用 torch_geometry.data.Data 构建图数据集的图数据部分

> [!HINT] 节点的特征向量
> 节点的特征向量维数即为对应节点的坐标位置， 例如下方部分的 $X$ 即是二维的。对于更高维的部分， 可以将对应的附加到坐标上。 
> 
> 至于可视化部分， 一般需要剪裁相应的维度部分， 并进行 2D 可视化。 

```python fold title:构建图网络数据的示例
import torch
from torch_geometric.data import Data 

if __name__ == '__main__':
    # 定义节点特征向量x和标签y
    x = torch.tensor([[2, 1], [5, 6], [3, 7], [12, 0]], dtype=torch.float)
    y = torch.tensor([0, 1, 0, 1], dtype=torch.float) 
	
    # 定义边
    edge_index = torch.tensor([[0, 1, 2, 0, 3],  # 起始点
                               [1, 0, 1, 3, 2]], dtype=torch.long)  # 终止点

    # 定义train_mask
    train_mask = [(True if d is not None else False) for d in y]  # train_mask 设置全为 True, 即不添加 mask. 

    # 构建data
    data = Data(x=x, y=y, edge_index=edge_index, train_mask=train_mask)
    print("data:", data)
    print("train_mask:", data.train_mask)
```

### (4) 训练数据集的简单示例 
加载 KarateClub 数据集 : 
```python fold title:
from torch_geometric.datasets import KarateClub  
from torch_geometric.utils import to_networkx  
import networkx as nx  
import matplotlib.pyplot as plt  
  
# load the KarateClub dataset  
dataset = KarateClub()  
print("number of graphs:", len(dataset))  
print("features:", dataset.num_features)  
print("classes:", dataset.num_classes)  
  
data = dataset[0]  
  
print("nodes of first graph:", data.num_nodes)  
print("edges of first graph:", data.num_edges)  
  
print(data.num_node_features, data.num_edge_features)  
  
graph = to_networkx(data)  
  
nx.draw_networkx(graph, node_color=data.y) 
plt.show()
```

其中第一个元素即为对应的 graph, 如下 :`Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])`, 其中共有 34 个 node_features (给出的分好类的节点数量)

![[attachments/Pasted image 20250613155851.png|300]]
此外也可以更改其中的 Pos, 注意 spring_layout 是<b><mark style="background: transparent; color: orange">通过力导向布局算法， 模拟物理互斥力计算节点的位置</mark></b>  
```python fold title:
nx.draw_networkx(graph, pos=nx.spring_layout(graph, seed=42), node_color=data.y)
```

给出一个简单的 GNN 网络如下 : 
```python fold title:GNN图神经网络基本分类示例
from torch_geometric.datasets import KarateClub  
from torch_geometric.utils import to_networkx  
import torch  
import torch.nn as nn  
import torch_geometric.nn as gnn  
import networkx as nx  
import matplotlib.pyplot as plt  
  
dataset = KarateClub()  
data = dataset[0]  
  
  
class GCN(nn.Module):  
    def __init__(self, num_features, num_classes):  
        super(GCN, self).__init__()  
        self.num_features = num_features  
        self.num_classes = num_classes  
  
        # define the network architecture  
        self.conv1 = gnn.GCNConv(num_features, 16)  
        self.relu1 = nn.ReLU()  
        self.conv2 = gnn.GCNConv(16, 16)  
        self.relu2 = nn.ReLU()  
        self.linear = nn.Linear(16, num_classes)  
  
    def forward(self, x, edge_index):  
        h = self.conv1(x, edge_index)  
        h = self.relu1(h)  
        h = self.conv2(h, edge_index)  
        h = self.relu2(h)  
        out = self.linear(h)  
        return out, h  
  
  
def train():  
    num_features = dataset.num_features  
    num_classes = dataset.num_classes  
    model = GCN(num_features, num_classes)  
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  
    criterion = nn.CrossEntropyLoss()  
      
    for epoch in range(100):  
        model.train()  
        optimizer.zero_grad()  
        # since the final layer is the classifier (classify each point)  
        out, h = model(data.x, data.edge_index)  
  
        # use data.y as the train target  
        loss = criterion(out, data.y)  # use out[data.train_mask] if want to mask on train set  
        loss.backward()  
        optimizer.step()  
  
        if epoch % 10 == 0:  
            model.eval()  
            print(f"Epoch: {epoch}, Loss: {loss:.4f}")  
  
    # evaluate the model on the test set  
    model.eval()  
    with torch.no_grad():  
        fig, ax = plt.subplots(1, 2, figsize=(16, 8))  
        out, h = model(data.x, data.edge_index)  
        pred = out.argmax(dim=1)  
  
        # get the accuracy on the unmasked test set  
        correct = (pred == data.y)  
        acc = int(correct.sum()) / int(correct.numel())  
        print(f"Test Accuracy: {acc:.4f}")  
  
        graph = to_networkx(data)  
        nx.draw_networkx(graph,  
                         pos=nx.spring_layout(graph, seed=42),  
                         node_color=pred, ax=ax[0],  
                         cmap="coolwarm",  
                         with_labels=False)  
        ax[0].set_title("Predicted Labels")  
  
        nx.draw_networkx(graph, pos=nx.spring_layout(graph, seed=42),  
                         node_color=data.y,  
                         ax=ax[1],  
                         cmap="coolwarm",  
                         with_labels=False)  
        ax[1].set_title("True Labels")  
  
    plt.show()  
  
  
if __name__ == "__main__":  
    train()
```

需要说明的是， 对于输出为 out 和 h, out 为对应的添加 Linear 分类头之后的结果，而 h 大小为 (h 相当于隐藏状态) :
$$N \times  H$$
out 大小为 34 * 4 (分类头)
$$N \times F$$
而过程中，边是需要提供的

对于上述代码， 结果如下 (下面是加  mask 之后的结果) :  
![[attachments/Pasted image 20250613165321.png|500]]



