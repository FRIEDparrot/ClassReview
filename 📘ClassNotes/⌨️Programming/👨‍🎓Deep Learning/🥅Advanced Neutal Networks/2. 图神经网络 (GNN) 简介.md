å‚è€ƒæ–‡ç«  : https://blog.csdn.net/weixin_51545953/article/details/127160151   
##  ä¸€ã€GNN åŸºæœ¬æ¦‚å¿µ
### (1) é‚»æ¥çŸ©é˜µå®šä¹‰ 
ä¾‹å¦‚ï¼Œ é™¤äº†ä¸€èˆ¬å›¾çš„[[ğŸ“˜ClassNotes/âŒ¨ï¸Programming/ğŸŒ³Data Structure & Algorithms/ã€½ï¸ Data Structure/ç¬¬ä¸ƒç«  å›¾#(1) é‚»æ¥çŸ©é˜µè¡¨ç¤ºæ–¹æ³•|é‚»æ¥çŸ©é˜µ]],  ä¹Ÿå¯ä»¥å°†é‚»æ¥çŸ©é˜µæ¨å¹¿åˆ°æ–‡æœ¬æ•°æ®, ä¾‹å¦‚ç”¨äºåˆ†æå…³è”æ€§ : 
![[Excalidraw/2. å›¾ç¥ç»ç½‘ç»œ (GNN) ç®€ä»‹ 2025-06-13 10.22.17|300]]

åŒæ—¶, GNN å¯ç”¨äºè§£ä¸åŒåŸå¸‚é“è·¯å’ŒèŠ‚ç‚¹æ•°é‡å‡ä¸å›ºå®šçš„é—®é¢˜ã€‚ 

### (2) å¸¸è§çš„ä»»åŠ¡ç±»å‹ 
å›¾ç¥ç»ç½‘ç»œä¸»è¦ä»»åŠ¡åŒ…æ‹¬ : 
1. é’ˆå¯¹èŠ‚ç‚¹æ•´åˆç‰¹å¾å‘é‡ï¼Œ è¿›è¡Œåˆ†ç±»æˆ–è€…å›å½’  
2. ä¸ºæ¯æ¡è¾¹æ•´åˆç‰¹å¾å‘é‡ï¼Œ æ ¹æ®å…¶è¾¹åšåˆ†ç±»æˆ–è€…å›å½’ 
3. ä¸ºå›¾æ•´åˆç‰¹å¾å‘é‡ï¼Œ æ ¹æ®æ­¤å¯¹å›¾åšåˆ†ç±»æˆ–è€…å›å½’ 

æ­¤å¤–ï¼Œ é™¤äº†é‚»æ¥çŸ©é˜µä»¥å¤–ï¼Œ é‚»æ¥è¡¨å’Œåå­—é“¾è¡¨å‡å¯ä»¥ç”¨äºå‡å°‘å†…å­˜ã€‚   

ä¾‹å¦‚ : 
-  é¢„æµ‹åˆ†å­ç»“æ„å›¾ï¼Œ åˆ¤æ–­æ˜¯å“ªä¸€ç±» (å›¾åˆ†ç±»é—®é¢˜)
-  é¢„æµ‹æŸä¸ªç‚¹æ˜¯å“ªä¸€ç±»  
-  é¢„æµ‹è¾¹æ˜¯å“ªä¸€ç±» 

### (3) è¾“å…¥å’Œè¾“å‡ºç‰¹æ€§
åœ¨ GNN å›¾ç¥ç»ç½‘ç»œä¸­ï¼Œ å…¶è¾“å…¥æ˜¯ç‰¹å¾ï¼Œ è¾“å‡ºä¹Ÿæ˜¯ç‰¹å¾ã€‚ è€Œ GNN æœ¬è´¨å°±æ˜¯**æ›´æ–°å›¾å„ä¸ªéƒ¨åˆ†çš„ç‰¹å¾**ã€‚è€Œæ•´ä¸ªè¿‡ç¨‹ä¸­ï¼Œ é‚»æ¥çŸ©é˜µæ˜¯ä¸å˜çš„ï¼›

ä¾‹å¦‚ï¼Œ å¯ä»¥é‡‡ç”¨**è¾“å…¥ä¸¤ä¸ªå›¾ï¼Œè¾“å‡ºä¸€ä¸ªå…³è”å›¾**çš„ä»»åŠ¡æ¡†æ¶ï¼Œ è¿™ç§æƒ…å†µå¯ä»¥ä½¿ç”¨ Encoder-Decoder GNN æ¶æ„åšå›¾ç”Ÿæˆæ¶æ„ã€‚
$encoder1 \rightarrow  h1 \qquad  encoder2 \rightarrow  h2 \rightarrow  z =f(h_{1}, h_{2})$ 

ä¹Ÿå¯ä»¥ä½¿ç”¨ **Graph Transformer** æˆ– **Graph Diffusion Models** è§£ç å™¨åšç»“æ„ç”Ÿæˆ (å¯å‚è€ƒ[GraphGPT](https://arxiv.org/abs/2301.08210))

å¸¸ç”¨çš„åº“æ˜¯ `torch_geometric` éƒ¨åˆ†. åªéœ€é‡‡ç”¨å¦‚ä¸‹éƒ¨åˆ† : 
```python fold title:å®‰è£…
pip install pyg_lib torch_scatter torch_sparse torch_cluster torch_spline_conv -f https://data.pyg.org/whl/torch-2.6.0+cu126.html
pip install torch-geometric 
```

é€šå¸¸è¾“å…¥ : 
1. å„ä¸ªèŠ‚ç‚¹çš„è¾“å…¥ç‰¹å¾ 
2. ç½‘ç»œç»“æ„å›¾
## 2. å›¾å·ç§¯ç½‘ç»œ (GCN) 
### (1)  åŸºæœ¬æ€æƒ³ 
å¯¹äº GCN, å±äº<b><mark style="background: transparent; color: orange">åŠç›‘ç£å¼å­¦ä¹ </mark></b> (semi-supervised learning),   
1. é¦–å…ˆï¼Œ è‡³å°‘éœ€è¦ä¸€ä¸ªèŠ‚ç‚¹å…·æœ‰æ ‡ç­¾ï¼Œ 
2.  **è®¡ç®— Loss æ—¶ï¼Œ ä»…è€ƒè™‘æœ‰æ ‡ç­¾çš„èŠ‚ç‚¹**
3. ä¸éœ€è¦æ‰€æœ‰èŠ‚ç‚¹éƒ½æœ‰æ ‡ç­¾  
4. ä¸€èˆ¬ GCN å±‚æ•°ä¸ä¼šå¤ªå¤šï¼Œ åœ¨ 2-3 å±‚å·¦å³;  

å¯¹äºå…·æœ‰æ ‡ç­¾çš„èŠ‚ç‚¹ï¼Œ<b><mark style="background: transparent; color: orange">å¹³å‡å…¶é‚»å±…ç‰¹å¾ä¹‹åï¼Œ ä¼ å…¥ç¥ç»ç½‘ç»œ</mark></b>ã€‚

å¯¹äºå›¾ç¥ç»ç½‘ç»œï¼Œæ¯ä¸ªèŠ‚ç‚¹å‡æœ‰ä¸€ä¸ªç‰¹å¾
![[Excalidraw/2. å›¾ç¥ç»ç½‘ç»œ (GNN) ç®€ä»‹ 2025-06-13 11.16.10|400]]
<b><mark style="background: transparent; color: orange">ç‰¹å¾çš„è®¡ç®—æ˜¯é‚»æ¥çŸ©é˜µå’Œç‰¹å¾çŸ©é˜µè¿›è¡Œä¹˜æ³•æ“ä½œæ¥èšåˆç›¸é‚»èŠ‚ç‚¹ä¿¡æ¯</mark></b> : 
$$X' = A  \cdot  X \qquad   (n \times  n)  \times  (n\times m)$$
### (2) é‚»æ¥çŸ©é˜µçš„å˜æ¢ 
é¦–å…ˆï¼Œ æˆ‘ä»¬å¯ä»¥è€ƒè™‘åœ¨é‚»æ¥çŸ©é˜µä¸­ï¼Œ åŠ ä¸Šå¯¹è§’çŸ©é˜µä¿è¯è‡ªèº«é¡¹ :  
$$\tilde{A} = A +  \lambda I_{N}$$
æ­¤æ—¶ï¼Œ å¯¹è§’çº¿å…ƒç´ éƒ¨åˆ†åœ¨ç›¸ä¹˜ä¹‹åï¼Œ å¾—åˆ°çš„æ˜¯è¡Œä¸Šéƒ¨åˆ†æ‰€æœ‰çš„æ€»åŠ å’Œ 
$$X_{i}' =  \sum_{j = 1}^{n} A_{ij} X_{j}$$
åŒæ—¶ï¼Œ å¼•å…¥<b><mark style="background: transparent; color: orange">å¸¦æœ‰è‡ªç¯çš„åº¦çŸ©é˜µ</mark></b> $\tilde{D}$  : 
$$\tilde{D}_{ii} =\sum_{j}  \tilde{A}_{jj}  = D + I$$
æ˜¾ç„¶ï¼Œå½“ä¸€ä¸ªèŠ‚ç‚¹çš„åº¦è¶Šå¤§ï¼Œå¾—åˆ°çš„ä¹˜æ³•ç»“æœåº¦ä¹Ÿç´¯åŠ æ›´å¤šï¼Œ å› æ­¤ï¼Œ æˆ‘ä»¬å¯ä»¥é‡‡ç”¨ $\tilde{D}^{-1}$ è¿›è¡Œå¹³å‡å˜æ¢åçš„çŸ©é˜µ A çš„ç»“æœ : 
$$\tilde{D}^{-1} (\tilde{A} X)$$
ä½†æ˜¯ç”±äºå·¦ä¹˜ä»…å¯¹è¡Œåšäº†å½’ä¸€åŒ–ï¼Œ ä¸ºäº†ä¿è¯èƒ½å¤Ÿå¯¹åˆ—ä¹Ÿæœ‰å½’ä¸€åŒ–ç‰¹æ€§ï¼Œ ä¸Šè¿°å¯ä»¥ä¿®æ”¹ä¸º: 
$$\boxed{\Large \hat{A} =  \tilde{D}^{-\frac{1}{2}} \tilde{A}  \tilde{D}^{-\frac{1}{2}} X}$$
è€Œ<b><mark style="background: transparent; color: orange"> softmax æ˜¯ GNN ä¸­æœ€å¸¸ç”¨çš„å½’ä¸€åŒ–å‡½æ•° </mark></b> 
$$Z = f(X, A) =  \text{softmax}(\hat{A}\space   \text{ReLU}(\hat{A} X W^{(0)}) W^{(1)} )$$
å…¶ä¸­, è®¾ X çš„é•¿åº¦ä¸º $C$ ,  $AX$  ä¸º $N \times C$ å‘é‡çŸ©é˜µ, éšè—å±‚ä¸º $H$, è¾“å‡ºå±‚ F,  åˆ™é¦–å…ˆç¬¬ä¸€å±‚è¾“å…¥ç»´åº¦ä¸º $N\times C$, åˆ™:
$$N \times  H$$
ç¬¬äºŒå±‚ä¸º $F \times H$ 

> [!summary] æ€»ç»“
> å›¾ç¥ç»ç½‘ç»œç›¸å¯¹äº CNN éƒ¨åˆ†ï¼Œ  å·ç§¯æ˜¯å·ç§¯æ ¸çš„è®¡ç®—å’Œå¹³ç§»ï¼Œ è€Œå›¾ç¥ç»ç½‘ç»œä¹Ÿæ˜¯åˆ©ç”¨é‚»æ¥ç‚¹çš„ç‰¹å¾ï¼Œ ä½†æ˜¯ä¸å¢åŠ ä»»ä½•é€šé“æ•°ã€‚ 

### (3) åˆ©ç”¨ torch.geometric æ„å»ºç½‘ç»œæ•°æ®é›† 
é¦–å…ˆï¼Œ ç‚¹çš„å®šä¹‰æ˜¯ $n \times 2$ çš„ torch å‘é‡  
è¾¹æ˜¯ $2 * m$ çš„  torch å‘é‡ï¼Œå…¶ä¸­æ¯ä¸ªæ˜¯ç›¸åº”ç‚¹çš„ä¸‹æ ‡
åˆ©ç”¨ torch_geometry.data.Data æ„å»ºå›¾æ•°æ®é›†çš„å›¾æ•°æ®éƒ¨åˆ†

> [!HINT] èŠ‚ç‚¹çš„ç‰¹å¾å‘é‡
> èŠ‚ç‚¹çš„ç‰¹å¾å‘é‡ç»´æ•°å³ä¸ºå¯¹åº”èŠ‚ç‚¹çš„åæ ‡ä½ç½®ï¼Œ ä¾‹å¦‚ä¸‹æ–¹éƒ¨åˆ†çš„ $X$ å³æ˜¯äºŒç»´çš„ã€‚å¯¹äºæ›´é«˜ç»´çš„éƒ¨åˆ†ï¼Œ å¯ä»¥å°†å¯¹åº”çš„é™„åŠ åˆ°åæ ‡ä¸Šã€‚ 
> 
> è‡³äºå¯è§†åŒ–éƒ¨åˆ†ï¼Œ ä¸€èˆ¬éœ€è¦å‰ªè£ç›¸åº”çš„ç»´åº¦éƒ¨åˆ†ï¼Œ å¹¶è¿›è¡Œ 2D å¯è§†åŒ–ã€‚ 

```python fold title:æ„å»ºå›¾ç½‘ç»œæ•°æ®çš„ç¤ºä¾‹
import torch
from torch_geometric.data import Data 

if __name__ == '__main__':
    # å®šä¹‰èŠ‚ç‚¹ç‰¹å¾å‘é‡xå’Œæ ‡ç­¾y
    x = torch.tensor([[2, 1], [5, 6], [3, 7], [12, 0]], dtype=torch.float)
    y = torch.tensor([0, 1, 0, 1], dtype=torch.float) 
	
    # å®šä¹‰è¾¹
    edge_index = torch.tensor([[0, 1, 2, 0, 3],  # èµ·å§‹ç‚¹
                               [1, 0, 1, 3, 2]], dtype=torch.long)  # ç»ˆæ­¢ç‚¹

    # å®šä¹‰train_mask
    train_mask = [(True if d is not None else False) for d in y]  # train_mask è®¾ç½®å…¨ä¸º True, å³ä¸æ·»åŠ  mask. 

    # æ„å»ºdata
    data = Data(x=x, y=y, edge_index=edge_index, train_mask=train_mask)
    print("data:", data)
    print("train_mask:", data.train_mask)
```

### (4) è®­ç»ƒæ•°æ®é›†çš„ç®€å•ç¤ºä¾‹ 
åŠ è½½ KarateClub æ•°æ®é›† : 
```python fold title:
from torch_geometric.datasets import KarateClub  
from torch_geometric.utils import to_networkx  
import networkx as nx  
import matplotlib.pyplot as plt  
  
# load the KarateClub dataset  
dataset = KarateClub()  
print("number of graphs:", len(dataset))  
print("features:", dataset.num_features)  
print("classes:", dataset.num_classes)  
  
data = dataset[0]  
  
print("nodes of first graph:", data.num_nodes)  
print("edges of first graph:", data.num_edges)  
  
print(data.num_node_features, data.num_edge_features)  
  
graph = to_networkx(data)  
  
nx.draw_networkx(graph, node_color=data.y) 
plt.show()
```

å…¶ä¸­ç¬¬ä¸€ä¸ªå…ƒç´ å³ä¸ºå¯¹åº”çš„ graph, å¦‚ä¸‹ :`Data(x=[34, 34], edge_index=[2, 156], y=[34], train_mask=[34])`, å…¶ä¸­å…±æœ‰ 34 ä¸ª node_features (ç»™å‡ºçš„åˆ†å¥½ç±»çš„èŠ‚ç‚¹æ•°é‡)

![[attachments/Pasted image 20250613155851.png|300]]
æ­¤å¤–ä¹Ÿå¯ä»¥æ›´æ”¹å…¶ä¸­çš„ Pos, æ³¨æ„ spring_layout æ˜¯<b><mark style="background: transparent; color: orange">é€šè¿‡åŠ›å¯¼å‘å¸ƒå±€ç®—æ³•ï¼Œ æ¨¡æ‹Ÿç‰©ç†äº’æ–¥åŠ›è®¡ç®—èŠ‚ç‚¹çš„ä½ç½®</mark></b>  
```python fold title:
nx.draw_networkx(graph, pos=nx.spring_layout(graph, seed=42), node_color=data.y)
```

ç»™å‡ºä¸€ä¸ªç®€å•çš„ GNN ç½‘ç»œå¦‚ä¸‹ : 
```python fold title:GNNå›¾ç¥ç»ç½‘ç»œåŸºæœ¬åˆ†ç±»ç¤ºä¾‹
from torch_geometric.datasets import KarateClub  
from torch_geometric.utils import to_networkx  
import torch  
import torch.nn as nn  
import torch_geometric.nn as gnn  
import networkx as nx  
import matplotlib.pyplot as plt  
  
dataset = KarateClub()  
data = dataset[0]  
  
  
class GCN(nn.Module):  
    def __init__(self, num_features, num_classes):  
        super(GCN, self).__init__()  
        self.num_features = num_features  
        self.num_classes = num_classes  
  
        # define the network architecture  
        self.conv1 = gnn.GCNConv(num_features, 16)  
        self.relu1 = nn.ReLU()  
        self.conv2 = gnn.GCNConv(16, 16)  
        self.relu2 = nn.ReLU()  
        self.linear = nn.Linear(16, num_classes)  
  
    def forward(self, x, edge_index):  
        h = self.conv1(x, edge_index)  
        h = self.relu1(h)  
        h = self.conv2(h, edge_index)  
        h = self.relu2(h)  
        out = self.linear(h)  
        return out, h  
  
  
def train():  
    num_features = dataset.num_features  
    num_classes = dataset.num_classes  
    model = GCN(num_features, num_classes)  
    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)  
    criterion = nn.CrossEntropyLoss()  
      
    for epoch in range(100):  
        model.train()  
        optimizer.zero_grad()  
        # since the final layer is the classifier (classify each point)  
        out, h = model(data.x, data.edge_index)  
  
        # use data.y as the train target  
        loss = criterion(out, data.y)  # use out[data.train_mask] if want to mask on train set  
        loss.backward()  
        optimizer.step()  
  
        if epoch % 10 == 0:  
            model.eval()  
            print(f"Epoch: {epoch}, Loss: {loss:.4f}")  
  
    # evaluate the model on the test set  
    model.eval()  
    with torch.no_grad():  
        fig, ax = plt.subplots(1, 2, figsize=(16, 8))  
        out, h = model(data.x, data.edge_index)  
        pred = out.argmax(dim=1)  
  
        # get the accuracy on the unmasked test set  
        correct = (pred == data.y)  
        acc = int(correct.sum()) / int(correct.numel())  
        print(f"Test Accuracy: {acc:.4f}")  
  
        graph = to_networkx(data)  
        nx.draw_networkx(graph,  
                         pos=nx.spring_layout(graph, seed=42),  
                         node_color=pred, ax=ax[0],  
                         cmap="coolwarm",  
                         with_labels=False)  
        ax[0].set_title("Predicted Labels")  
  
        nx.draw_networkx(graph, pos=nx.spring_layout(graph, seed=42),  
                         node_color=data.y,  
                         ax=ax[1],  
                         cmap="coolwarm",  
                         with_labels=False)  
        ax[1].set_title("True Labels")  
  
    plt.show()  
  
  
if __name__ == "__main__":  
    train()
```

éœ€è¦è¯´æ˜çš„æ˜¯ï¼Œ å¯¹äºè¾“å‡ºä¸º out å’Œ h, out ä¸ºå¯¹åº”çš„æ·»åŠ  Linear åˆ†ç±»å¤´ä¹‹åçš„ç»“æœï¼Œè€Œ h å¤§å°ä¸º (h ç›¸å½“äºéšè—çŠ¶æ€) :
$$N \times  H$$
out å¤§å°ä¸º 34 * 4 (åˆ†ç±»å¤´)
$$N \times F$$
è€Œè¿‡ç¨‹ä¸­ï¼Œè¾¹æ˜¯éœ€è¦æä¾›çš„

å¯¹äºä¸Šè¿°ä»£ç ï¼Œ ç»“æœå¦‚ä¸‹ (ä¸‹é¢æ˜¯åŠ   mask ä¹‹åçš„ç»“æœ) :  
![[attachments/Pasted image 20250613165321.png|500]]



