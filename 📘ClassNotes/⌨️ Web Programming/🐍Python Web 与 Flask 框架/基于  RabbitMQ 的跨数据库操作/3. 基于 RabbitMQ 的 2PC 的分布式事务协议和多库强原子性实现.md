需要说明， 使用 RabbitMQ 实现最终一致性的方式无法满足“两个事务都回滚”的需求。这是因为 RabbitMQ 是一个消息队列，它的作用是解耦和异步处理，而不是提供分布式事务的原子性保证。如果 `reviews_db` 插入失败，消息会留在队列中重试，但 `blog_db` 的事务已经提交，无法回滚。

如果你需要保证跨库的原子性（即两个数据库的事务要么同时成功，要么同时回滚），传统的单数据库事务机制无法满足需求。你需要使用分布式事务的解决方案，例如 **两阶段提交（2PC）** 或 **Saga 模式**。 

## 一、 SqlAlchemy 错误捕获原理 
### (1) 错误触发 
我们以  add 为例，  在 Sqlalchemy 中，  一般需要进行 两阶段的 Add 和 flush (), Add 不会主动抛出异常， 但是 flush 会抛出异常。 
- **`add` 的作用** : 
  - 将对象添加到会话（Session）中，标记为“待插入”状态。
  - 此时并不会立即将数据发送到数据库，而是将操作缓存在会话中。 
  - **通常不会触发错误**：`add` 只是将对象添加到会话中，不会立即检查数据库约束（如唯一性约束、数据类型等）。
  - **特殊情况**：
    - 如果启用了 SQLAlchemy 的 **`flush` 机制**（例如在查询前自动刷新），可能会触发数据库约束检查。
    - 如果==手动调用 `session.flush()`，会将挂起的操作发送到数据库，此时会触发错误==。

因此， 我们可以调用 flush 来显式触发错误 :  
1. **`flush` 的作用**:
    - `flush` 会将挂起的操作（如 `add`）发送到数据库，但不会提交事务。
    - 如果在 `flush` 后发生错误，**当前会话的事务可以回滚，但另一个会话的事务不受影响。**
2. **是否需要回滚**：
    - 如果不调用 `commit`，事务不会提交，数据库不会有任何更改。
    - 但如果在 `flush` 后发生错误，仍然需要显式调用 `rollback` 来清理会话状态。 
### (2)  roll back 回滚机制 
**1. `commit` 和 `rollback` 的作用**
- **`commit`**：
  - 提交事务，将所有挂起的操作（如 `add`、`update`、`delete`）永久保存到数据库中。
  - 如果 `commit` 成功，事务结束，数据被持久化。

- **`rollback`**：
  - 回滚事务，撤销所有未提交的操作。
  - 如果发生错误（如数据库约束冲突、网络问题等），调用 `rollback` 可以确保数据的一致性。

**2. `rollback` 的使用场景**
- **发生错误时**：
  - 如果在事务执行过程中发生错误（例如抛出异常），应该调用 `rollback` 来撤销未提交的操作。
  - 如果不调用 `rollback`，未提交的操作可能会继续占用资源，甚至导致数据库处于不一致状态。

- **`commit` 成功后**：
  - ==如果 `commit` 成功，事务已经结束，数据被持久化，此时调用 `rollback` 不会有任何效果==。
  - 换句话说，`rollback` 只对未提交的事务有效。

因此， 对于以下的双事务回滚操作 :   
```python
except Exception as e:
	session.rollback()
	session_accounts.rollback()
	if isinstance(e, ServiceException):
		raise e
	if isinstance(e, SQLAlchemyError):
		database_logger.error(f"Database error: {e}", exc_info=True)
	else:
		system_logger.error(f"Unexpected error: {e}", exc_info=True)
	raise ServiceException("Failed to accept registration request",
						   1) from e
```
采用两个 session 的方案 : <b><mark style="background: transparent; color: orange">即使加入了 flush, 也无法保证操作原子性</mark></b>。 

## 二、重要参数

在 RabbitMQ 中，`queue_declare` 和 `basic_consume` 是两个非常重要的方法，分别用于声明队列和启动消费者。以下是对这两个方法的参数详解：

---

### (1) 回调函数参数解释 
1. **`ch` (channel)**:
    - 类型: `pika.channel.Channel`
    - 含义: 这是与 RabbitMQ 服务器通信的通道对象。通过这个通道，你可以执行诸如消息确认、拒绝等操作。
2. **`method`**:
    - 类型: `pika.spec.Basic.Deliver`
    - 含义: 这个对象包含了消息的元数据，比如消息的投递标签（delivery tag）、交换机名称（exchange）、路由键（routing key）等。这些信息通常用于消息的确认或拒绝。
3. **`properties`**:
    - 类型: `pika.spec.BasicProperties`
    - 含义: 这个对象包含了消息的属性，比如消息的内容类型（content type）、内容编码（content encoding）、消息的优先级（priority）、消息的过期时间（expiration）等。
4. **`body`**:
    - 类型: `bytes`
    - 含义: 这是消息的实际内容，通常是字节类型。你需要根据消息的编码方式（如 JSON、字符串等）将其解码为可用的数据格式。 

### (2) Basic Publish 参数详解
在 RabbitMQ 中，`basic_publish` 是用于将消息发送到指定队列或交换器的方法。它的参数决定了消息如何被路由和处理。下面是对 `basic_publish` 方法的各个参数的详细解释，特别是 `exchange` 和 `routing_key` 的作用。
#### 1. `basic_publish` 方法签名
```python
basic_publish(exchange, routing_key, body, properties=None, mandatory=False)
```
#### 2. 参数详解
1. **`exchange`**:
   - **作用**: 指定消息发送到的交换器（Exchange）。交换器是 RabbitMQ 中用于接收消息并将其路由到一个或多个队列的组件。
   - **取值**:
     - `''` (空字符串): 表示使用默认交换器。默认交换器是一个特殊的交换器，它会将消息直接路由到与 `routing_key` 同名的队列。
     - `'exchange_name'`: 指定一个自定义的交换器名称。交换器需要提前在 RabbitMQ 中声明。
   - **示例**: 如果你使用 `exchange=''`，消息会被发送到默认交换器，并且 `routing_key` 必须指定目标队列的名称。

2. **`routing_key`**:
   - **作用**: 指定消息的路由键（Routing Key）。路由键用于决定消息如何被交换器路由到队列。
   - **取值**:
     - 如果使用默认交换器（`exchange=''`），`routing_key` 必须指定目标队列的名称。
     - 如果使用自定义交换器，`routing_key` 的值取决于交换器的类型（如 direct、topic、fanout 等）。
   - **示例**: 如果 `routing_key='prepare_queue'`，并且使用默认交换器，消息会被发送到名为 `prepare_queue` 的队列。

3. **`body`**:
   - **作用**: 消息的内容，通常是字节类型的数据。
   - **取值**: 可以是字符串、字节数组或任何可以被序列化的数据。
   - **示例**: 如果你发送 JSON 数据，可以使用 `json.dumps(data)` 将字典转换为 JSON 字符串。

4. **`properties`**:
   - **作用**: 可选参数，用于指定消息的属性（如消息头、优先级、持久化等）。
   - **取值**: 通常是一个 `pika.BasicProperties` 对象。
   - **示例**: 你可以设置消息的 `delivery_mode=2` 来使消息持久化，确保消息在 RabbitMQ 重启后不会丢失。

5. **`mandatory`**:
   - **作用**: 可选参数，指定如果消息无法被路由到任何队列时，是否返回消息给生产者。
   - **取值**: `True` 或 `False`。
   - **示例**: 如果设置为 `True`，并且消息无法被路由到任何队列，RabbitMQ 会通过 `basic.return` 方法将消息返回给生产者。

#### 3. 代码示例 
假设你有一个名为 `prepare_queue` 的队列，并且你希望将消息发送到这个队列。你可以这样调用 `basic_publish`：

```python
self.channel.basic_publish(
    exchange='',  # 使用默认交换器
    routing_key='prepare_queue',  # 指定目标队列名称
    body=json.dumps(data),  # 消息内容
    properties=pika.BasicProperties(
        delivery_mode=2,  # 使消息持久化
    ),
    mandatory=False  # 如果消息无法路由，不返回给生产者
)
```

- **`exchange`**: 指定消息发送到的交换器。使用 `''` 表示默认交换器。
- **`routing_key`**: 指定消息的路由键。如果使用默认交换器，`routing_key` 必须是目标队列的名称。
- **`body`**: 消息的内容，通常是序列化后的数据。
- **`properties`**: 可选参数，用于设置消息的属性（如持久化、优先级等）。
- **`mandatory`**: 可选参数，指定如果消息无法路由时是否返回给生产者。

通过合理设置这些参数，你可以控制消息如何被 RabbitMQ 路由和处理。

### (3) **`queue_declare` 方法**
`queue_declare` 用于声明一个队列。如果队列不存在，RabbitMQ 会自动创建它；如果队列已存在，则不会重复创建。

#### **方法签名**
```python
queue_declare(queue, passive=False, durable=False, exclusive=False, auto_delete=False, arguments=None)
```

#### **参数详解**
| 参数名         | 类型    | 默认值  | 说明                                                                 |
|----------------|---------|---------|----------------------------------------------------------------------|
| `queue`        | str     | `''`    | 队列名称。如果为空，RabbitMQ 会生成一个随机名称。                   |
| `passive`      | bool    | `False` | 如果为 `True`，仅检查队列是否存在，不会创建队列。                    |
| `durable`      | bool    | `False` | 如果为 `True`，队列会被持久化，即使 RabbitMQ 重启也不会丢失。        |
| `exclusive`    | bool    | `False` | 如果为 `True`，队列仅对当前连接可见，连接关闭时队列会被自动删除。   |
| `auto_delete`  | bool    | `False` | 如果为 `True`，当最后一个消费者断开连接时，队列会被自动删除。        |
| `arguments`    | dict    | `None`  | 额外的队列参数（如消息 TTL、队列长度限制等）。                       |

#### **示例**
```python
self.channel.queue_declare(
    queue="my_queue",
    durable=True,        # 队列持久化
    exclusive=False,     # 队列对所有连接可见
    auto_delete=True,    # 当最后一个消费者断开时删除队列
    arguments={
        "x-message-ttl": 60000  # 消息存活时间（60秒）
    }
)
```

---

### (4) **`basic_consume` 方法**
`basic_consume` 用于启动一个消费者，监听指定队列并处理消息。

#### **方法签名**
```python
basic_consume(queue, on_message_callback, auto_ack=False, exclusive=False, consumer_tag=None, arguments=None)
```

#### **参数详解**
| 参数名               | 类型         | 默认值  | 说明                                                                 |
|----------------------|--------------|---------|----------------------------------------------------------------------|
| `queue`              | str          | -       | 要监听的队列名称。                                                  |
| `on_message_callback`| callable     | -       | 消息处理回调函数，格式为 `callback(ch, method, properties, body)`。  |
| `auto_ack`           | bool         | `False` | 如果为 `True`，消费者会自动确认消息，无需手动调用 `basic_ack`。      |
| `exclusive`          | bool         | `False` | 如果为 `True`，队列仅允许当前消费者连接，其他消费者会被拒绝。        |
| `consumer_tag`       | str          | `None`  | 消费者标签，用于唯一标识消费者。                                     |
| `arguments`          | dict         | `None`  | 额外的消费者参数（如优先级、QoS 等）。                              |

#### **示例**
```python
def callback(ch, method, properties, body):
    print(f"Received message: {body.decode()}")
    # 手动确认消息
    ch.basic_ack(delivery_tag=method.delivery_tag)

self.channel.basic_consume(
    queue="my_queue",
    on_message_callback=callback,
    auto_ack=False,       # 手动确认消息
    exclusive=False,      # 允许多个消费者
    consumer_tag="my_consumer",
    arguments={
        "x-priority": 10  # 设置消费者优先级
    }
)
```

### 3. **参数组合使用场景**
以下是一些常见的参数组合及其使用场景：
```python
self.channel.queue_declare(queue="my_queue", durable=True)
self.channel.basic_consume(queue="my_queue", on_message_callback=self.callback, auto_ack=False)
```
#### **场景 1：持久化队列 + 手动确认消息**
- **`queue_declare`**：
  - `durable=True`：队列持久化，确保 RabbitMQ 重启后队列仍然存在。
- **`basic_consume`**：
  - `auto_ack=False`：<b><mark style="background: transparent; color: orange">手动确认消息，确保消息处理完成后再确认</mark></b>。
```python
self.channel.queue_declare(queue="my_queue", durable=True)
self.channel.basic_consume(queue="my_queue", on_message_callback=self.callback, auto_ack=False)
```
#### **场景 2：临时队列 + 自动删除**
- **`queue_declare`**：
  - `exclusive=True`：队列仅对当前连接可见。
  - `auto_delete=True`：当最后一个消费者断开时，队列自动删除。
- **`basic_consume`**：
  - `auto_ack=True`：自动确认消息，适合不需要严格消息确认的场景。

```python
self.channel.queue_declare(queue="temp_queue", exclusive=True, auto_delete=True)
self.channel.basic_consume(queue="temp_queue", on_message_callback=self.callback, auto_ack=True)
```

#### **场景 3：优先级队列 + 消费者优先级**
- **`queue_declare`**：
  - `arguments={"x-max-priority": 10}`：设置队列支持优先级消息（优先级范围为 0-10）。
- **`basic_consume`**：
  - `arguments={"x-priority": 5}`：设置消费者优先级。

```python
self.channel.queue_declare(queue="priority_queue", arguments={"x-max-priority": 10})
self.channel.basic_consume(queue="priority_queue", on_message_callback=self.callback, arguments={"x-priority": 5})
```

- **`queue_declare`**：
  - 用于声明队列，支持持久化、独占、自动删除等特性。
  - 可以通过 `arguments` 设置额外的队列参数（如消息 TTL、优先级等）。
- **`basic_consume`**：
  - 用于启动消费者，支持自动确认、独占消费者等特性。
  - 可以通过 `arguments` 设置额外的消费者参数（如优先级、QoS 等）。

通过合理组合这些参数，可以满足不同场景下的需求，如持久化队列、临时队列、优先级队列等。 

## 三、 2PC 提交模式和强一致性实现 
### (1) 总体 2PC 提交队列设计
在 RabbitMQ 中， 如果相同服务内采用同一队列 ， 而RabbitMQ本身不支持消费者级别的消息过滤， 如果不同事务共享队列， 可能导致消息被多个消费者竞争， 显然不符合需求。 

- **RabbitMQ 的消息分发机制**:  
    - RabbitMQ 默认会将队列中的消息轮询分发给所有消费者。
    - 如果多个消费者监听同一个队列，消息会被竞争消费，无法保证特定消费者只处理特定事务的消息。 

RabbitMQ 的设计是支持上千乃至万级别的队列的，因此， 一个比较好的实践是<b><mark style="background: transparent; color: orange">为每个事务种类创建单独的队列，并采用动态创建等办法，减少 RabbitMQ 负担</mark></b>。 

基本思路示例代码如下 : 
```python
from flask import Flask, request, jsonify
from sqlalchemy import create_engine, Column, Integer, String, Text
from sqlalchemy.ext.declarative import declarative_base
from sqlalchemy.orm import sessionmaker
import pika
import json
import threading

app = Flask(__name__)

# 配置数据库连接
blog_db_engine = create_engine('sqlite:///blog.db', echo=True)
reviews_db_engine = create_engine('sqlite:///reviews.db', echo=True)

# 创建基类
Base = declarative_base()

# 定义 Blog 模型
class Blog(Base):
    __tablename__ = 'blogs'
    id = Column(Integer, primary_key=True)
    title = Column(String(100))
    content = Column(Text)

# 定义 Review 模型
class Review(Base):
    __tablename__ = 'reviews'
    id = Column(Integer, primary_key=True)
    blog_id = Column(Integer)
    review_content = Column(Text)

# 创建表
Base.metadata.create_all(blog_db_engine)
Base.metadata.create_all(reviews_db_engine)

# 创建会话类
BlogSession = sessionmaker(bind=blog_db_engine)
ReviewSession = sessionmaker(bind=reviews_db_engine)

# RabbitMQ 配置
rabbitmq_connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
rabbitmq_channel = rabbitmq_connection.channel()
rabbitmq_channel.queue_declare(queue='prepare_queue')  # 准备阶段队列
rabbitmq_channel.queue_declare(queue='commit_queue')   # 提交阶段队列
rabbitmq_channel.queue_declare(queue='rollback_queue')  # 回滚阶段队列

# 提交文章的路由
@app.route('/submit_blog', methods=['POST'])
def submit_blog():
    data = request.json
    title = data.get('title')
    content = data.get('content')

    # 生成事务 ID
    transaction_id = hash(f"{title}_{content}")

    # 发送准备消息到 RabbitMQ
    prepare_message = {
        'transaction_id': transaction_id,
        'title': title,
        'content': content
    }
    rabbitmq_channel.basic_publish(
        exchange='',
        routing_key='prepare_queue',
        body=json.dumps(prepare_message)
    )
    return jsonify({'status': 'success', 'transaction_id': transaction_id})


# RabbitMQ 消费者：处理准备阶段
def consume_prepare():
    def callback(ch, method, properties, body):
        message = json.loads(body)
        transaction_id = message['transaction_id']
        title = message['title']
        content = message['content']

        # 在 blog_db 中准备事务
        blog_session = BlogSession()
        new_blog = Blog(title=title, content=content)
        blog_session.add(new_blog)
        blog_session.flush()  # 暂不提交

        # 在 reviews_db 中准备事务
        review_session = ReviewSession()
        new_review = Review(blog_id=new_blog.id, review_content=f"Initial review for blog {new_blog.id}")
        review_session.add(new_review)
        review_session.flush()  # 暂不提交

        # 返回“同意”消息
        agree_message = {
            'transaction_id': transaction_id,
            'status': 'agree'
        }
        rabbitmq_channel.basic_publish(
            exchange='',
            routing_key='commit_queue',
            body=json.dumps(agree_message)
        )

    rabbitmq_channel.basic_consume(queue='prepare_queue', on_message_callback=callback, auto_ack=True)
    rabbitmq_channel.start_consuming()

# RabbitMQ 消费者：处理提交阶段
def consume_commit():
    def callback(ch, method, properties, body):
        message = json.loads(body)
        transaction_id = message['transaction_id']
        status = message['status']
        if status == 'agree':
            # 提交 blog_db 事务
            blog_session = BlogSession()
            blog_session.commit()

            # 提交 reviews_db 事务
            review_session = ReviewSession()
            review_session.commit()

            print(f"Transaction {transaction_id} committed")
        else:
            # 回滚 blog_db 事务
            blog_session = BlogSession()
            blog_session.rollback()

            # 回滚 reviews_db 事务
            review_session = ReviewSession()
            review_session.rollback()

            print(f"Transaction {transaction_id} rolled back")

    rabbitmq_channel.basic_consume(queue='commit_queue', on_message_callback=callback, auto_ack=True)
    rabbitmq_channel.start_consuming()

if __name__ == '__main__':
    # 启动消费者线程
    prepare_thread = threading.Thread(target=consume_prepare)
    prepare_thread.daemon = True
    prepare_thread.start()

    commit_thread = threading.Thread(target=consume_commit)
    commit_thread.daemon = True
    commit_thread.start()

    # 启动 Flask 应用
    app.run(debug=True)
```


###  (2) 基于动态队列 + 消费者绑定的 2PC 实现方案
**每个事务中的每次提交都会生成一个独立的 UUID，并且这些 UUID 是短暂的（事务结束后清除队列）**。这种情况下，如果为每个 UUID 创建一组队列，可能会导致以下问题：

1. **队列数量爆炸**：
   - 每次提交都会生成一个新的 UUID，导致队列数量快速增加。
   - 即使事务结束后清除队列，高并发场景下仍然可能产生大量队列。

2. **队列竞争**：
   - 如果多个事务共享同一组队列（如 `prepare`、`commit`、`rollback`），RabbitMQ 会将消息分发给不同的消费者，导致消息被竞争消费。
   - 这与 2PC 的需求（每个事务的消息必须由特定消费者处理）相冲突。

为了既能 **减少队列数量**，又能 **避免消息竞争** 的方案，设计如下 ： 

**动态队列 + 消费者绑定**
- **核心思想**：
  - 为每个事务动态创建独立的队列（如 `txn_<uuid>_prepare`、`txn_<uuid>_commit`、`txn_<uuid>_rollback`）。
  - 消费者在事务开始时绑定到对应的队列，事务结束后解绑并删除队列。
- **优点**：
  - 完全隔离消息，避免竞争消费。
  - 队列数量动态调整，资源利用率高。
- **缺点**：
  - 实现复杂，需要动态管理队列和消费者绑定关系。

#### **实现步骤**
1. **事务开始时**：
   - 生成一个唯一的 UUID。
   - 动态创建队列（如 `txn_<uuid>_prepare`、`txn_<uuid>_commit`、`txn_<uuid>_rollback`）。
   - 消费者绑定到这些队列。

2. **事务进行中**：
   - 生产者将消息发送到对应的队列。
   - 消费者从队列中接收消息并处理。

3. **事务结束时**：
   - 消费者解绑队列。
   - 删除队列以释放资源。

#### **代码示例**
```python
import pika
import uuid

def create_transaction_queue(queue_name):
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
    channel = connection.channel()
    channel.queue_declare(queue=queue_name)
    connection.close()
    print(f"Created queue: {queue_name}")

def delete_transaction_queue(queue_name):
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
    channel = connection.channel()
    channel.queue_delete(queue=queue_name)
    connection.close()
    print(f"Deleted queue: {queue_name}")

def consume_transaction_messages(queue_name):
    connection = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
    channel = connection.channel()

    def on_message(ch, method, properties, body):
        print(f"Received message from {queue_name}: {body.decode()}")
        # 处理消息逻辑
        if body.decode() == "prepare":
            print("Processing prepare...")
        elif body.decode() == "commit":
            print("Processing commit...")
        elif body.decode() == "rollback":
            print("Processing rollback...")

    channel.basic_consume(queue=queue_name, on_message_callback=on_message, auto_ack=True)
    print(f"Consumer for {queue_name} is waiting for messages...")
    channel.start_consuming()

# 示例：事务生命周期
transaction_uuid = str(uuid.uuid4())
prepare_queue = f"txn_{transaction_uuid}_prepare"
commit_queue = f"txn_{transaction_uuid}_commit"
rollback_queue = f"txn_{transaction_uuid}_rollback"

# 事务开始
create_transaction_queue(prepare_queue)
create_transaction_queue(commit_queue)
create_transaction_queue(rollback_queue)

# 消费者绑定队列（假设使用多线程或异步处理）
consume_transaction_messages(prepare_queue)
consume_transaction_messages(commit_queue)
consume_transaction_messages(rollback_queue)

# 事务结束
delete_transaction_queue(prepare_queue)
delete_transaction_queue(commit_queue)
delete_transaction_queue(rollback_queue)
```

### (3) 基于线程连接池的 RabbitMQ 结构设计
首先， 按照上述方法，对于每个 2PC 连接对象， 首先需要一个连接参数 conn,  但是,  对于小型应用能否共享 conn 直接为一个全局的 rabbitMQconn 对象，仍然是存在顾虑的 : 
#### 1. 线程安全性分析
虽然 RabbitMQ 的通道 (`channel`) 是线程隔离的（每个通道的操作是独立的），但 `pika.BlockingConnection` 的连接对象 (`conn`) 本身**不是线程安全的**。

**共享连接  +  独立线程通道**是不安全的， 例如两个线程同时调用 : 
```python
# 线程1和线程2同时执行以下代码
channel = rabbit_conn.channel()  # 共享全局 rabbit_conn
```
**可能导致多个线程同时修改连接对象的内部状态，导致协议解析错误或缓冲区损坏**。 由于状态混乱，连接可能会意外断开

**为什么共享连接 + 独立通道不安全？**
- **底层实现原因**：  
    `pika.BlockingConnection` **是基于同步阻塞 I/O 的实现**，其内部状态（如协议帧解析、缓冲区管理）在多个线程同时调用时无法保证原子性。
- **协议限制**：  
    AMQP 协议要求<b><mark style="background: transparent; color: orange">连接和通道的创建是顺序的，多个线程同时创建通道会破坏协议的顺序性</mark></b>。

解决上述问题的方法一是使用线程锁 (`threading.Lock`) 确保同一时间只有一个线程可以创建通道。 
```python
import threading

# 全局连接和锁
rabbit_conn = pika.BlockingConnection(pika.ConnectionParameters('localhost'))
channel_lock = threading.Lock()
# 接下来使用 threading 创建的部分就是安全的， 但是在高并发下往往会产生问题
```

#### 2. 基于线程池分配的解决方案  
因为 RabbitMQ 的 TCP 连接是很昂贵的操作,    为了平衡并发性和性能开销， 可以使用连接池管理多个连接，按需分配连接给线程; 

```python
class RabbitMQConnPool:  
    def __init__(self, max_conn=10):  
        self.max_conn = max_conn  
        self.pool = Queue(maxsize=max_conn)  
        for i in range(max_conn):  
            conn = pika.BlockingConnection(  
                pika.ConnectionParameters('localhost')  # RabbitMQ server IP address  
            )  
            self.pool.put(conn)  
  
    def get_conn(self):  
        if self.pool.empty():  
            system_logger.warn("Connection pool is empty. Connection limit reached.")  
            raise RuntimeError("Connection pool is empty. No connections available.")  
        return self.pool.get()  
  
    def release_conn(self, conn):  
        self.pool.put(conn)
```

使用一个 ， 每次服务,  需要创建一个 transaction 对象， 多个客户端，每次创建的 transaction 对象不同, 实际上也是使用不同连接池的，因此不会产生并发问题 

### (3) 线程锁机制说明
但是考虑到 channel 线程不安全时会发生不可预料操作，  因此仍然可以考虑用 `channel_lock` 进行一个兜底操作， 即使多个客户端同时创建 `transaction` 对象，也能保证 `channel` 的创建是线程安全的。 同时靠连接池的方法， 以应对高并发的机制。 

需要说明, ==如果后续有其他操作（如 `prepare`、`commit`、`rollback`）需要访问 `self.channel`，也需要加锁==。例如: 
```python
 with self.channel_lock: 
	  self.channel.basic_publish(
            exchange='',
            routing_key=self.queue,
            body=data_str,
            properties=pika.BasicProperties(
                delivery_mode=TwoPC_DELIVERY_MODE,
                headers={
                    '__type__': Base2PCStatus.PREPARE.value,
                }
            ),
            mandatory=True,
        )
```

基于 Threading.Lock 的超时机制设置 : 
由于是多线程运行环境，我们在进行线程锁时， 为了应对高并发场景， 应当进行锁的超时机制设置。 我们可以使用 `threading.semaphore` 实现超时锁， 可自定义一个类型如下: 
```python
class TimeoutLock:  
    def __init__(self):  
        # only 1 thread can acquire the lock at a time.  
        self._semaphore = threading.Semaphore(1)  
  
    def acquire(self, timeout=None):  
        if not self._semaphore.acquire(timeout=timeout):  
            raise TimeoutError("Failed to acquire lock")  
        return True  
  
    def release(self):  
        self._semaphore.release()
```

**使用和获取非阻塞锁** 
一般除了超时锁， 用的更加广泛的还有非阻塞锁, 同时为了能够在 with 中使用， 我们一般定义 `__enter__` 和 `__exit__`  方法进行获取。 

但是由于我们在关闭时可能也需要加锁， 而显然无法获取会立即错误， 不符合需求， 那么实际可能不需要锁的操作。 

### (4) 异步编程和 Prepare 结果的非阻塞等待 
Python 提供了 `asyncio` 库来支持异步操作， 对于消息队列，我们可以使用 asyncio 以实现<b><mark style="background: transparent; color: orange">非阻塞式地等待操作</mark></b>。 参考[[📘ClassNotes/⌨️Programming/🐍Python/⛳Python 进阶与软件架构设计相关/8. Python 异步编程,   asyncio 库与 async, await 语法|Python 异步编程,   asyncio 库与 async, await 语法]]  

需要说明: 在 flask 框架中, `await` 不会阻塞其他客户端的操作，因为 `asyncio` 是**基于事件循环的异步框架**，每个客户端都有自己的协程上下文。只要事件循环没有被阻塞，多个客户端可以并发执行。 

基本的新语法为 : 
```python
import asyncio
async def prepare(self, data: dict) -> None: 
```


ayncio.run