## 一、 大数定律
`````ad-cite 
title: 概率收敛的定义与性质
collapse: open
设$f_A$是$n$次<mark style="background: transparent; color: red">独立重复试验</mark>中事件$A$发生的次数， 而$p$是事件$A$在每次实验中发生的概率，则对于任意的正数$\varepsilon > 0$均有:
$$\lim_{n \rightarrow \infty} \left\{|Y_{n} - a| < \varepsilon \right\}  = 1$$
则称$Y_{n}$依概率收敛于$a$, 并记为$Y_{n}\overset{P}{\rightarrow} a$, 并有以下的性质: 
我们设$X_{n}\overset{P}{\rightarrow} a, Y_{n}\overset{P}{\rightarrow } b$, 则有$g(X_{n},Y_{n}) \overset{P}{\rightarrow} g(a,b)$
`````
### (1) 辛钦大数定理
大数定律证明参考[[📘ClassNotes/📐Mathmatics/🎣Probability Theory/补充部分/大数定律证明.pdf|大数定律证明.pdf]] 
**辛钦大数定律**: 设$X_{1},  X_{2},\dots X_{n}$<mark style="background: transparent; color: red">是相互独立，服从统一分布的随机变量序列</mark>, 且**具有数学期望**$E(X_{k}) = \mu$(其中$k = 1,2 \dots$) 是前 $n$个变量的算数平均$\frac{1}{n}\sum^{n}_{k=1}X_{k}$,则对于任意的$\varepsilon> 0$ 均有: 
$$\small \lim_{n\rightarrow  + \infty} P\left\{\left|\frac{1}{n}\sum^{n}_{k=1} X_{k} - \mu \right| < \varepsilon \right\} = 1$$
即$X_1, X_2,\dots  X_{n}$的均值<mark style="background: transparent; color: red">依概率收敛于</mark>$\mu$ 
$$\Large \boxed{\frac{1}{n}\sum^{n}_{k=1} X_{k} \overset{P}{\longrightarrow}  \mu}$$
### (2) 伯努利大数定律
**伯努利大数定律**: 设$f_{A}$是$n$次<mark style="background: transparent; color: red">独立重复试验(伯努利实验)</mark>中$A$发生的次数，而$p$是事件$A$在每次实验中发生的概率， 则对于任意的正数$\varepsilon > 0$, 均有: 
$$\lim_{n\rightarrow \infty} \left\{ \left|\frac{f_{A}}{n}  -p \right| < \varepsilon \right\} = 1\quad \text{or} \quad  \lim_{n \rightarrow \infty} \left\{\left| \frac{f_{A}}{n} - p \right|\geq \varepsilon \right\} = 0$$
即有事件发生的频率依概率收敛于其概率
$$\frac{f_{A}}{n} \overset{P}{\longrightarrow} p $$
伯努利大数定律的意义是，当实验次数很大时， 可以<mark style="background: transparent; color: red">使用事件的频率代替事件的概率</mark>

## 二、中心极限定理
### (1) 独立同分布的中心极限定理
定理一(<mark style="background: transparent; color: red">独立同分布的中心极限定理</mark>) 设随机变量 $X_{1}, X_{2},\dots X_{n}$相互独立且服从同一分布，且具有数学期望和方差$E(X_{k}) = \mu, D(X_{k}) = \sigma^{2}>0$, 则有随机变量之和$\sum^{n}_{k=1} X_{k}$的标准化变量: 
$$Y_{n} = \frac{\sum^{n}_{k=1}X_{k}  - E(\sum^{n}_{k=1} X_{k})}{\sqrt{D \left(\sum^{n}_{k=1} X_{k}\right)}} = \frac{\sum^{n}_{k=1} X_{k}-  n \mu}{\sqrt{n}\sigma}$$
的<mark style="background: transparent; color: red">分布函数</mark>$F_{n}(x)$对于任意$X$满足:
$$\Large\boxed{\lim_{n \rightarrow \infty} F_{n} (x) = \lim_{n \rightarrow \infty} P\left\{Y_{n} \leq  x\right\} = \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-\frac{t^{2}}{2}} dt = \Phi(x)}$$
`````ad-note
title: 物理意义
collapse: open
对于均值为$\mu$, 方差为$\sigma^{2} >0$的独立同分布的随机变量$X_{1}, X_{2},  \dots X_{n}$之和$\sum^{n}_{k=1} X_{k}$的标准化变量，当$n$充分大时服从于均值$\mu$, 方差$\sigma^2/n$的正态分布
$$\boxed{ \frac{\overline{X} - \mu }{\sigma / \sqrt{n}}\sim N(0,1) \qquad   \overline{X} \sim N(\mu, \frac{\sigma^{2}}{n})}$$
这一结果是数理统计中，大样本统计推断的基础。
`````
### (2) 李亚普诺夫定理
定理二(**李雅普诺夫Lyapunov定理**) 设随机变量 $X_{1}, X_{2},\dots X_{n}$相互独立，且具有数学期望和方差$E(X_{k}) = \mu_{k}, D(X_{k}) = \sigma^{2}_{k}>0, k = 1,2 \dots$, 此时，我们记$B_{n}^{2} = \sum^{n}_{k=1} \mu_{k}$, 此时如果存在正数$\delta$, 使得当$n\rightarrow \infty$时, 有: 
$$\Large\boxed {\frac{1}{B_{n}^{2 + \delta}} \sum^{n}_{k=1} E\left\{\left|X_{k} - \mu_{k} \right|^{2 + \delta}\right\} = 0}$$
此时<mark style="background: transparent; color: red">随机变量之和的标准化变量</mark>$\sum^{n}_{k=1} x_{k}$满足(其中由定律$D\left(\sum^{n}_{k=1} X_{k}\right)  = \sum^{n}_{k=1} D(X_{k})$ ):
$$Z_{n} = \frac{\sum^{n}_{k=1}  X_{k} - E \left(\sum^{n}_{k=1}  X_{k}\right) }{\sqrt{D\left(\sum^{n}_{k=1} X_{k}\right)}}= \frac{\sum^{n}_{k=1}  X_{k} - \sum^{n}_{k=1} \mu_{k}}{B_{n}}$$
该变量$Z_{n}$的分布函数满足:
$$\Large\boxed{\lim_{n \rightarrow \infty} F_{n}(x) = \lim_{n \rightarrow \infty} P\left\{Z_{n} \leq  x\right\} = \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi}} e^{-\frac{t^{2}}{2}} dt = \Phi(x)}$$
`````ad-note
title: 物理意义
collapse: open
在很多问题中, 考虑的随机变量可以表示成很多个独立的随机变量之和。且其测量误差是由这些随机变量的误差合成的。则如果样本空间足够大， 则其往往近似服从正态分布
`````
### (3) 棣莫弗-拉普拉斯定理
设随机变量$\eta_{n}$服从参数为$n, p$的二项分布，则对于任意的$x$，均有:
$$\lim_{n \rightarrow \infty} P\left\{ \frac{\eta_{n} - np}{\sqrt{np (1- p)}}\leq x\right\} = \int_{-\infty}^{x} \frac{1}{\sqrt{2 \pi} } e^{- \frac{t^{2}}{2}} dt = \Phi(x)$$
这个通过独立同分布的中心极限定理和$\eta_{n} = \sum^{n}_{k=1} X_{k}$很容易证明。

`````ad-note
title: 物理意义
collapse: open
正态分布是二项分布的极限分布, 且独立重复实验(伯努利实现)所出现结果的分布为二项分布
`````

