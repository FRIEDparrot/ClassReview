## 一、随机变量的数学期望
### (1) 数学期望的定义
对于随机变量, 有<mark style="background: transparent; color: red">数学期望, 方差, 相关系数和矩</mark>等数字特征。
我们以一个射击标靶的实例为例: 我们分别以射入区域$e_{0}, e_{1}, e_{2}$的概率为$X$的分布律。
![[Excalidraw/第四章 随机变量的数字特征 2023-09-23 19.14.24|400]]
我们设$X$的**分布律**为: 
$$P\{X= k\} = p_{k}\qquad k = 0, 1, 2 \dots $$
射击$N$次，其中**得$0$分的有$a_0$次, 得1分的有$a_1$次, 得2分的有$a_{2}$次**, 显然有$a_{0} + a_{1} + a_{2} = N$, 总分为随机变量$X$, 我们取<u>平均射击一次的得分</u>为随机变量$X$的**数学期望**: 
$$X = \frac{a_{0} \times 0 + a_{1}\times 1 + a_{2}\times 2}{N} = \sum^{2}_{k=0}k \frac{a_{k}}{N}$$
其中$\frac{a_{k}}{N}$是事件$\{X = k\}$发生的**频率**, 而当$N$很大时, $\frac{a_{k}}{N}$在一定意义下, 接近于事件的频率$p_{k}$, 过程中在试验次数很大时，随机变量$X$的数学期望或者均值， 并有如下的定义: 

1) (<mark style="background: transparent; color: blue">离散型随机变量的数学期望</mark>) 设**某个离散型随机变量**的分布律为: $P\{ X = x_k\} = P_{k}\qquad k =1,2 \dots$ 此时, 如果级数: 
$$\boxed{E(x) = \sum^{\infty}_{k=1} x_{k} p_{k}}$$
绝对收敛, 则称$E(x)$为<mark style="background: transparent; color: red">随机变量的数学期望</mark>。数学期望简称**期望**，又称为**均值**。

2) (<mark style="background: transparent; color: blue">连续型随机变量的数学期望</mark>) 设某个**连续型随机变量**的分布律为$f(x)$, 则其**数学期望**为: 
$$E(X) = \int_{-\infty}^{\infty} x f(x) dx$$

`````ad-note
title: 数学期望的性质
collapse: open
1. 设$C$是常数，则$E(C) = C$ 
2. 设$X$是一个随机变量, $C$是常数, 则有: 
$$E(CX) = CE(X)$$
3. 设$X,Y$是两个随机变量, 则有: 
$$E(X + Y) = E(X) + E(Y)$$
4. 设$X,Y$是相互独立的随机变量, 则有: 
$$E(XY) = E(X) E(Y)$$
`````

### (2) 常见分布与变量函数的数学期望 
参考[[📘ClassNotes/📐Mathmatics/🎣Probability Theory/补充部分/常见分布与变量函数的数学期望.pdf|常见分布与变量函数的数学期望.pdf]], 有: 
对于参数为$\lambda$的[[📘ClassNotes/📐Mathmatics/🎣Probability Theory/第二章 随机变量及其分布#3. 泊松分布|泊松分布]], $X\sim \pi(\lambda)$, 数学期望为$\lambda$ 
对于平均分布, 数学期望为$\frac{a + b}{2}$

**定理**(<mark style="background: transparent; color: red">变量函数的数学期望</mark>): 
1. 如果$X$是离散型随机变量, 分布律为$P(X = x_{k}) = p_{k}, k=1,2 \dots$, 此时, 若有<mark style="background: transparent; color: red">(前提是右侧绝对收敛)</mark>
$$\Large\boxed {E(Y) = E[g(x)] = \sum^{\infty}_{k=1} g(x_{k}) p_{k}}$$
2. 如果$X$是连续型随机变量, 概率密度为$f(x)$, 则有<mark style="background: transparent; color: red">(前提是右侧绝对收敛)</mark>
$$\Large \boxed{E(Y) = E[g(X)] = \int_{- \infty }^{ + \infty }  g(x) f(x) dx}$$
3. 对于**二维随机变量, 有离散型和连续型的概率密度公式<mark style="background: transparent; color: red">(前提是右侧绝对收敛)</mark>**:
$$\boxed{E(Z) = \sum^{\infty}_{j=1} \sum^{\infty}_{i=1} g(x_{i}, y_{i}) p_{ij} \qquad  E(Z) = E[g(X,Y)] = \int_{-\infty}^{+ \infty} \int_{-\infty}^{+ \infty} g(x,y)f(x,y) dx dy}$$

## 二、方差

定义: 设$X$是一个随机变量， 若$E\{[X - E(x)]^{2}\}$存在, 则称$E\{[X - E(X)]^{2}\}$为$X$的<b><mark style="background: transparent; color: blue">方差</mark></b>, 并记为$D(X)$或者$\text{Var}(X)$,有:
$$D(x) = E\{[X - E(X)]^{2}\}$$
在应用上，引入量$\sigma(X) = \sqrt{D(X)}$, 称为<u>标准差</u>或者<u>均方差</u>

随机变量$X$的方差可以通过下面的公式计算:
$$\Large \boxed{D(X) = E(X^{2}) - [E(X)]^{2}}$$

方差的性质如下:
1. 设$C$是常数， 则D(C) = 0 
2. 设$X$是随机变量, 而$C$是常数, 则有
3. 设$X,Y$是两个随机变量, 则: 
$$D(X + Y) = D(X) + D(Y) + 2E\{ (X - E(X)) (Y - E(Y))\}$$
当X,Y相互独立时， 有:$D(X + Y) = D(X) + D(Y)$
4. $D(X) = 0$的充要条件是$X$以概率1取常数$E(X)$, 即有
$$P\{ X = E(X) \} = 1$$

**定理(切比雪夫不等式)**: 设随机变量$X$具有数学期望$E(X) = \mu$, 方差$D(X) = \sigma^2$, 则对于任意的正数$\varepsilon$, 不等式
$$P \{|X - \mu| \geq  \varepsilon\} \leq \frac{\sigma^{2}}{\varepsilon^{2}}$$
成立
`````ad-todo
title: 推导
collapse: open
`````

## 三、协方差及其相关系数
如果两个随机变量$X$和$Y$是相互独立的, 则:
$$E\{[X - E(x)] [Y - E(Y)] \} = 0$$
此时，若$E \{[X- E(X)][Y -E(Y)]\}\neq 0$, $X,Y$不相独立, 而是存在一定的关系。

**定义** 量$E\{[X - E(X)][Y - E(Y)]\}$ 称为随机变量$X$与$Y$的<mark style="background: transparent; color: red">协方差</mark>，并记为$\text{Cov}(X, Y)$, 即有:
$$\Large \text{Cov} (X, Y) = E\{[X - E(X)][Y - E(Y)]\}$$
$$\rho_{XY} = \frac{\text{Cov}(X,Y)}{\sqrt{D}(X), \sqrt{D}(Y)}$$
称为随机变量$X$与$Y$的<mark style="background: transparent; color: red">相关系数</mark>。我们常常使用下列的定义式展开计算协方差 : 
$$\Large \boxed{\text{Cov}(X,Y) = E(X,Y) - E(X) E(Y)}$$

协方差的**性质**:
1. $\text{Cov}(aX, bY) = ab \text{Cov} (X,Y)\qquad a, b = \text{const}$
2. $\text{Cov}(X_{1}+ X_{2} , Y) = \text{Cov}(X_{1}, Y) + \text{Cov}(X_{2}, Y)$
3. $\text{Cov}(X,Y) = \text{Cov}(Y,X)\qquad \text{Cov}(X,X) = D(X)$

而相关系数$\rho_{XY}$也有下列重要性质 :
1. $|\rho_{XY} |\leq 1$
2. $|\rho_{XY}| = 1$的充要条件是, 存在常数$a,b$使得
$$P\{ Y = a +b X \} = 1$$
其中， $\rho_{XY}$描述相关程度, 而$\rho_{XY} =0$时，称$X,Y$不相关

## 四、矩和协方差矩阵
### (1) 矩的概念
定义: 设$X, Y$为随机变量，若有:
$$E\{[X - E(X)]^{k}\}\qquad   k = 1,2 \dots$$
存在， 则称其为$X$的$k$阶<b><mark style="background: transparent; color: blue">中心矩</mark></b>
$$E(X^{k}) \qquad k = 1, 2 \dots $$
称为X的$k$阶<b><mark style="background: transparent; color: blue">原点矩</mark></b>, **原点矩简称$k$阶矩**

而对于
$$E(X^{k} Y^{l})$$
存在， 则称为X$,Y$的$k + l$阶<mark style="background: transparent; color: red">混合矩</mark>. 相应地，定义
$$E\{[X - E(X)]^{k} [Y - E(Y)]^{l} \}$$
为$X,Y$的$k+ l$阶<mark style="background: transparent; color: red">混合中心矩</mark>

`````ad-note
对于随机变量$X$,其数学期望是其一阶原点矩，而方差$D(X)$是$X$的二阶中心矩
协方差为$X,Y$的二阶混合中心矩
`````
### (2) 协方差矩阵
协方差矩阵的概念: 取变量的混合中心矩
$$c_{11} = E\{[X_{1} - E(X_{1}) ]^{2}\}\qquad c_{12} = E\{[X_{1} - E(X_{1}) ] [X_{2}- E(X_{2})]\}$$
$$c_{21} = E\{[X_{2} - E(X_{2}) [X_{1} - E(X_{1})]] \}\qquad c_{22} = E\{[X_{2} - E(X_{2}) ]^{2}\}$$
并将其组装称$n$维随机变量的<mark style="background: transparent; color: red">协方差矩阵</mark>， 即
$$\left(\begin{matrix}
c_{11} & c_{12}  \\  c_{21} & c_{22}
\end{matrix} \right)$$
称为随机变量$(X_1, X_2)$的**协方差矩阵**
设$n$维随机变量$(X_1, X_2, \dots X_n)$的**二阶混合中心矩**$c_{ij} = \text{Cov}(X_{i}, X_{j}) = E\{[X_{i} - E(X_{i})] [X_{j} - E(X_{j})]\}$其中$i,j = 1,2\dots n$, 则称矩阵 
$$\left[ \begin{matrix}
c_{11} & c_{12} & ... & c_{1n} \\
c_{21} & c_{22} & ... & c_{2n} \\
...  &&& ...\\
c_{n1} & c_{n2} & ... & c_{nn}
\end{matrix}\right]$$
为$n$维随机变量的<b><mark style="background: transparent; color: blue">协方差矩阵</mark></b>

### (3) n维正态随机变量的概率密度
首先， 对于二维正态随机变量的概率密度， 我们有: 
$$f(x_{1},x_{2}) = \frac{1}{2\pi \sigma_{1}\sigma_{2} \sqrt{1 - \rho^{2}}} \exp\left\{ \frac{-1}{2(1- \rho^{2})} \left[ \frac{(x_{1} - \mu_{1})^{2}}{\sigma_{1}^{2}} - 2 \rho \frac{(x - \mu_{1}) (x - \mu_{2})}{\sigma_{1} \sigma_{2}} + \frac{(x_{2} - \mu_{2})^{2}}{\sigma_{2}^{2}}\right]\right\}$$
为了将其改写成矩阵的形式, 引入
$$X = \left(\begin{matrix}
x_{1}  \\ x_{2}
\end{matrix} \right) \qquad \mu = \left( \begin{matrix}
\mu_{1} \\  \mu_{2} 
\end{matrix}\right)$$
则$X_1, X_2$的协方差矩阵为:
$$C = \left[\begin{matrix}
\sigma_{1}^{2} & \rho \sigma_{1}\sigma_{2} \\ \rho \sigma_{1}\sigma_{2} & \sigma_{2}^{2}
\end{matrix}\right]$$
而经过
`````ad-todo
title: 推导
collapse: open
`````
得到$(X_1, X_2)$的概率密度为: 
$$f(x_{1},x_{2}) = \frac{1}{(2 \pi)^{\frac{2}{2}} (\det C)^{\frac{1}{2}}} \exp \left\{ - \frac{1}{2} (X - \mu)^{T} C^{-1} (X - \mu)\right\}$$
上式推广到 n维正态随机变量$(X_1,X_2, \dots X_n)$情况时，有: 取
$$X = \left[\begin{matrix}
x_{1} , x_{2} \dots  x_{n}
\end{matrix}\right]^{T} \qquad \mu = \left[\begin{matrix}
\mu_{1}, \mu_{2} \dots \mu_{n}
\end{matrix}\right]^{T}$$
则$n$维正态随机变量的概率密度定义为:
$$f(x_{1}, x_{2},\dots  x_{n})  = \frac{1}{(2 \pi)^{\frac{n}{2}} (\det C )^{\frac{1}{2}}} \exp \left\{-\frac{1}{2} (X - \mu )^{T} C^{-1} (X- \mu)\right\}$$
`````ad-note
title: $n$维随机变量的性质
collapse: open
1. $n$维正态随机变量$X$的每一个分量$X_{i}$都是正态随机变量，反之，若有$X_{1}, X_{2}, \dots X_{n}$<mark style="background: transparent; color: red">均为正态随机变量且相互独立</mark>，则$(X_1, X_2, \dots X_n)$是正态随机变量
2. $n$维随机变量服从$n$维正分布的==充要条件==是$X_1, X_2, \dots  , X_n$的任意的线性组合: $$X_{1}l_{1} + X_{2}l _{2} + \dots  X_{n}l_{n}$$服从一维正态分布
3. 若$X_{1}, X_{2} \dots X_{n}$服从$n$维正态随机分布，而$Y_{1}\dots Y_{n}$为其线性函数，则$(Y_{1}, Y_{2}, \dots  Y_{k})$也服从多维正态分布。(称为**正态分布量的线性不变性**)
4. 设$(X_{1},X_{2}\dots X_{n})$服从n为正态分布， 则其"相互独立"与"两两不相关"是等价的
`````



