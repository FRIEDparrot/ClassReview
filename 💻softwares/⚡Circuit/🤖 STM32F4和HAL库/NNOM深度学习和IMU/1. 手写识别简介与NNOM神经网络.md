## 一、认识 NNOM 与配置
对于嵌入式深度学习和运行神经网络部分, 可以参考 [卷积神经网络魔杖识别](https://github.com/lyg09270/CyberryPotter_ElectromagicWand_Basic_Project) 以及 [nnom嵌入式机器学习库](https://github.com/majianjia/nnom) 的部分。

对于 python, 上述机器学习库需要创建 python3.11 的虚拟环境, 只需cd到对应的目录, 然后创建3.11虚拟环境:
```python
python -m venv E:\PythonVenv\.venv    # 其中.venv 代表虚拟环境文件夹
# 一般只需要在当前文件夹下创建就好
# 注意: 这个必须使用 3.11 进行创建, 否则将默认采用3.12 创建
```
使用如下进行激活虚拟环境:
```c
.venv\Scripts\activate
```
取消激活
```python
deactivate
```

一般pycharm 在创建工程指定编译器之后，就会自动创建虚拟环境了;

首先在 pycharm 中设置 interpreter 的环境, <mark style="background: transparent; color: red">需要注意,如果是将 Base interpreter 设置为Python311 文件夹下, 则安装的 site-packages 是在3.11 根目录下的, 如果设置在本工程的python, 则安装在本工程下方;</mark>
![[attachments/Pasted image 20240805111322.png]]

此时使用pycharm 打开并切换编译器到3.11, 对应工程虚拟环境下的 python 环境是 python 3.11.9 
![[attachments/Pasted image 20240805110501.png]]
在下面命令行激活环境
```c
venv\scripts\activate
# 使用 python --version 检查版本
```

如果在此激活环境下执行, 则附加包会全部安装到这个虚拟环境中, 和其他项目环境独立:
```python
pip install git+https://github.com/majianjia/nnom@master
pip install 'tensorflow-cpu<=2.14.1'
```
![[attachments/Pasted image 20240805111828.png]]
即可添加 tensorflow 到此工程中; 原始工程已经在 workpack 中有了;

对于移动之后， 需要修改 activate 中的虚拟环境路径: VIRTUAL_ENV='E:\workpack\MCU_NNOM\venv'
(需要修改 activate 以及 activate.bat 文件)


## 二、提供的手写识别库
提供手写识别库的原理是特征提取(512维) > LDA线性判决分析法降维(64维) > 平均值计算得到类别样本的模板;

提供支持数字, 大小写字母的识别支持; 可以通过如下的几个进行获取 : 
![[attachments/Pasted image 20240805113928.png]]

要求 52kb Flash 和 6kb RAM;

使用办法如下:
①调用alientek_ncr_init函数，初始化识别程序
     该函数用来初始化识别器，在手写识别进行之前，必须调用该函数
②  获取输入的点阵数据
      通过触摸屏获取输入轨迹点阵坐标，并存放到缓存区里，注意至少输入2个不同坐标的点
      阵数据，才能正常识别。输入点数越多，需要内存越大，推荐输入点数范围：100~200点
③ 调用alientek_ncr函数,得到识别结果
     通过调用alientek_ncr函数，得到输入点阵的识别结果，结果将保存在result参数里面，
     采用ASCII码格式存储
④调用alientek_ncr_stop函数，终止识别
    调用alientek_ncr_stop函数，可停止识别。如果还需要继续识别，重复步骤②和步骤③
