## 一、NNOM 环境配置
### (1) python 环境
注意nnom 仅支持3.11, 如果使用3.12安装需要先卸载。其中虚拟环境均在  MCU_NNOM 文件夹下
```c
.venv\Scripts\activate
```

使用如下代码检测
```c
import tensorflow  
import nnom_core  
import keras  
  
print(nnom_core.__path__[0])  
print(keras.__version__)
```

NNOM 与 **Keras** 相近, 可以参考 https://keras.io/ 部分; 同时 nnom 可以采用 kera 2.14 进行联合工作;
Keras 可以以 jax, tensorflow 或者 pytorch 中的任一作为框架运行; 
另外也安装了 keras-cv , 但没有安装 keras-nlp  `TF_ENABLE_ONEDNN_OPTS=0` 可以通过代码实现, 即先import os 之后定义变量特性: 
```c
import os  
os.environ["TF_ENABLE_ONEDNN_OPTS"] = "0"  
os.environ["TF_USE_LEGACY_KERAS"]   = "1"  
  
import tensorflow  
import nnom_core  
import keras 
```
然后在虚拟环境下设置 export 的环境变量:
![[attachments/Pasted image 20240807002025.png]]

> [!caution] Deploy Process
> Simply use `generate_model(model, x_data)` to generate a C header `weights.h` after you have trained your model in Keras. It is available in [nnom_utils.py](https://github.com/majianjia/nnom/blob/master/scripts/nnom_utils.py)
> 
> Include the `weights.h` in your project, then call `nnom_model_create()` to create and compile the model on the MCU. Finaly, call `model_run()` to do your prediction.

实际上只需三个文件夹: inc, port, src;

NNOM 的整体部署结构如下(其中框架内包括 Layer API, Constrution API 和 Evaluation API):
![[attachments/nnom_structure.png|800]]

而实际上运行程序过程中需要训练好的 weights.h 文件, 而运行的过程中, 基本层级结构如下:
其中python 库称为 "layer-based libs", 包括 keras, tensorlayer, caffe 等, 而只需将其转化为 nnom model,  
![[attachments/nnom_structures.png|900]]

Recurrent layers **(Simple RNN, GRU, LSTM)** are implemented in version 0.4.1. Support `statful` and `return_sequence` options.

最简单的构建 keras 的多层部分如下图:
```python
import keras  
from keras import layers

model = keras.Sequential()
  
model.add(layers.Dense(32, input_dim = 784))  
model.add(layers.Activation('relu'))  
model.add(layers.Dense(10))
```

也可以采用:
```python
inputs = keras.Input(shape=(3,))  
x = keras.layers.Dense(4, activation=tf.nn.relu)(inputs)    # create layer after  inputs  
outputs = keras.layers.Dense(5, activation=tf.nn.softmax)(x)  
model = keras.Model(inputs = inputs, outputs = outputs)
```

**NNOM 必须和 keras 联合进行使用和训练**, 一般的 python 文件部分使用如下:
1. 构建 Keras 模型 
2. 生成 NNOM 模型的 weights.h  
3. 使用 NNOM 模型构建 NNOM  网络, 同时使用测试集进行推理, 验证准确性

一个简单的测试如下, 讲解了如何训练和构建神经网络, 最终调用 `generate_model(model, x_test, name='weights.h')` 来生成权重文件 weights.h 部分; 

主要包括 build_model 和 train 两个部分, 采用的是官网的**基于图片的 mnist 手写数据集**, 一般采用 keras.Input() 创建输入, 
```python fold title:main.py
import sys  
import os 

from tensorflow.keras import * 
from tensorflow.keras.datasets import mnist  
from tensorflow.keras.layers import *  
from tensorflow.keras.activations import *  
from tensorflow.keras.models import load_model, save_model  
import tensorflow as tf  
import numpy as np  
from nnom import *  
  
save_dir = 'keras_mnist_trained_model.h5'  
  
def build_model(x_shape):  
    inputs = Input(shape=x_shape)  
    x = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding='valid')(inputs)  
    x = BatchNormalization()(x)  
  
    x = Conv2D(16, dilation_rate=(1,1), kernel_size=(5, 5), strides=(1, 1), padding="valid")(x)  
    x = BatchNormalization()(x)  
    x = LeakyReLU(alpha=0.2)(x)  
    x = MaxPool2D((2, 2), strides=(2, 2), padding="same")(x)  
    x = Dropout(0.2)(x)  
  
    x = DepthwiseConv2D(depth_multiplier=2, dilation_rate=(2,2), kernel_size=(3, 3), strides=(1, 1), padding="valid")(x)  
    x = BatchNormalization()(x)  
    x = ReLU(negative_slope=0.2, threshold=0, max_value=6)(x)  
    x = Dropout(0.2)(x)  
  
    x = Conv2D(16, kernel_size=(1, 1), strides=(1, 1), padding="valid")(x)  
    x = BatchNormalization()(x)  
    x = ReLU()(x)  
    x = MaxPool2D((2, 2), strides=(2, 2), padding="same")(x)  
    x = Dropout(0.2)(x)  
  
    x = Flatten()(x)  
    x = Dense(64)(x)  
    x = ReLU()(x)  
    x = Dropout(0.2)(x)  
    x = Dense(10)(x)  
    # x = Conv2D(10, kernel_size=(3, 3), strides=(1, 1), padding="valid")(x)  
    # x = GlobalAveragePooling2D()(x)    predictions = Softmax()(x)  
  
    model = Model(inputs=inputs, outputs=predictions)  
    return model  
  
def train(model, x_train, y_train, x_test, y_test, batch_size=64, epochs=50):  
    model.compile(loss='categorical_crossentropy',  
                  optimizer='adam',  
                  metrics=['accuracy'])  
    model.summary()  
  
    history = model.fit(x_train, y_train,  
              batch_size=batch_size,  
              epochs=epochs,  
              verbose=2,  
              validation_data=(x_test, y_test),  
              shuffle=False)  
  
    save_model(model, save_dir)  
    return history  
  
def main():  
    #physical_devices = tf.config.experimental.list_physical_devices("GPU")  
    #if(physical_devices is not None):    #    tf.config.experimental.set_memory_growth(physical_devices[0], True)  
    epochs = 2  
    num_classes = 10  
	  
    # The data, split between train and test sets:  
    (x_train, y_train), (x_test_original, y_test_original) = mnist.load_data()  
  
    x_test = x_test_original  
    y_test = y_test_original  
    print(x_train.shape[0], 'train samples')  
    print(x_test.shape[0], 'test samples')  
  
    # Convert class vectors to binary class matrices.  
    y_train = tf.keras.utils.to_categorical(y_train, num_classes)  
    y_test = tf.keras.utils.to_categorical(y_test, num_classes)  
  
    # reshape to 4 d becaue we build for 4d?  
    x_train = x_train.reshape(x_train.shape[0], x_train.shape[1], x_train.shape[2], 1)  
    x_test = x_test.reshape(x_test.shape[0], x_test.shape[1], x_test.shape[2], 1)  
    print('x_train shape:', x_train.shape)  
  
    # quantize the range to q7  
    x_test = x_test.astype('float32')/255  
    x_train = x_train.astype('float32')/255  
    print("data range", x_test.min(), x_test.max())  
  
    #build model  
    model = build_model(x_test.shape[1:])  
  
    # train model  
    history = train(model, x_train, y_train, x_test.copy(), y_test.copy(), epochs=epochs)  
    del model  
    tf.keras.backend.clear_session()  
  
    # -------- generate weights.h (NNoM model) ----------  
    # get the best model    model = load_model(save_dir)  
  
    # output test  
    # for L in model.layers:    #     layer_model = Model(inputs=model.input, outputs=L.output)    #     print("layer", L.name)    #     features = layer_model.predict(x_test[:1])    #     pass    #     #print("output", features)  
    # only use 1000 for test    x_test = x_test[:1000]  
    y_test = y_test[:1000]  
    # generate binary dataset for NNoM validation, 0~1 -> 0~127, q7  
    generate_test_bin(x_test*127, y_test, name='test_data.bin')  
  
    # evaluate in Keras (for comparision)  
    scores = evaluate_model(model, x_test, y_test)  
  
    # generate NNoM model, x_test is the calibration dataset used in quantisation process  
    generate_model(model,  x_test, format='hwc', per_channel_quant=False, name="weights.h")  
  
    # --------- for test in CI ----------  
    # build NNoM    os.system("scons")  
  
    # do inference using NNoM  
    cmd = ".\mnist.exe" if 'win' in sys.platform else "./mnist"  
    os.system(cmd)  
    try:  
        # get NNoM results  
        result = np.genfromtxt('result.csv', delimiter=',', dtype=np.int32, skip_header=1)  
        result = result[:,0]        # the first column is the label, the second is the probability  
        label = y_test_original[:len(y_test)].flatten()     # use the original numerical label  
        acc = np.sum(result == label).astype('float32')/len(result)  
        if (acc > 0.5):  
            print("Top 1 Accuracy on Keras %.2f%%" %(scores[1]*100))  
            print("Top 1 Accuracy on NNoM  %.2f%%" %(acc *100))  
            return 0  
        else:  
            raise Exception('test failed, accuracy is %.1f%% < 80%%' % (acc * 100.0))  
    except:  
        raise Exception('could not perform the test with NNoM')  
  
if __name__ == "__main__":  
    main()
```

常用的生成模型部分的函数有如下几个: 包括评估模型准确性, 生成 weights.h 和 bin 文件;
```c
# -------- generate weights.h (NNoM model) ----------
# get the best model
model_path = os.path.join(save_dir, model_name)
model = load_model(model_path)

# evaluate
evaluate_model(model, x_test, y_test)

# save weight
generate_model(model,  x_test, format='hwc', name="weights.h")

# generate binary
generate_test_bin(x_test*127, y_test, name='mnist_test_data.bin')
```

### (2) NNOM 移植方法
修改nnom_port.h 中的malloc部分就可以了:
```c
#ifndef NNOM_USING_STATIC_MEMORY
    #if (SYS_USER_MALLOC == 0)
    #define nnom_malloc(n)      malloc(n)
    #define nnom_free(p)        free(p)
    #else
    #include "mymalloc.h"
    #define nnom_malloc(n)      mymalloc(SRAMIN, n)
    #define nnom_free(p)        myfree(SRAMIN, p) 
    #endif 
#endif
```
实际上**将三个文件夹移植进去然后全部包含加上 weights.h 就可以移植成功了**。 

```c
Memory cost by each block:
 blk_0:7744  blk_1:10816  blk_2:1936  blk_3:0  blk_4:0  blk_5:0  blk_6:0  blk_7:0  
 Memory cost by network buffers: 20496 bytes
 Total memory occupied: 22704 bytes
```
实际上大约会使用 20 kb RAM 部分;

调用模型代码如下:
```c
#include "weights.h"
#include "nnom.h"

int main(){
	nnom_model_t *model; 
	model = nnom_model_create(); 
	model_run(model);
}
```

预测结果的方法如下:
You can now use the model to predict your data.
- Firstly, filling the input buffer `nnom_input_buffer[]` with your own data(image, signals) which is defined in `weights.h`.
- Secondly, call `model_run(model);` to do your prediction.
- Thirdly, read your result from `nnom_output_buffer[]`. The maximum number is the results.

The data they normally process a few channels of time sequence measurement. For example, the accelerometer data consist of 3-axis (channel) measurement per timestamp.

## 二、 CMSIS-NN 的使用与 DSP 数字信号处理库
### (1) CMSIS-NN 部分
注意: CMSIS-NN 是专门为Cortex-M 设计的优化器后端, porting can gain better performance in some platforms by switch the backends or to provide print-out model info and evaluation. 
<mark style="background: transparent; color: red">对于 CMSIS, 针对 Cortex-M4, M7 内核, 可以提升大约 5 倍性能, 只需将 NNOM_USING_CMSIS_NN 进行定义即可</mark>

需要注意的是, 在启用 NNOM_USING_CMSIS_NN 时, 需要两个文件:
```c
#include "arm_math.h"
#include "arm_nnfunctions.h"
```
这两个文件可以在固件包的 CMSIS 以下两个文件夹找到:
其中 DSP (Digital Signal Processing) 为数字信号处理库, 而 NN 为神经网络库,
![[attachments/Pasted image 20240807161305.png]]
其中NN部分提供了不少函数, 我们只需包含 q7, q15 部分即可:
1. **q7**：表示 8 位定点数，其中 7 位用于表示小数部分。取值范围为 -1 到 0.9999 之间。
2. **s8**：表示 8 位有符号整数，取值范围为 -128 到 127。
3. **s16**：表示 16 位有符号整数，取值范围为 -32768 到 32767。
4. **q15**：表示 16 位定点数，其中 15 位用于表示小数部分。取值范围为 -1 到 0.9999 之间

然后, 根据需要进行裁剪: 
![[attachments/Pasted image 20240807165029.png]] 

最后将 arm_relu_q15.c 中有一处错误:  `read_q15x2_ia` 改为 `arm_nn_read_q15x2_ia` 即可编译成功;

实际添加文件, DSP 仅需添加 BasicMathFunctions 的部分
![[attachments/Pasted image 20240807171805.png]] 
而 NN 包添加基本所有的带有 q7 和 q15 后缀的部分, 注意别忘了添加 SupportFunctions 中的 arm_nntables.c 
![[attachments/Pasted image 20240807171904.png]]
然后即可编译成功。
### (2) DSP 库认识和环境搭建
如图 Cortex - M4  支持 DSP 指令: 包括
单周期乘加(MAC), 单周期SIMD 指令(多个数据参与运算), 双 16位城乘加器,  
![[attachments/Pasted image 20240812102603.png]]
参考 User Guide 部分,  由于 SIMD 指令支持, 可以完成如下的指令运算:
![[attachments/Pasted image 20240812103137.png|700]]

| 文件夹                  | 描述                                                                                   |
| -------------------- | ------------------------------------------------------------------------------------ |
| BasicMathFunctions   | 基本数学函数，提供浮点数的各种基本运算函数，如向量加减乘除等运算                                                     |
| CommonTables         | arm_common_tables.c文件提供位翻转或相关参数表                                                     |
| ComplexMathFunctions | 复杂数学功能，如向量处理，求模运算                                                                    |
| ControllerFunctions  | 控制功能函数，包括正弦余弦，PID电机控制，矢量Clarke变换，矢量Clarke逆变换等                                        |
| FastMathFunctions    | 快速数学功能函数，提供了一种快速的近似正弦，余弦和平方根等相比CMSIS计算库要快的数学函数                                       |
| FilteringFunctions   | 滤波函数功能，主要为FIR和LMS（最小均方根）等滤波函数                                                        |
| MatrixFunctions      | 矩阵处理函数，包括矩阵加法、矩阵初始化、矩阵反、矩阵乘法、矩阵规模、矩阵减法、矩阵转置等函数                                       |
| StatisticsFunctions  | 统计功能函数，如求平均值、最大值、最小值、计算均方根RMS、计算方差/标准差等                                              |
| SupportFunctions     | 支持功能函数，如数据拷贝，Q格式和浮点格式相互转换，Q任意格式相互转换                                                  |
| TransformFunctions   | 变换功能，包括复数FFT（CFFT）/复数FFT逆运算（CIFFT）、实数FFT（RFFT）/实数FFT逆运算（RIFFT）、和DCT（离散余弦变换）和配套的初始化函数 |

需要说明的是, 上述文件由于不方便包含, **也可以通过封装的 .lib 形式进行方便使用**; 注意整体的可以从 https://github.com/ARM-software/CMSIS_4/tree/master 进行下载: 

一般可以在 STM32Cube 固件包中找到对应的 CMSIS-> lib -> ARM 中找到
一般 Cortex-M3为小端(l) 模式, 而大端模式为 b 
![[attachments/Pasted image 20240812110238.png|600]]
具体存储位置如下:
![[attachments/Pasted image 20240812110925.png]]
一般选择小端浮点 lf_math.lib 即可; 
接着是搭建库的运行环境: 
首先获取到对应的库, 放在DSP > Include 文件夹下(其余的可以从 DSP> Include 中找到):
![[attachments/Pasted image 20240812112037.png]]
然后将 include文件夹设为 include 路径，并将 .lib 文件设置为源文件, 如图所示:
![[attachments/Pasted image 20240812112621.png]]
此时,即可直接编译成功; 配置环境完成;
另外，为了使用DSP库的功能, 需要添加如下的宏定义到工程中: 
```c
__FPU_USED          (optional)
__FPU_PRESENT    (optional)
ARM_MATH_DSP
ARM_MATH_MATRIX_CHECK
ARM_MATH_ROUNDING
```
需要说明的是, 前面的两个部分已经在 core_cm4.h 和 stm32f407xx.h 中已经定义过了。此时, 使用 Dsp 库中的部分， 只需要包含头文件:
```c
#include "arm_math.h"
```

即可使用:
```c
arm_sin_f32, arm_cos_f32
```

## 三、基本配置 
有 HWC 和 CHW 两种格式如下:
```markdown
### Format configuration
There are 2 formats normally use in machine learning. `HWC` and `CHW`. HWC called channel last, CHW called channel first.

The default backend will be running on `HWC format`, which is optimized for CPU case. Images are normally stored in the memory using HWC format.
```

NNOM_USING_CMSIS_NN 会采用 CISIS-NN 加速推理, 需要包含 DSP 和 NN 部分, 默认 HWC 

另外， You might also define your chip core and **enable your FPU support in your pre-compile configuration** if you are not able to compile.

> _e.g. when using STM32L476, you might add the two macro in your project ' ARM_MATH_CM4, \_\_FPU\_PRESENT=1'\_

注意 CHW 格式在仅CPU情况下, 效率很低, 但可以采用KPU加速; 而且此时不允许使用 CMSIS-NN 
```c
// runtime & debuges 
#define nnom_us_get() 0 
#define nnom_ms_get() rt_tick_get() // when tick is set to 1000 
#define NNOM_LOG(...) rt_kprintf(__VA_ARGS__)
```

```python
generate_model(model, x_test, name='weights.h', format='hwc', kld=True)
# 1. It firsly scans the output range of each layer's output using `layers_output_ranges()`
# 2. Then it quantised and write the weights & bias, fused the BatchNorm parameters using `generate_weights()`
# 3. Finally, it generate the C functions `nnom_model_t* nnom_model_create(void)` in `weights.h`
```
**Kullback-Leibler Divergence**(KLD) : This often results in better accuracy but can be more computationally intensive.

```python
layers_output_ranges(model, x_test, kld=True, calibrate_size=1000) 
# check the output range and generate the output shifting list of each layer. It will automatically distinguish whether a layer can change its output Q format or not.
```

```python
generate_weights(model, name='weights.h', format='hwc', shift_list=None)
# Scans all the layer which includes weights, quantise the weights and put them into the c header.
```

模型评估和结果输出:
```python
evaluate_model(model, x_test, y_test, running_time=False, to_file='evaluation.txt')
generate_test_bin(x, y, name='test_data_with_label.bin')
```

## 四、训练过程
一般都要使用 numpy 作为数据集容器，通过定义数据集，激活函数和隐藏层(Dense)实现模型训练，一个训练 iris 数据集的简单代码如下所示:

```python fold title:iris_test.py
import nnom  
import keras  
import numpy as np  
from keras import layers  
from keras.models import save_model  
import pandas as pd  
from sklearn import datasets  
from sklearn.model_selection import train_test_split  
  
  
def create_model():  
    inputs   = keras.Input(shape=(4,))  
  
    x = layers.ReLU()(inputs)  
    x = layers.Dense(20)(x)   # create a 20 nodes hidden dense layer (RELU activation function)  
    x = layers.ReLU()(x)  
    x = layers.Dense(10)(x)   # create a 10 nodes hidden dense layer (RELU activation function)  
    x = layers.ReLU()(x)  
    x = layers.Dense(3)(x)    # create a 3 nodes dense layer (RELU activation function)  
    predictions = layers.Softmax()(x)  
    model = keras.Model(inputs=inputs, outputs=predictions)  
    return model  
  
def train_model(model, x_train, y_train, x_test, y_test, epoch = 30):  
    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])  
    model.summary()  
  
    history = model.fit(x_train, y_train, epochs=epoch, batch_size=20, validation_data=(x_test, y_test), shuffle=True)  
    model.save('iris_trained_model.h5')  
    return history  
  
# x = keras.layers.Dense(4, activation=tf.nn.relu)(inputs)    # create layer after  inputs  
# outputs = keras.layers.Dense(5, activation=tf.nn.softmax)(x)  
# model = keras.Model(inputs = inputs, outputs = outputs)  
  
if __name__ == "__main__":  
    iris = datasets.load_iris()  
  
    x_total = pd.DataFrame(iris.get("data"))  
    y_total = pd.DataFrame(iris.get("target"))  
  
    dataset_all = pd.concat([x_total, y_total], axis=1)  
    train_dataset, test_dataset = train_test_split(dataset_all, test_size=0.2, random_state=None)  
  
    x_train = np.array(train_dataset.iloc[:, 0:4])  
    y_train = np.array(train_dataset.iloc[:, 4])  
    x_test = np.array(test_dataset.iloc[:, 0:4])  
    y_test = np.array(test_dataset.iloc[:, 4])  
  
    # transfer the data to the format of keras  
    x_train = np.reshape(x_train,(x_train.shape[0], x_train.shape[1], 1))  
    x_test = np.reshape(x_test,(x_test.shape[0], x_test.shape[1], 1))  
  
    print(x_train.shape, x_test.shape)  
    y_train = keras.utils.to_categorical(y_train, 3)  
    y_test = keras.utils.to_categorical(y_test, 3)  
    keras_model = create_model()  
  
    history = train_model(keras_model, x_train, y_train, x_test, y_test, epoch=10)  
    # save the model  
    model_build = keras.saving.load_model('iris_trained_model.h5')  
    nnom.generate_model(model_build, x_test, format='hwc', per_channel_quant=False, name='iris_weights.h', quantize_method='max-min')  
  
    nnom.evaluate_model(model_build,x_test,y_test)  
  
    # save test data  
    test_dataset.to_csv('test.csv', index=False)  
    print('test data saved')
```

